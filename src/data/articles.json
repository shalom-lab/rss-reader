[
  {
    "id": "ruanyf",
    "title": "ç§‘æŠ€çˆ±å¥½è€…å‘¨åˆŠï¼ˆç¬¬ 342 æœŸï¼‰ï¼šé¢è¯•çš„ AI ä½œå¼Š----ç”¨æ•°å­—äººåŽ»é¢è¯•",
    "description": "è¿™é‡Œè®°å½•æ¯å‘¨å€¼å¾—åˆ†äº«çš„ç§‘æŠ€å†…å®¹ï¼Œå‘¨äº”å‘å¸ƒã€‚\næœ¬æ‚å¿—å¼€æºï¼Œæ¬¢è¿ŽæŠ•ç¨¿ã€‚å¦æœ‰ã€Šè°åœ¨æ‹›äººã€‹æœåŠ¡ï¼Œå‘å¸ƒç¨‹åºå‘˜æ‹›è˜ä¿¡æ¯ã€‚åˆä½œè¯·é‚®ä»¶è”ç³»ï¼ˆyifeng.ruan@gmail.comï¼‰ã€‚\nå°é¢å›¾\n\nå››å·çœå½­å·žå¸‚çš„ä¸­å›½è”¬èœåšè§ˆé¦†ï¼Œè®¾æœ‰ä¸€ä¸ª\"ç§å­é“¶è¡Œ\"ï¼Œä¿å­˜äº†200å¤šç§è”¬èœçš„ç§å­ã€‚ï¼ˆviaï¼‰\né¢è¯•çš„ AI ä½œå¼Šï¼šç”¨æ•°å­—äººåŽ»é¢è¯•\nå¤§å®¶è‚¯å®šæƒ³åˆ°äº†ï¼ŒAI çš„èƒ½åŠ›çŽ°åœ¨è¿™ä¹ˆå¼ºï¼Œä¸€å®šæœ‰äººç”¨æ¥ä½œå¼Šã€‚\næ±‚èŒä½œå¼Šæ˜¯æœ€ç®€å•çš„ï¼Œæ±‚èŒä¿¡å’Œå±¥åŽ†éƒ½å¯ä»¥è®© AI ç”Ÿæˆï¼Œä½†æ˜¯ä½ æœªå¿…èƒ½æƒ³åˆ°ï¼Œé¢è¯•ä¹Ÿèƒ½ AI ä½œå¼Šï¼Œæ´¾ä¸€ä¸ªæ•°å­—äººæ¥é¢è¯•ã€‚\n\"æ•°å­—äºº\"æŠ€æœ¯å‡ å¹´å‰å°±æœ‰äº†ï¼ŒçŽ°åœ¨æ·»åŠ äº† AIï¼Œç®€ç›´å¦‚è™Žæ·»ç¿¼ï¼Œå¯ä»¥ä¹±çœŸã€‚\nç½‘ä¸Šæœ‰å¾ˆå¤šæ•™ç¨‹ï¼Œæ•™ä½ æ€Žä¹ˆç”Ÿæˆæ•°å­—äººï¼Œå“ªæ€•ä¸æ‡‚è½¯ä»¶ï¼Œéƒ½å¯ä»¥è·Ÿç€åšå‡ºæ¥ã€‚\n\n\n\nåªè¦ä¸Šä¼ è„¸éƒ¨ç…§ç‰‡å’Œè¯­éŸ³ç‰‡æ®µï¼ŒAI å°±ä¼šç”Ÿæˆä½ çš„æ•°å­—åŒ–èº«ï¼Œå®ƒè·Ÿä½ é•¿å¾—ä¸€æ¨¡ä¸€æ ·ï¼Œç”¨ä½ çš„å£°éŸ³å’Œè¡¨æƒ…è¯´è¯ã€‚ä½ è®©å®ƒè¯´ä»€ä¹ˆï¼Œå®ƒå°±è¯´ä»€ä¹ˆï¼Œå°±åƒä¸‹å›¾è¿™æ ·ã€‚\n\nçŽ°åœ¨ï¼Œå¾ˆå¤šå…¬å¸é‡‡ç”¨è§†é¢‘é¢è¯•ï¼Œå°¤å…¶æ˜¯æ‹›è˜è¿œç¨‹å‘˜å·¥ï¼Œå¯èƒ½åªæœ‰è§†é¢‘é¢è¯•ï¼Œæ ¹æœ¬æ²¡æœ‰çº¿ä¸‹é¢è¯•ã€‚\næ•°å­—äººæ—¢ç„¶è·ŸçœŸäººé•¿å¾—ä¸€æ ·ï¼Œå½“ç„¶å¯èƒ½å†’å……çœŸäººå‚åŠ è§†é¢‘é¢è¯•ã€‚\næœ€è¿‘ï¼Œç½‘ä¸Šå°±çˆ†å‡ºäº†ä¸€ä¸ªçœŸå®žçš„æ¡ˆä¾‹ï¼Œæ³¢å…°çš„ä¸€å®¶åˆ›ä¸šå…¬å¸é‡åˆ°äº†æ•°å­—äººå‚åŠ é¢è¯•ã€‚\nè¿™ä¸ªå«åš Bratislav RakoÄeviÄ‡ çš„åº”è˜è€…ï¼Œæœ‰ç€éžå¸¸è¯¦ç»†å®Œæ•´çš„ LinkedIn ä¸»é¡µï¼ˆä¸‹å›¾ï¼‰ã€‚\n\nç®€åŽ†ä¹Ÿæ¯«æ— é—®é¢˜ï¼ˆä¸‹å›¾ï¼‰ï¼Œçœ‹ä¸ŠåŽ»å¾ˆæœ‰è¯´æœåŠ›ï¼Œç½—åˆ—äº†æŽŒæ¡çš„å‰åŽç«¯æŠ€èƒ½ï¼Œç”³è¯·èŒä½æ˜¯å…¨æ ˆå·¥ç¨‹å¸ˆã€‚\n\né¡ºç†æˆç« ï¼Œä»–å°±è¿›å…¥äº†è§†é¢‘é¢è¯•ã€‚é¢è¯•å®˜è§åˆ°æœ¬äººï¼ˆä¸‹å›¾å³ï¼‰æ—¶ï¼Œå°±è§‰å¾—è·Ÿç½‘é¡µå¤´åƒï¼ˆä¸‹å›¾å·¦ï¼‰ä¸å¤ªåƒã€‚\n\nè€Œä¸”ï¼Œä»–ä½¿ç”¨äº†èƒŒæ™¯æ»¤é•œï¼Œæ•´ä¸ªäººçš„å½±åƒæ˜¯æå–å‡ºæ¥çš„ï¼Œè´´åœ¨èƒŒæ™¯ä¸Šï¼Œå¤´éƒ¨è¾¹ç¼˜æ˜¾å¾—æ¨¡ç³Šè€Œä¸è‡ªç„¶ã€‚é¢è¯•å®˜å½“æ—¶ä¹Ÿæ²¡æœ‰å¤šæƒ³ã€‚\nä»–çš„é¢è¯•è¡¨çŽ°æžä½³ï¼Œä»»ä½•é—®é¢˜éƒ½èƒ½å¿«é€Ÿåº”å¯¹ï¼Œåœ¨è§„å®šçš„2å°æ—¶å†…å®Œæˆäº†æ‰€æœ‰ç¼–ç é¢˜ç›®å’ŒåŽç»­æé—®ï¼Œè¿™æ˜¯å‰æ‰€æœªæœ‰çš„ã€‚\nä½†æ˜¯ï¼Œåœ¨äº¤è°ˆè¿‡ç¨‹ä¸­ï¼Œé¢è¯•å®˜é€æ¸äº§ç”Ÿäº†æ€€ç–‘ã€‚é¦–å…ˆï¼ŒæŒ‰ç…§ç®€åŽ†ï¼Œè¿™ä¸ªäººåœ¨å¡žå°”ç»´äºšè¯»å¤§å­¦ï¼Œä½†æ˜¯å´ä¸ä¼šè¯´å¡žå°”ç»´äºšè¯­ï¼Œåªä¼šè¯´è‹±è¯­ã€‚ï¼ˆäº‹åŽæŽ¨æµ‹ï¼ŒåŽŸå› å¾ˆå¯èƒ½æ˜¯ï¼Œä»–çš„è¯­éŸ³å¼•æ“Žæ²¡æœ‰å¡žå°”ç»´äºšè¯­ï¼Œæˆ–è€…ä¸å¦‚è‹±è¯­é€¼çœŸã€‚ï¼‰\nå…¶æ¬¡ï¼Œä»–çš„è‹±è¯­ç¼ºä¹è¯­æ°”è¯­è°ƒå˜åŒ–ï¼Œè¯´è¯æ²¡æœ‰æ²Ÿé€šæŠ€å·§ï¼Œè®©äººæ„Ÿè§‰æœ‰ç‚¹æœºæ¢°ã€‚\næœ€åŽï¼Œä»–å¯¹ä»¥å‰èŒä½çš„ç»†èŠ‚ï¼Œè¯´å¾—ä¸æ¸…æ¥šï¼Œéš¾ä»¥ä»¤äººä¿¡æœã€‚\nä¸ºäº†æµ‹è¯•è¿™æ˜¯å¦çœŸäººï¼Œé¢è¯•å®˜ä¸´æ—¶åŠ äº†ä¸€ä¸ªé¡¹ç›®ã€‚\n\né¢è¯•å®˜åšäº†ä¸€ä¸ªç¤ºèŒƒåŠ¨ä½œï¼Œä¸¾èµ·ä¸€åªæ‰‹ï¼Œå¼ å¼€äº”ä¸ªæ‰‹æŒ‡ï¼ŒæŒ¡ä½è‡ªå·±çš„è„¸éƒ¨ï¼Œè¦æ±‚åº”è˜è€…ç…§ç€åšï¼ˆä¸Šå›¾ï¼‰ã€‚\nç»“æžœï¼Œåº”è˜è€…è¯´äº†ä¸€å †ç†ç”±ï¼Œæ‹’ç»äº†è¿™ä¸ªè¦æ±‚ã€‚è‡³æ­¤ï¼Œé¢è¯•å®˜ç¡®å®šï¼Œå¯¹é¢æ˜¯ä¸€ä¸ª AI æ•°å­—äººã€‚\nä»–ä»¬æŠŠè¿™ä»¶äº‹å…¬å¼€åˆ°ç½‘ä¸Šï¼Œå¸Œæœ›å…¶ä»–å…¬å¸æé«˜è­¦æƒ•ï¼Œä¸è¦è¢«éª—äº†ã€‚\nè¿™æ ·çš„æ•°å­—äººé¢è¯•ï¼Œä»¥åŽè‚¯å®šè¶Šæ¥è¶Šå¤šï¼Œæ€Žä¹ˆåº”å¯¹å‘¢ï¼Ÿ\nä¸‹é¢æ˜¯ä¸€äº›ç ´è§£æ–¹æ³•ã€‚\nï¼ˆ1ï¼‰è¦æ±‚åº”è˜è€…ç»™å‡ºæŽ¨èäººï¼Œä»¥ä¾›è”ç³»æ ¸å¯¹ã€‚\nï¼ˆ2ï¼‰æŸ¥æ‰¾åº”è˜è€…çš„ç½‘ç»œæ´»åŠ¨ç—•è¿¹ã€‚å¦‚æžœç½‘ä¸Šæ ¹æœ¬æœä¸åˆ°ä»€ä¹ˆç—•è¿¹ï¼Œå°±è¯´æ˜Žå¾ˆå¯ç–‘ã€‚\nï¼ˆ3ï¼‰é™¤äº†è§†é¢‘é¢è¯•ï¼Œå†å®‰æŽ’ä¸€åœºçº¿ä¸‹é¢è¯•ã€‚\nï¼ˆ4ï¼‰åœ¨è§†é¢‘é¢è¯•ä¸­ï¼Œè¦æ±‚åº”è˜è€…åšä¸€äº›æ•°å­—äººæ— æ³•å¤„ç†çš„äº‹æƒ…ï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰ç ´ç»½ã€‚æ¯”å¦‚ï¼Œç«™èµ·èº«å›´ç»•æ‘„åƒå¤´è½¬ä¸€åœˆï¼Œå¤´éƒ¨å‰åŽå·¦å³è½¬åŠ¨ï¼Œä»¥åŠä¸¾èµ·æ‰‹åšä¸€äº›åŠ¨ä½œã€‚\nAI ç¼–ç¨‹åˆ›æ„æŒ‘æˆ˜èµ›\nä¸çŸ¥ä¸è§‰ï¼Œç¨€åœŸæŽ˜é‡‘å’Œ Trae è”åˆä¸¾åŠžçš„ AI FOR CODE åˆ›æ„æŒ‘æˆ˜èµ›ï¼Œå·²ç»èµ›ç¨‹è¿‡åŠã€‚\nï¼ˆ1ï¼‰\"åˆ›æ„èµ›é“\"çš„æäº¤å…¥å£ï¼Œå°†åœ¨ä¸‹å‘¨äº”ï¼ˆ3æœˆ28æ—¥ï¼‰æˆªæ­¢ã€‚å¦‚æžœæœ‰å¥½çš„ AI ç¼–ç¨‹åˆ›æ„ï¼ˆä¸éœ€è¦åŠ¨æ‰‹å®žçŽ°ï¼‰ï¼ŒçŽ°åœ¨è¿˜èƒ½æäº¤ã€‚\nï¼ˆ2ï¼‰åˆ›æ„èµ›é“çš„æŠ•ç¥¨æ­£åœ¨è¿›è¡Œä¸­ï¼Œå‚èµ›è€…çš„åæ¬¡é€šè¿‡æŠ•ç¥¨èŽ·å¾—ï¼Œæƒ³å¾—å¥–çš„åŒå­¦è¦ç§¯æžæ‹‰ç¥¨å‘€ã€‚\nï¼ˆ3ï¼‰\"åº”ç”¨èµ›é“\"çš„æäº¤å…¥å£ï¼Œæœ¬å‘¨å·²ç»å¼€å¯ï¼Œå¤§å®¶å¯ä»¥æäº¤è‡ªå·±çš„ AI ç¼–ç¨‹ä½œå“äº†ã€‚æˆªæ­¢æ—¶é—´æ˜¯3æœˆ31æ—¥ï¼ŒåŠ¡å¿…æŠ“ç´§ã€‚\n\næœ¬æ¬¡å¤§èµ›è®¾æœ‰ä¼—å¤šå¥–å“ï¼ŒåŒ…æ‹¬å¥–é‡‘ã€iPhone 16ã€åŽä¸ºmate 70ã€å¤§ç–†pocket3ã€ç´¢å°¼PS5ã€å¤–æ˜Ÿäººé”®ç›˜&æ˜¾ç¤ºå™¨ã€ä»»å¤©å ‚switchã€é©¬æ­‡å°”éŸ³å“ç­‰ï¼Œå‚èµ›å³æœ‰æœºä¼šæŠ½å¥–ã€‚\nèŽ·å¥–çš„åˆ›æ„å’Œä½œå“ï¼Œè¿˜å¯èƒ½èŽ·å¾—æŠ•èµ„å…¬å¸çš„é’çï¼Œå¹¶ä¸”é€šè¿‡ AI çš„åŠ©åŠ›ï¼Œè¯´ä¸å®šå¯ä»¥è§£å†³å¾ˆå¤šäººç”Ÿæ´»ä¸­é¢ä¸´çš„å›°å¢ƒã€‚\nå¤§èµ›çš„è¯¦ç»†ä»‹ç»ï¼Œä»¥åŠæäº¤/æŠ•ç¥¨å…¥å£ï¼Œè¯·ç‚¹å‡»è¿™é‡Œï¼Œæˆ–è€…æ‰«æä¸Šæ–¹æµ·æŠ¥ã€‚ç¥æ„¿å¤§å®¶éƒ½èƒ½å¾—å¥–ã€‚\nç§‘æŠ€åŠ¨æ€\n1ã€ç‰¹æ–¯æ‹‰çš„è‡ªåŠ¨é©¾é©¶\nç‰¹æ–¯æ‹‰çš„è‡ªåŠ¨é©¾é©¶ï¼Œå®Œå…¨ä¾é æ‘„åƒå¤´ï¼Œæ²¡æœ‰æ¿€å…‰é›·è¾¾ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒåªæœ‰è§†è§‰è¯†åˆ«ã€‚\nä¸€ä½ç¾Žå›½å·¥ç¨‹å¸ˆè®¤ä¸ºï¼Œè¿™æ ·æ˜¯ä¸å¤Ÿçš„ã€‚ä»–åšäº†ä¸€ä¸ªå®žéªŒï¼Œåœ¨é“è·¯ä¸­å¤®æž¶èµ·äº†ä¸€å—å·¨å¤§çš„ç”»å¸ƒã€‚\n\næŽ€èµ·é®ç›–åŽï¼Œç”»ä¸Šæ˜¯å»¶ä¼¸åˆ°å‰æ–¹çš„é“è·¯ï¼Œè·Ÿå‘¨å›´èžä¸ºä¸€ä½“ã€‚\n\nç»“æžœï¼Œç‰¹æ–¯æ‹‰çš„è‡ªåŠ¨é©¾é©¶ï¼Œæ ¹æœ¬è®¤ä¸å‡ºæ¥è¿™æ˜¯ç”»ï¼Œä¸€å¤´å°±æ’žä¸ŠåŽ»äº†ã€‚\n\nç›¸æ¯”ä¹‹ä¸‹ï¼Œä½¿ç”¨æ¿€å…‰é›·è¾¾çš„è½¦åž‹ï¼Œåˆ™ä¼šåœ¨ç”»å‰è‡ªåŠ¨åœä¸‹æ¥ã€‚\nè™½ç„¶è¿™ä¸ªå®žéªŒæ˜¯æžç«¯æƒ…å†µï¼Œä½†æ˜¯æ‘„åƒå¤´åœ¨æµ“é›¾å’Œå¤§é›¨å¤©æ°”ï¼Œæ•ˆæžœä¸ä½³ï¼Œå´æ˜¯ä¸äº‰çš„äº‹å®žã€‚\n2ã€Windows è®°äº‹æœ¬çš„æ”¶è´¹åŠŸèƒ½\nè®°äº‹æœ¬ï¼ˆNotepadï¼‰å’Œç”»æ¿ï¼ˆPaintï¼‰ï¼Œä¸€ç›´æ˜¯ Windows çš„åŸºæœ¬ç»„ä»¶ï¼Œæ¯ä¸€ä»£ Windows éƒ½å†…ç½®äº†ï¼Œå…è´¹ä½¿ç”¨ã€‚\nä½†æ˜¯ï¼ŒWindows 11 æœ€æ–°ä¸€æ¬¡çš„æ›´æ–°ï¼Œä¸ºè¿™ä¸¤ä¸ªè½¯ä»¶åŠ å…¥äº†æ”¶è´¹åŠŸèƒ½ã€‚\n\nå¾®è½¯ä¸ºè®°äº‹æœ¬å’Œç”»æ¿é…ç½®äº† AIï¼Œå‰è€…å¯ä»¥è‡ªåŠ¨é‡å†™ã€ç¼©å†™ã€æ‰©å†™æ–‡ç« ï¼ŒåŽè€…å¯ä»¥è‡ªåŠ¨ç”Ÿæˆå›¾åƒã€‚\nè¿™äº› AI åŠŸèƒ½åªæœ‰ Microsoft 365 çš„è®¢æˆ·æ‰èƒ½ä½¿ç”¨ï¼ˆæœˆè´¹9.99ç¾Žå…ƒï¼‰ã€‚å¦‚æžœæ²¡æœ‰ä»˜è´¹ï¼Œå°±æ— æ³•ä½¿ç”¨ï¼Œå³ä¸Šè§’çš„ AI èœå•ä¼šå˜ç°è‰²ï¼ˆä¸Šå›¾ï¼‰ã€‚\nä»Žæ­¤ï¼Œè®°äº‹æœ¬å’Œç”»æ¿ä¸å†æ˜¯å…è´¹è½¯ä»¶äº†ï¼Œéƒ¨åˆ†åŠŸèƒ½æœ‰ä»˜è´¹å¢™ã€‚\n3ã€AI åŽ»é™¤å›¾åƒæ°´å°\nå¾ˆå¤šç¾Žå›½ç”¨æˆ·åœ¨ç¤¾äº¤åª’ä½“ä¸Šåæ˜ ï¼Œè°·æ­Œæ–°å‘å¸ƒçš„ Gemini 2.0 Flash æ¨¡åž‹ï¼ŒåŽ»é™¤å›¾ç‰‡æ°´å°çš„æ•ˆæžœæžä½³ã€‚\nè¿™æ˜¯å¸¦æœ‰æ°´å°çš„åŽŸå›¾ã€‚\n\nè¿™æ˜¯å¤§æ¨¡åž‹åŽ»é™¤æ°´å°çš„æ•ˆæžœã€‚\n\nè¯¥æ¨¡åž‹ä¸ä»…èƒ½åŽ»é™¤æ°´å°ï¼Œè¿˜èƒ½å¡«è¡¥åŽ»é™¤æ°´å°è€Œäº§ç”Ÿçš„ä»»ä½•ç©ºç™½ã€‚\n\n\nè™½ç„¶å…¶ä»–æ¨¡åž‹ä¹Ÿèƒ½åŽ»é™¤æ°´å°ï¼Œä½†æ˜¯ Gemini 2.0 Flash ä¼¼ä¹Žç‰¹åˆ«æ“…é•¿è¿™ä»¶äº‹ï¼Œè€Œä¸”å®ƒå¯ä»¥å…è´¹ä½¿ç”¨ã€‚\nGemini 2.0 Flash å¯ä»¥åœ¨è°·æ­Œå®˜ç½‘ä½¿ç”¨ã€‚å¦å¤–ï¼Œç½‘å‹ @panjianning æŠ•ç¨¿äº†ä¸€ä¸ªè‡ªå·±åšçš„è°ƒç”¨åœ°å€ã€‚\n4ã€å…¶ä»–\nï¼ˆ1ï¼‰ä¸­å›½é¦–æ¬¾è¶…é•¿å¯¿å‘½ç¢³-14æ ¸ç”µæ± \"çƒ›é¾™ä¸€å·\"ç ”åˆ¶æˆåŠŸï¼Œåˆ©ç”¨åŒä½ç´ è¡°å˜ä¾›ç”µï¼Œç†è®ºä¸Šå¯ä»¥æŒç»­æ”¾ç”µä¸Šåƒå¹´ï¼Œé€‚åˆé«˜å±±æµ·æ´‹ã€å®‡å®™ç©ºé—´ã€è„‘æœºæŽ¥å£ã€å¿ƒè„èµ·æå™¨ç­‰åœºæ™¯ã€‚\n\nï¼ˆ2ï¼‰ç¾Žå›½åŠ³å·¥å±€ç»Ÿè®¡ï¼Œç¾Žå›½åœ¨èŒçš„ç¨‹åºå‘˜ç›®å‰æœ‰30å¤šä¸‡ï¼Œæ˜¯1980å¹´ä»¥æ¥çš„æœ€ä½Žå€¼ï¼Œä»…ä¸º21ä¸–çºªåˆäº’è”ç½‘ç¹è£æ—¶æœŸçš„ä¸€åŠã€‚\nåŽŸå› å¯èƒ½æ˜¯ AI çš„å†²å‡»ï¼Œä»…ä»…2023å¹´ä¸€å¹´ï¼Œç¨‹åºå‘˜å°±ä¸šäººæ•°å°±æ€¥å‰§ä¸‹é™äº†27.5%ã€‚\nï¼ˆ3ï¼‰Nginx æœåŠ¡å™¨æ‹’ç»ä¸ºé»˜è®¤çš„404é¡µé¢ï¼Œæ·»åŠ æš—é»‘æ¨¡å¼ï¼ˆä¸‹å›¾å³ï¼‰ï¼Œç†ç”±æ˜¯ä¸æ„¿å¢žåŠ å¤æ‚æ€§ï¼Œè€Œä¸”ç”¨æˆ·å®Œå…¨å¯ä»¥è‡ªå®šä¹‰è¿™ä¸ªé¡µé¢ã€‚\n\nï¼ˆ4ï¼‰è°·æ­Œ AI éƒ¨é—¨è´Ÿè´£äººç§°ï¼Œé€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰å°†åœ¨æœªæ¥äº”åˆ°åå¹´å†…å‡ºçŽ°ã€‚\næ–‡ç« \n1ã€æœåŠ¡å™¨å‘é€äº‹ä»¶ï¼ˆSSEï¼‰è¢«ä½Žä¼°äº†ï¼ˆè‹±æ–‡ï¼‰\n\næœ¬æ–‡è¯¦ç»†ä»‹ç»\"æœåŠ¡å™¨å‘é€äº‹ä»¶\"æ˜¯ä»€ä¹ˆï¼Œä»¥åŠç›®å‰çš„ AI æœåŠ¡å¦‚ä½•ä½¿ç”¨å®ƒã€‚\n2ã€å…³äºŽç»§æ‰¿å’Œå­ç±»åž‹ï¼ˆè‹±æ–‡ï¼‰\n\nJavaã€Goã€Python è¿™ä¸‰ç§è¯­è¨€ï¼Œæœ‰ä¸ä¸€æ ·çš„ç»§æ‰¿è®¾è®¡ï¼Œæœ¬æ–‡æ¯”è¾ƒäº†å®ƒä»¬å„è‡ªå¦‚ä½•å®žçŽ°ä¸€ä¸ªå­ç±»åž‹ã€‚\n3ã€CSS å±žæ€§çš„ unset å€¼ï¼ˆè‹±æ–‡ï¼‰\n\nCSS å±žæ€§å‡ ä¹Žéƒ½å¯ä»¥è®¾æˆä¸‰ä¸ªå€¼ initialï¼ˆä¸ç»§æ‰¿ï¼‰/inheritï¼ˆç»§æ‰¿ï¼‰/unsetï¼ˆå–æ¶ˆé»˜è®¤å€¼ï¼‰ï¼Œæœ¬æ–‡ç”¨ä¾‹å­è§£é‡Šå®ƒä»¬çš„å«ä¹‰ã€‚\n4ã€å¸ƒå°”å±žæ€§çš„é™·é˜±ï¼ˆè‹±æ–‡ï¼‰\n\næœ¬æ–‡æå‡ºä¸€ä¸ªç¼–ç¨‹æŠ€å·§ï¼šå°½é‡å°‘åœ¨ç±»ï¼ˆclassï¼‰é‡Œé¢è®¾ç½®å¸ƒå°”å±žæ€§ï¼Œè€Œè¦æ”¹ç”¨æžšä¸¾ï¼ˆenumï¼‰ã€‚\n5ã€æˆ‘ä»Žé›¶åˆ¶ä½œäº†ä¸€ä¸ªæ™ºèƒ½æ‰‹è¡¨ï¼ˆè‹±æ–‡ï¼‰\n\nä½œè€…ä»‹ç»æ€Žä¹ˆåˆ¶ä½œä¸€æ¬¾æ™ºèƒ½æ‰‹è¡¨ï¼Œå¯ä»¥ç”¨æ¥äº†è§£ç¡¬ä»¶å·¥ç¨‹å¸ˆçš„å·¥ä½œã€‚\n6ã€:user-valid ä¼ªç±»ï¼ˆè‹±æ–‡ï¼‰\n\nä¸€ç¯‡ CSS æ•™ç¨‹ï¼Œä»‹ç» :user-valid ä¼ªç±»ï¼ˆè¡¨ç¤ºç”¨æˆ·çš„è¾“å…¥é€šè¿‡äº† input è¾“å…¥æ¡†çš„æ ¡éªŒï¼‰ã€‚\n7ã€ä½¿ç”¨ GitHub Actions å’Œ GitHub Pages æž„å»ºå’Œéƒ¨ç½²ç½‘ç«™ï¼ˆè‹±æ–‡ï¼‰\n\næœ¬æ–‡æ˜¯ä¸€ç¯‡æ•™ç¨‹ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨ GitHub Actions æž„å»ºç½‘ç«™ï¼Œç„¶åŽéƒ¨ç½²åˆ° GitHub Pagesã€‚\nå·¥å…·\n1ã€daylight\n\nå‘½ä»¤è¡ŒæŸ¥è¯¢æ—¥å‡ºæ—¥è½æ—¶é—´ï¼Œå¯ä»¥æŒ‡å®šåœ°ç‚¹å’Œæ—¥æœŸã€‚\n2ã€FilePizza\n\nåœ¨æµè§ˆå™¨é‡Œ\"ç‚¹å¯¹ç‚¹\"ä¼ é€æ–‡ä»¶çš„å¼€æºå·¥å…·ã€‚\n3ã€git-who\n\nä¸€ä¸ªå¼€æºçš„å‘½ä»¤è¡Œå·¥å…·ï¼Œæ˜¾ç¤º Git ä»“åº“çš„æäº¤è€…ç»Ÿè®¡ã€‚\n4ã€rust-stakeholder\n\nä¸€ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼Œå”¯ä¸€ä½œç”¨å°±æ˜¯è®©ä½ çš„ç»ˆç«¯æ˜¾å¾—å¾ˆå¿™ï¼Œæºæºä¸æ–­æœ‰è¾“å‡ºï¼Œé€‚åˆæ‘¸é±¼ã€‚\n5ã€hoarder\n\nä¸€ä¸ªè‡ªæ‰˜ç®¡çš„ä¹¦ç­¾åº”ç”¨ï¼Œæœ‰ Web ç«¯å’Œæ‰‹æœºç«¯ï¼Œå¯ä»¥ç”¨ AI è‡ªåŠ¨ç”Ÿæˆå†…å®¹æ ‡ç­¾ã€‚\n6ã€å¾®ä¿¡ç¾¤èŠçš„æ°¸ä¹…äºŒç»´ç \n\nå¾®ä¿¡ç¾¤èŠçš„äºŒç»´ç é¢‘ç¹å˜åŠ¨ï¼Œè¿™ä¸ªå·¥å…·å¯ä»¥ç”Ÿæˆæ°¸ä¹…äºŒç»´ç ï¼ŒåŸºäºŽ Cloudflare Workers å’Œ KV å­˜å‚¨ã€‚ï¼ˆ@xxnuo æŠ•ç¨¿ï¼‰\n7ã€Webcam Runner\n\nä¸€ä¸ªå¯¹ç€ç”µè„‘æ‘„åƒå¤´çš„å¼€æºè·‘æ­¥æ¸¸æˆï¼Œæ£€æµ‹ç”¨æˆ·åŠ¨ä½œæ¥æŽ§åˆ¶æ¸¸æˆè§’è‰²åœ¨æ— é™åœºæ™¯ä¸­å¥”è·‘ï¼Œé€‚åˆå®¤å†…é”»ç‚¼èº«ä½“ã€‚ï¼ˆ@Jamesun921 æŠ•ç¨¿ï¼‰\n8ã€Cover Page\n\nå…è´¹çš„å°é¢å›¾åˆ¶ä½œç½‘ç«™ã€‚ï¼ˆ@amuluze æŠ•ç¨¿ï¼‰\n9ã€EchoShare\n\nå¼€æºçš„åŸºäºŽ WebRTC çš„åœ¨çº¿å±å¹•å…±äº«å·¥å…·ï¼Œå…è®¸ä¸Žä»–äººå…±äº«å±å¹•ã€æ‘„åƒå¤´å’ŒéŸ³é¢‘ã€‚\nï¼ˆ@shawroger æŠ•ç¨¿ï¼‰\n10ã€Lazyeat\n\nå¼€æºçš„ Windows æ¡Œé¢åº”ç”¨ï¼Œæ‰‹åŠ¿æŽ§åˆ¶ç”µè„‘ã€‚ï¼ˆ@maplelost æŠ•ç¨¿ï¼‰\nAI ç›¸å…³\n1ã€SVG ç§€\n\næ ¹æ®æ–‡å­—æè¿°ï¼Œç”Ÿæˆ SVG å›¾ç‰‡ï¼Œå¹¶å¯ä»¥ç¼–è¾‘ï¼Œä»£ç å¼€æºï¼ˆå‰ç«¯å’ŒåŽç«¯ï¼‰ã€‚ï¼ˆ@chaseFunny æŠ•ç¨¿ï¼‰\n2ã€MarkPDFDown\n\nåŸºäºŽå¤§æ¨¡åž‹çš„ PDF è½¬ Markdown å·¥å…·ï¼Œå®žçŽ°æ–‡æ¡£ç»“æž„åŒ–è½¬æ¢ã€‚ï¼ˆ@jorben æŠ•ç¨¿ï¼‰\n3ã€We0\n\né€šè¿‡ AI ç”Ÿæˆåº”ç”¨ç¨‹åºï¼Œæ”¯æŒåŽç«¯ç”Ÿæˆå’Œå‰ç«¯ç”Ÿæˆï¼Œè¿˜å¯ä»¥ Sketch/Figma è®¾è®¡ç¨¿1:1è¿˜åŽŸï¼Œä»£ç å¼€æºã€‚ï¼ˆ@Mashiro2000 æŠ•ç¨¿ï¼‰\n4ã€Githubhunt\n\nä½¿ç”¨è‡ªç„¶è¯­è¨€ï¼Œæœç´¢ GitHub ä»“åº“ã€‚ï¼ˆ@xgzlucario æŠ•ç¨¿ï¼‰\n5ã€Prompt Optimizer\n\nå¼€æºçš„ AI æç¤ºè¯ä¼˜åŒ–å·¥å…·ã€‚ï¼ˆ@linshenkx æŠ•ç¨¿ï¼‰\n6ã€Bob plugin MTranServer\n\nBobï¼ˆmacOS å¹³å°çš„ç¿»è¯‘è½¯ä»¶ï¼‰çš„ä¸€ä¸ªæ’ä»¶ï¼Œå¼•å…¥æœ¬åœ°ç¿»è¯‘æœåŠ¡å™¨ MTranServerã€‚ï¼ˆ@gray0128 æŠ•ç¨¿ï¼‰\nèµ„æº\n1ã€Maple Mono\n\nå¼€æºçš„ç­‰å®½å­—ä½“ï¼Œæ”¯æŒä¸­æ–‡ã€‚ï¼ˆ@subframe7536 æŠ•ç¨¿ï¼‰\n2ã€ä¸Šç½‘2005\n\nè¿˜åŽŸ20å¹´å‰çš„ä¸­æ–‡äº’è”ç½‘ã€‚ï¼ˆ@wong2 æŠ•ç¨¿ï¼‰\n3ã€Bambot\n\nç½‘å‹å¼€æºçš„ä½Žæˆæœ¬ï¼ˆçº¦2000å…ƒäººæ°‘å¸ï¼‰çš„äººå½¢æœºå™¨äººã€‚ï¼ˆ@timqian æŠ•ç¨¿ï¼‰\n4ã€OpenAPK\n\nè¿™ä¸ªç½‘ç«™æä¾›å¼€æºçš„å®‰å“ App ä¸‹è½½ã€‚\nå›¾ç‰‡\n1ã€æžå…‰æœˆå…¨é£Ÿ\nä¸Šä¸ªæœˆï¼Œä¸€ä¸ªç¾Žå›½æ‘„å½±å¸ˆå‰å¾€é˜¿æ‹‰æ–¯åŠ å·žæ‹æ‘„æžå…‰ã€‚\nä»–æ— æ„ä¸­å‘çŽ°ï¼Œè¿™æ®µæ—¶é—´è¿˜æœ‰æœˆå…¨é£Ÿï¼ŒäºŽæ˜¯æˆåŠŸæ‹åˆ°äº†æžå…‰ä¸­çš„æœˆå…¨é£Ÿã€‚\n\nä¸Šé¢ç…§ç‰‡ä¸­ï¼Œå³ä¸‹è§’çš„çº¢ç‚¹å°±æ˜¯æœˆçƒã€‚\n\næœˆå…¨é£Ÿçš„æ—¶å€™ï¼Œæœˆçƒã€åœ°çƒã€å¤ªé˜³æˆä¸€æ¡ç›´çº¿ï¼Œæœˆçƒè½åœ¨åœ°çƒçš„é˜´å½±é‡Œé¢ï¼Œç…§ä¸åˆ°ç›´æŽ¥çš„å¤ªé˜³å…‰ï¼Œè€Œæ˜¯è¢«åœ°çƒå¤§æ°”å±‚åå°„çš„å¤ªé˜³å…‰ç…§äº®ã€‚\nåœ°çƒåå°„çš„æ˜¯å¤ªé˜³å…‰çš„çº¢å…‰ï¼Œæ‰€ä»¥æœˆå…¨é£Ÿå‘ˆçŽ°çº¢è‰²ï¼Œåˆç§°\"è¡€æœˆ\"ã€‚è¿™å¼ ç»¿è‰²æžå…‰ä¸­çš„\"è¡€æœˆ\"ç…§ç‰‡ï¼Œéžå¸¸éš¾å¾—ã€‚\n2ã€EK215 èˆªç­è·¯çº¿\nåœ°çƒæ˜¯åœ†çš„ï¼Œä½†æ˜¯ä¸–ç•Œåœ°å›¾æ˜¯é‡‡ç”¨\"å¢¨å¡æ‰˜æŠ•å½±æ³•\"ç»˜åˆ¶çš„å¹³é¢åœ°å›¾ï¼Œå®ƒä¼šè®©é«˜çº¬åº¦åœ°åŒºè¢«å¤§å¤§æ‹‰é•¿ï¼Œå˜å½¢ä¸¥é‡ã€‚\né˜¿è”é…‹èˆªç©º EK215 èˆªç­ï¼Œä»Žè¿ªæ‹œé£žå¾€æ´›æ‰çŸ¶ï¼Œä¸‹å›¾æ˜¯å®ƒçš„èˆªçº¿åœ¨åœ°çƒä»ªä¸Šçš„æ ·å­ï¼Œä»¥åŠåœ¨å¹³é¢åœ°å›¾ä¸Šçš„æ ·å­ã€‚\n\nå¯ä»¥çœ‹åˆ°ï¼Œåœ¨åœ°çƒä»ªä¸Šï¼Œè¿™æ¡èˆªçº¿åŸºæœ¬æ˜¯ç›´çš„ï¼Œè·¯çº¿éžå¸¸åˆç†ã€‚\nä½†æ˜¯ï¼Œåœ¨å¹³é¢åœ°å›¾ä¸Šï¼ŒåŒ—æžåœ°åŒºçš„èˆªçº¿è¢«æ‹‰é•¿æˆäº†ä¸€æ¡å·¨å¤§çš„å¼§çº¿ï¼Œè¶Šé è¿‘åŒ—æžï¼Œèˆªçº¿çš„å˜å½¢å°±è¶Šä¸¥é‡ã€‚\næ–‡æ‘˜\n1ã€è€åŠ›æ˜¯ä¸€ç§ä¼˜åŠ¿\näººä»¬å¸¸å¸¸ä½Žä¼°è€åŠ›çš„ä½œç”¨ï¼ŒåªæŠŠå®ƒç†è§£æˆæ¯”åˆ«äººæ›´åŠªåŠ›ã€æ›´æŒä¹…ã€‚\nå®žé™…ä¸Šï¼Œè€åŠ›ä¹Ÿæ˜¯åšå®ˆè‡ªå·±çš„ä»·å€¼è§‚å’Œç›®æ ‡çš„èƒ½åŠ›ï¼Œå³ä½¿åœ¨çœ‹ä¸ŠåŽ»å¾ˆéš¾åšåˆ°çš„æ—¶å€™ï¼Œä¹Ÿä¸æ”¾å¼ƒã€‚\nåœ¨ç¼ºä¹æ˜Žæ˜¾è¿›å±•çš„æƒ…å†µä¸‹ï¼ŒåšæŒåŽ»å®žçŽ°ç›®æ ‡çš„èƒ½åŠ›ï¼Œè¿™å°±æ˜¯è€åŠ›ã€‚\nåœ¨ä¸€ä¸ªå……æ»¡è¯±æƒ‘åˆ†æ•£ä½ æ³¨æ„åŠ›çš„ä¸–ç•Œä¸­ä¿æŒä¸“æ³¨ï¼Œå…‹æœå›°éš¾ï¼Œç»§ç»­å‰è¿›ï¼Œä½ éœ€è¦è€åŠ›ã€‚\nè€åŠ›æ˜¯äººä»¬å¯ä»¥åŸ¹å…»çš„æœ€æœ‰ç”¨çš„å“è´¨ä¹‹ä¸€ã€‚å®ƒæ¯”åŠ›é‡ã€æ™ºåŠ›ã€é€Ÿåº¦ã€é­…åŠ›ç­‰ç‰¹è´¨ï¼Œå…·æœ‰æ›´å¤§çš„é€‚ç”¨æ€§ï¼Œæ—¥å¸¸ç”Ÿæ´»å¾ˆå¤šæ—¶å€™éƒ½èƒ½ç”¨åˆ°ã€‚\næ›´èªæ˜Žçš„äººæŸäº›æ—¶å€™ä¼šè¡¨çŽ°å‡ºè‰²ï¼Œæ¯”ä½ æ›´å¿«åœ°è§£å†³éš¾é¢˜ã€‚ä½†åªè¦å‡­ç€è€åŠ›ï¼Œä½ å¯ä»¥è§£å†³æ›´å¤šçš„é—®é¢˜ã€‚\nè¨€è®º\n1ã€\nå¼€æºè¿åŠ¨çš„äººä»¬å®Œæˆäº†ä¸å¯èƒ½çš„ä»»åŠ¡ã€‚ä»–ä»¬åˆ›é€ äº†æ•´ä¸ªç™¾ç§‘å…¨ä¹¦ã€åœ°çƒä¸Šæœ€æˆåŠŸã€ä½¿ç”¨æœ€å¹¿æ³›çš„æ“ä½œç³»ç»Ÿã€è½¯ä»¶åº“å’Œæ— æ•°åº”ç”¨ç¨‹åºã€‚ä»–ä»¬å¯¹å…¬å…±èµ„æºçš„è´¡çŒ®ç”šè‡³åœ¨ç§‘å¹»å°è¯´ä¸­éƒ½éš¾ä»¥æƒ³è±¡ï¼Œå…¶ä¸­ä¸€äº›ç³»ç»Ÿåº”è¯¥è¢«è§†ä¸ºä¸–ç•Œçš„æ•°å­—å¥‡è¿¹ã€‚\n-- ã€Šè‡ªç”±è½¯ä»¶ä¸ºäº†è°ï¼Ÿã€‹\n2ã€\nä½ çš„åº”ç”¨æœ€å¥½ä¸è¦ä¾èµ–äº‘æœåŠ¡å•†ï¼Œè¦åšåˆ°\"å¯å¼¹å‡º\"ï¼ˆejectableï¼‰ï¼Œå³éšæ—¶å¯ä»¥åˆ‡æ¢åˆ°è‡ªæ‰˜ç®¡çŽ¯å¢ƒã€‚\nä½ çš„åº”ç”¨åº”è¯¥æœ‰ä¸€ä¸ª workspace.zip æ–‡ä»¶ï¼Œé‡Œé¢åŒ…å«äº†å½“å‰çš„æ‰€æœ‰çŠ¶æ€ã€‚åªè¦è½¬ç§»è¿™ä¸ªæ–‡ä»¶ï¼Œå°±å¯ä»¥è¿˜åŽŸå½“å‰çŠ¶æ€ã€‚\n--ã€Šæœ¬åœ°ä¼˜å…ˆä¸”å¯å¼¹å‡ºã€‹\n3ã€\næˆ‘è§è¿‡çš„æœ€å¥½çš„å·¥ç¨‹å¸ˆï¼Œæ˜¯é‚£äº›æ„¿æ„åœ¨å‘¨æœ«èŠ±å‡ ä¸ªå°æ—¶æž„å»ºä¸€ä¸ªçŽ°æœ‰è½¯ä»¶çš„è‡ªå·±ç‰ˆæœ¬çš„äººã€‚\nè¿™å°±æ˜¯ä½ èŽ·å¾—åˆ›æ–°å’Œè¿›æ­¥çš„æ–¹å¼ã€‚å¦‚æžœä½ ä¸äº†è§£ç³»ç»Ÿçš„å·¥ä½œåŽŸç†ï¼Œå°±æ— æ³•æ‰¾åˆ°æ”¹è¿›çš„åœ°æ–¹ã€‚\n-- ã€ŠAI è®©å¼€å‘è€…å˜è ¢ã€‹\n4ã€\nä½¿ç”¨ GitHub Copilot åŽï¼Œæˆ‘å¾—äº†ä¸€ç§å«åš\"Copilot å»¶è¿Ÿ\"çš„ç—…ã€‚è¿™ç§ç—…æŒ‡çš„æ˜¯å·¥ç¨‹å¸ˆåœ¨æ¯æ¬¡æ“ä½œåŽéƒ½ä¼šæš‚åœï¼Œç­‰å¾… AI æç¤ºä»–ä»¬ä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆã€‚\nå¾ˆå¤šå·¥ç¨‹å¸ˆæœ‰äº† AI ä»¥åŽï¼Œå°±åšä¸åˆ°åªé è‡ªå·±äº†ï¼Œè¦é  AI å‘Šè¯‰ä»–ä»¬ä¸‹ä¸€æ­¥ã€‚è¿™ç±»ä¼¼äºŽåˆçº§ç¨‹åºå‘˜åœ¨åˆšå¼€å§‹æ—¶ï¼Œä¾é èµ„æ·±çš„åŒäº‹çš„æŒ‡å¯¼å¼€å±•å·¥ä½œã€‚\n-- ã€ŠAI è®©å¼€å‘è€…å˜è ¢ã€‹\n5ã€\nå¦‚æžœä½ æˆåŠŸäº†ï¼Œè®°ä½ä½ è¦åŽ»å“ªé‡Œï¼Œè®°ä½ä½ æ¥è‡ªå“ªé‡Œï¼Œå¹¶é€‰æ‹©ä½ è¦æˆä¸ºä»€ä¹ˆæ ·çš„äººã€‚\n-- ã€Šäº”å‘¨çš„ç‹¬è‡ªåˆ›ä¸šã€‹\nå¾€å¹´å›žé¡¾\nå·§å¦™çš„ç¯æ³¡é’Ÿï¼ˆ#295ï¼‰\næ‘©å¤©å¤§æ¥¼æ˜¯åäººç±»çš„ï¼ˆ#245ï¼‰\nä½ åšè¿‡ä¸åœ¨ä¹Žç»“æžœçš„é¡¹ç›®å—ï¼Ÿï¼ˆ#195ï¼‰\nå¤§å®¶ä¸å‡ºé—¨ï¼Œç»æµŽæ€Žä¹ˆåŠžï¼Ÿï¼ˆ#145ï¼‰\nï¼ˆå®Œï¼‰\næ–‡æ¡£ä¿¡æ¯\nç‰ˆæƒå£°æ˜Žï¼šè‡ªç”±è½¬è½½-éžå•†ç”¨-éžè¡ç”Ÿ-ä¿æŒç½²åï¼ˆåˆ›æ„å…±äº«3.0è®¸å¯è¯ï¼‰\nå‘è¡¨æ—¥æœŸï¼š 2025å¹´3æœˆ21æ—¥",
    "link": "http://www.ruanyifeng.com/blog/2025/03/weekly-issue-342.html",
    "pubDate": "2025-03-21T00:13:43.000Z",
    "source": "é˜®ä¸€å³°çš„ç½‘ç»œæ—¥å¿—",
    "category": "æŠ€æœ¯åšå®¢"
  },
  {
    "id": "ruanyf",
    "title": "ç§‘æŠ€çˆ±å¥½è€…å‘¨åˆŠï¼ˆç¬¬ 341 æœŸï¼‰ï¼šä½Žä»£ç ç¼–ç¨‹ï¼Œææ€•ä¸ä¼šæˆåŠŸ",
    "description": "è¿™é‡Œè®°å½•æ¯å‘¨å€¼å¾—åˆ†äº«çš„ç§‘æŠ€å†…å®¹ï¼Œå‘¨äº”å‘å¸ƒã€‚\næœ¬æ‚å¿—å¼€æºï¼Œæ¬¢è¿ŽæŠ•ç¨¿ã€‚å¦æœ‰ã€Šè°åœ¨æ‹›äººã€‹æœåŠ¡ï¼Œå‘å¸ƒç¨‹åºå‘˜æ‹›è˜ä¿¡æ¯ã€‚åˆä½œè¯·é‚®ä»¶è”ç³»ï¼ˆyifeng.ruan@gmail.comï¼‰ã€‚\nå°é¢å›¾\n\næˆéƒ½å‡ºçŽ°äº†èŠ±ç”°ç«é”…ï¼Œç«é”…åº—å¼€åœ¨ç››å¼€çš„æ²¹èœèŠ±åœ°é‡Œï¼Œè¿è¥æœŸä¸¤ä¸ªæœˆã€‚ï¼ˆviaï¼‰\nä½Žä»£ç ç¼–ç¨‹ï¼Œææ€•ä¸ä¼šæˆåŠŸ\nè¿™åå‡ å¹´ï¼Œä¸€æ‰¹æ‰¹ç¨‹åºå‘˜å‰ä»†åŽç»§ï¼ŒåŽ»æžä½Žä»£ç ç¼–ç¨‹ï¼ˆåŒ…æ‹¬æ— ä»£ç ç¼–ç¨‹ï¼‰ã€‚å…‰åœ¨æˆ‘èº«è¾¹ï¼Œå°±æœ‰ä¸‰å››æ‰¹ã€‚\n\nä»–ä»¬æžçš„ä½Žä»£ç ç¼–ç¨‹ï¼Œæˆ‘ç†è§£å°±æ˜¯é€šè¿‡å›¾å½¢ç•Œé¢ï¼Œæ‹–æ‹‰å„ç§ç»„ä»¶ï¼Œè‡ªåŠ¨ç”Ÿæˆè½¯ä»¶ UI çš„åº•å±‚ä»£ç ï¼Œå‡å°‘æ‰‹å·¥ç¼–ç ã€‚\n\nè¿™ä¸ªæƒ³æ³•å¾ˆå¥½ï¼Œç¡®å®žå¾ˆå¤šäººéœ€è¦ï¼Œå°¤å…¶ä¸æ‡‚ç¼–ç¨‹çš„äººï¼Œè¿™ç®€ç›´æ˜¯ç”Ÿæˆç¨‹åºçš„å”¯ä¸€å¯ç”¨æ–¹å¼ã€‚\nä½†æ˜¯å¾ˆå¥‡æ€ªï¼Œä»–ä»¬æ— ä¸€ä¾‹å¤–éƒ½å¤±è´¥äº†ï¼Œå¼€å‘å‡ºæ¥çš„ä½Žä»£ç å·¥å…·ï¼Œå¼€å§‹è¿˜æœ‰ä¸€äº›å¥½å¥‡çš„ç”¨æˆ·ï¼Œå¾ˆå¿«å°±ä¸æ¥äº†ï¼Œç”¨æˆ·è¶Šæ¥è¶Šå°‘ï¼ŒåŽæ¥å³ä½¿å¼€æºäº†ï¼Œä¹Ÿæ²¡äººç”¨ã€‚\næ›´å¥‡æ€ªçš„æ˜¯ï¼Œè¿™ä¼¼ä¹Žä¸æ˜¯å¶ç„¶çŽ°è±¡ï¼Œä¸šç•Œæ‰€æœ‰çš„ä½Žä»£ç å·¥å…·å¥½åƒéƒ½ä¸æˆåŠŸï¼Œè‡³å°‘æˆ‘æƒ³ä¸å‡ºæˆåŠŸçš„ä¾‹å­ï¼Œå“ªä¸€ä¸ªå—æ¬¢è¿Žçš„åº”ç”¨ç¨‹åºæ˜¯ç”¨ä½Žä»£ç å·¥å…·ç”Ÿæˆçš„ã€‚\nå®ƒçš„èƒŒåŽæœ‰ä»€ä¹ˆåŽŸå› å—ï¼Ÿæ˜¯å“ªé‡Œæ²¡æœ‰åšå¯¹ï¼Œè¿˜æ˜¯ä½Žä»£ç ç¼–ç¨‹æœ¬èº«å°±ä¸å¯è¡Œï¼Ÿ\næˆ‘ä¸€ç›´æ²¡æœ‰æƒ³é€šè¿™ä¸ªé—®é¢˜ã€‚è™½ç„¶ä¸çœ‹å¥½ï¼Œä½†æ˜¯ä¾ç„¶æŠ±æœ‰ä¸€ä¸å¹»æƒ³ï¼Œä¹Ÿè®¸æŸä¸€å¤©é†’æ¥ï¼Œä½Žä»£ç ç¼–ç¨‹å°±æˆäº†ä¸»æµï¼Œæ— è®ºæ‰‹æœº App è¿˜æ˜¯æ¡Œé¢åº”ç”¨ï¼Œé¼ æ ‡æ‹–å‡ ä¸‹ï¼Œå°±å¯ä»¥ç”Ÿæˆã€‚\n\nç›´åˆ°ä¸Šå‘¨ï¼Œæˆ‘è¯»åˆ°ä¸€ç¯‡æ–‡ç« ã€Šä½Žä»£ç ç¼–ç¨‹å—å›°äºŽå½¢å¼ã€‹ï¼ˆä¸‹å›¾ï¼‰ï¼Œæ‰æç„¶å¤§æ‚Ÿï¼Œä½Žä»£ç ç¼–ç¨‹æœ‰å…ˆå¤©ç¼ºé™·ï¼Œææ€•ä¸ä¼šæˆåŠŸã€‚\n\næ–‡ç« è¯´ï¼Œä¼˜ç§€çš„ä½œå“éƒ½æ˜¯å½¢å¼ï¼ˆformï¼‰å’ŒåŠŸèƒ½ï¼ˆfunctionï¼‰çš„ç»Ÿä¸€ã€‚å½¢å¼å¿…é¡»æœä»ŽåŠŸèƒ½ï¼ŒåŠŸèƒ½å†³å®šäº†å½¢å¼ï¼Œè‹±æ–‡å«åš\"form follows function\"ã€‚\n\nå¯¹äºŽä¼˜ç§€çš„ç¨‹åºå‘˜ï¼Œåªè¦å¼„æ¸…æ¥šäº†åº•å±‚ï¼ŒUIï¼ˆç”¨æˆ·ç•Œé¢ï¼‰å°±ä¼šæ˜¾è€Œæ˜“è§ã€‚\nä½Žä»£ç ç¼–ç¨‹çš„é—®é¢˜åœ¨äºŽï¼Œå®ƒæ˜¯å…ˆæœ‰ UIï¼ˆå½¢å¼ï¼‰ï¼Œå†æœ‰ä»£ç ï¼ˆåŠŸèƒ½ï¼‰ã€‚\nç”¨æˆ·å…ˆæ‹–æ‹‰ç”Ÿæˆ UIï¼Œç³»ç»Ÿå†æ ¹æ® UI ç”Ÿæˆä»£ç ã€‚è¿™æ˜¯æœ¬æœ«å€’ç½®ï¼Œè®©åº•å±‚ä»£ç é€‚é… UIï¼Œæ³¨å®šäº†ä¸¤è€…éƒ½æœ‰é—®é¢˜ï¼šUI æ˜¯ç©ºæƒ³å‡ºæ¥çš„ï¼Œä»£ç ä¸ºäº†é€‚é… UIï¼Œæ³¨å®šå†—ä½™å’Œä½Žæ•ˆã€‚\næ‰€ä»¥ï¼Œä¼˜ç§€çš„è½¯ä»¶ä¸å¯èƒ½ç”¨è¿™ç§æ–¹å¼ç”Ÿæˆï¼Œä½Žä»£ç ç¼–ç¨‹ä¸ä¼šæˆåŠŸã€‚\næˆ‘è®¤ä¸ºï¼Œä»–è¯´çš„å¾ˆæœ‰é“ç†ã€‚ä½Žä»£ç ç¼–ç¨‹è§£å†³ä¸äº†è¿™ä¸ªæ ¹æœ¬ç¼ºé™·ï¼Œé€‚ç”¨åœºæ™¯æœ‰é™ï¼Œå¤§æ¦‚åªé€‚åˆä¸€äº›ç®€å•ä»»åŠ¡ï¼Œæˆ–è€…ç”ŸæˆåŽŸåž‹ï¼Œä¸ä¼šæˆä¸ºä¸»æµå·¥å…·ã€‚ç¨‹åºå‘˜åº”è¯¥è°¨æ…Žå¼€å‘è¿™ç±»å·¥å…·ï¼Œä»˜å‡ºçš„åŠ³åŠ¨å¾ˆå¯èƒ½æ‰“æ°´æ¼‚ã€‚\nå†™åˆ°è¿™é‡Œï¼Œé—®é¢˜å°±æ¥äº†ï¼šAI ç®—ä¸ç®—ä½Žä»£ç ç¼–ç¨‹ï¼ˆæˆ–è€…æ— ä»£ç ç¼–ç¨‹ï¼‰ï¼Ÿå¦‚æžœä½Žä»£ç ç¼–ç¨‹ä¸ä¼šæˆåŠŸï¼Œé‚£ä¹ˆ AI ç¼–ç¨‹ä¼šæˆåŠŸå—ï¼Ÿ\næˆ‘è®¤ä¸ºï¼ŒAI ä¸åŒäºŽä½Žä»£ç ç¼–ç¨‹ã€‚ä½Žä»£ç ç¼–ç¨‹æ˜¯ä½¿ç”¨è€…ç»™å‡º UIï¼Œç³»ç»Ÿæ¥ç”Ÿæˆä»£ç ï¼Œè€Œ AI æ˜¯ç³»ç»ŸåŒæ—¶ç”Ÿæˆ UI å’Œä»£ç ï¼Œç”¨æˆ·åªéœ€è¦è¯´å‡ºéœ€æ±‚å³å¯ã€‚\nè¿™ç§æƒ…å†µä¸‹ï¼Œå½¢å¼ä¸ŽåŠŸèƒ½çš„ç»“åˆï¼Œå®Œå…¨å–å†³äºŽ AI çš„èƒ½åŠ›ã€‚å¦‚æžœæœ‰ä¸€å¤©ï¼ŒAI è§†é¢‘èƒ½å¤ŸæˆåŠŸï¼Œç”»é¢ç¾Žï¼Œæƒ…èŠ‚å¥½ï¼Œé‚£ä¹ˆ AI ç¼–ç¨‹å¤§æ¦‚ä¹Ÿä¼šæˆåŠŸï¼Œç”Ÿæˆå½¢å¼ä¸ŽåŠŸèƒ½ç»Ÿä¸€çš„åº”ç”¨ç¨‹åºã€‚\nå°ç¨‹åºå®¹å™¨ FinClip\nçŽ°åœ¨çš„æ‰‹æœº App æœ‰ä¸€ä¸ªæŠ€æœ¯è¶‹åŠ¿ï¼Œå¤§å®¶æ³¨æ„åˆ°äº†å—ï¼Ÿ\né‚£å°±æ˜¯æ·»åŠ å°ç¨‹åºå®¹å™¨ï¼Œè®©è‡ªå®¶ App èƒ½å¤Ÿè¿è¡Œå…¶ä»–åº”ç”¨ç¨‹åºã€‚\nä¸ä»…å›½å†… App è¿™æ ·åšï¼Œæµ·å¤–çš„ä¸€äº›è¶…çº§ App ä¹Ÿçº·çº·æ•ˆä»¿ï¼Œæ¯”å¦‚ YouTubeã€Telegramã€Lineã€‚\n\nä¸Šå›¾å°±æ˜¯ Youtube åº”ç”¨å†…ç½®çš„\"å°æ¸¸æˆ\"ï¼Œç±»ä¼¼äºŽå¾®ä¿¡å°ç¨‹åºã€‚\nç©¶å…¶åŽŸå› ï¼Œå¤§æ¦‚æ˜¯å› ä¸ºå°ç¨‹åºè¿™ç§æž¶æž„å¾ˆçµæ´»ï¼Œå¯ä»¥æ–¹ä¾¿åœ°æ·»åŠ å’Œæ›´æ–°åŠŸèƒ½ï¼Œæœ‰åˆ©äºŽå½¢æˆå¤–éƒ¨ç”Ÿæ€å’Œå˜çŽ°ã€‚\nä»Šå¤©ï¼Œå°±å‘å¤§å®¶ä»‹ç»ä¸€æ¬¾å›½äº§çš„å°ç¨‹åºå®¹å™¨ FinClipã€‚å¦‚æžœä½ æƒ³ä¸ºè‡ªå·±çš„ App å¼•å…¥å°ç¨‹åºï¼Œå°±ç”¨å¾—åˆ°å®ƒã€‚\nå®ƒæ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å¼€ç®±å³ç”¨çš„å°ç¨‹åºæŠ€æœ¯è§£å†³æ–¹æ¡ˆï¼Œæä¾›çŽ°æˆçš„ SDKï¼Œå°†å°ç¨‹åºè¿è¡ŒçŽ¯å¢ƒåµŒå…¥å®¿ä¸» Appã€‚\næœ‰äº†å®ƒï¼Œä»»ä½•å¼€å‘è€…éƒ½èƒ½åœ¨ iOS / Android / HarmonyOS ç­‰å¹³å°ï¼Œæž„å»ºè‡ªå·±çš„\"å°ç¨‹åºå®‡å®™\"ã€‚ä¸‹å›¾æ˜¯ FinClip ç›®å‰æ”¯æŒçš„å®¿ä¸»å¹³å°ã€‚\n\nå¯ä»¥çœ‹åˆ°ï¼Œé™¤äº†æ‰‹æœºç³»ç»Ÿï¼Œå®ƒè¿˜æ”¯æŒåµŒå…¥æ¡Œé¢åº”ç”¨ã€è½¦æœºåº”ç”¨ã€ç”µè§†åº”ç”¨ç­‰ç­‰ã€‚\næ­¤å¤–ï¼Œå®ƒè¿˜æœ‰ä¸€äº›å¾ˆå¸å¼•äººçš„æŠ€æœ¯ç‰¹æ€§ã€‚\nï¼ˆ1ï¼‰è·¨å¹³å°ç»Ÿä¸€æ€§ã€‚å®ƒç›´æŽ¥å…¼å®¹å¾®ä¿¡/æ”¯ä»˜å®/æŠ–éŸ³å°ç¨‹åºï¼Œå¯ä»¥ä¸€è¡Œä¸æ”¹ï¼Œç›´æŽ¥è®©å¾®ä¿¡å°ç¨‹åºè·‘åœ¨ä½ çš„åº”ç”¨é‡Œé¢ï¼Œæ— éœ€äºŒæ¬¡å¼€å‘ã€‚\nï¼ˆ2ï¼‰æ•æ·å¼€å‘èŒƒå¼ã€‚å®ƒçš„å°ç¨‹åºæ›´æ–°æ— éœ€åº”ç”¨å•†åº—å®¡æ ¸ï¼Œå¯ä»¥å®žçŽ°\"å°æ—¶çº§\"è¿­ä»£ã€‚\nï¼ˆ3ï¼‰å°æ¸¸æˆå¼•æ“Žã€‚è·Ÿå®ƒé…å¥—çš„è¿˜æœ‰ä¸€ä¸ªå°æ¸¸æˆå®žæ—¶å†…å®¹äº’åŠ¨å¼•æ“Ž RealClipï¼Œæä¾›å°æ¸¸æˆè¿è¡ŒçŽ¯å¢ƒã€‚\n\nè¿™ä¸ªå¼•æ“Žé‡ç‚¹é’ˆå¯¹å°æ¸¸æˆçš„æ€§èƒ½å’Œå…¼å®¹æ€§ï¼Œè¿›è¡Œäº†ä¼˜åŒ–ï¼Œé™¤äº†å¾®ä¿¡å°æ¸¸æˆï¼Œè¿˜å…¼å®¹ Unityã€Cocosã€Layaã€Egret Engine ç­‰ä¸»æµå¼•æ“Žå’Œ WebViewã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ— è®ºå“ªç§å¼•æ“Žåˆ¶ä½œçš„å°æ¸¸æˆï¼Œéƒ½èƒ½å¤Ÿç›´æŽ¥è¿è¡Œåœ¨ä½ çš„ App ä¸­ã€‚\nï¼ˆ4ï¼‰é…å¥—å¼€å‘å·¥å…· FinClip Studioã€‚è¿™ä¸ªå·¥å…·èƒ½å°†çŽ°æœ‰çš„å°ç¨‹åº/å°æ¸¸æˆä»£ç ï¼Œä¸€é”®è½¬æ¢æˆç‹¬ç«‹ Appï¼Œåšæˆå¯ç”¨äºŽ iOSã€Android å’Œé¸¿è’™çš„å®‰è£…åŒ…ã€‚\næ€»ä¹‹ï¼Œå¦‚æžœä½ çš„ App æƒ³å¼•å…¥å°ç¨‹åºï¼Œæˆ–è€…ä½ çŽ°æœ‰çš„å°ç¨‹åºéœ€è¦è¿è¡Œåœ¨å…¶ä»–åº”ç”¨ï¼ˆæ‰‹æœºæˆ–æ¡Œé¢ï¼‰ï¼Œé‚£ä¹ˆå°±å¯ä»¥å°è¯• FinClipã€‚\næ¬¢è¿Žè®¿é—® Finclip å®˜ç½‘è¯¦ç»†äº†è§£ï¼Œå…è´¹æ³¨å†Œè¯•ç”¨ã€‚ä»»ä½•é—®é¢˜éƒ½å¯ä»¥åŠ å…¥å®˜æ–¹ç¤¾ç¾¤äº¤æµï¼ˆä¸‹å›¾ï¼‰ã€‚\n\n[æ´»åŠ¨] AI åˆ›æ„æŒ‘æˆ˜èµ›ï¼Œå¼€å§‹æŠ•ç¥¨äº†\nä¸Šå‘¨äº”ï¼Œå‘¨åˆŠå‘å¸ƒäº†æ¶ˆæ¯ã€‚é¦–å±Šå…¨å›½ AI ç¼–ç¨‹å¤§èµ›çš„\"åˆ›æ„èµ›é“\"ï¼Œå¯ä»¥æäº¤ä½œå“äº†ï¼Œä¸ç®¡ä½ ä¼šä¸ä¼šç¼–ç¨‹ï¼Œåªè¦æœ‰ AI åˆ›æ„ï¼Œéƒ½å¯ä»¥å‚èµ›ã€‚\næ¶ˆæ¯å‘å¸ƒåŽï¼Œå¤§å®¶åå“çƒ­çƒˆã€‚æˆ‘ä»Žç»„å§”ä¼šåŒå­¦é‚£é‡Œå¾—çŸ¥ï¼Œå·²ç»æœ‰å‡ ç™¾ä¸ªåˆ›æ„æäº¤äº†ã€‚\n\nä»Žä»Šå¤©ï¼ˆ3æœˆ14æ—¥ï¼‰å¼€å§‹ï¼Œå¤§èµ›è¿›å…¥äº†æŠ•ç¥¨é˜¶æ®µï¼Œæ¬¢è¿Žå¤§å®¶æŠ•ç¥¨ï¼Œè¯„å‡ºæœ€èƒ½æ‰“åŠ¨ä½ çš„åˆ›æ„ã€‚ä¹Ÿè®¸ä½ è¿˜å¯ä»¥ä»Žä¸­å¾—åˆ°çµæ„Ÿï¼Œæ‹¿æ¥è‡ªå·±å®žçŽ°ã€‚\næ‰€æœ‰æŠ•ç¥¨ç”¨æˆ·å‡å¯æŠ½å¥–ï¼Œå¥–å“æœ‰å°å¤œç¯ã€å·¥å¡å¥—ã€æ‰‹æŒé£Žæ‰‡ç­‰ç­‰ã€‚å› ä¸ºæŠ•ç¥¨æ˜¯å½“å¤©æœ‰æ•ˆï¼Œç¬¬äºŒå¤©å¯ä»¥å†æ¬¡æŠ•ç¥¨ï¼Œæ‰€ä»¥æ¯ä¸ªäººæœ‰å¤šæ¬¡æŠ½å¥–æœºä¼šã€‚\nå½“ç„¶ï¼Œå¦‚æžœä½ è¿˜æœ‰åˆ›æ„æ²¡æœ‰æäº¤ï¼ŒçŽ°åœ¨ä¾ç„¶å¯ä»¥æäº¤å‚èµ›ã€‚\nå·²ç»å‚èµ›çš„åŒå­¦ï¼Œä¸è¦å¿˜äº†ä¸ºè‡ªå·±æ‹‰ç¥¨ï¼Œå‘å¸ƒåˆ°ç¤¾äº¤å¹³å°ä¸Šï¼ˆå…¬ä¼—å·/bç«™/å°çº¢ä¹¦/å¾®ä¿¡æœ‹å‹åœˆ/æŠ€æœ¯ç¤¾ç¾¤ï¼‰ï¼Œåˆ†äº«æ¯”èµ›ï¼Œäº‰å–å¤§èµ›èŽ·å¥–ã€‚\nå¤§èµ›è¯¦æƒ…å’Œä½œå“æŠ•ç¥¨ï¼Œå¯ä»¥ç‚¹å‡»è¿™é‡Œï¼Œæˆ–è€…æ‰«æä¸Šæ–¹æµ·æŠ¥ã€‚\nç§‘æŠ€åŠ¨æ€\n1ã€äººå·¥å¿ƒè„\nä¸€ä¸ªæ¾³å¤§åˆ©äºšç”·å­ï¼Œæ¤å…¥äº†ä¸€é¢—äººå·¥å¿ƒè„ï¼ˆä¸‹å›¾ï¼‰ï¼Œå·²ç»æ´»äº†100å¤©ï¼Œå¹¶ä¸”æˆåŠŸå‡ºé™¢ï¼Œåˆ›é€ äº†ä¸–ç•Œçºªå½•ã€‚\n\nè¿™ç›¸å½“äºŽåœ¨èƒ¸è…”æ¤å…¥ä¸€ä¸ªè¡€æ¶²æ³µï¼Œä¸€å¤©24å°æ—¶æŽ¨åŠ¨è¡€æ¶²å¾ªçŽ¯ã€‚\nä»–æ˜¯ç›®å‰ä¸–ç•Œå”¯ä¸€ä¸€ä¸ªå¸¦æœ‰äººå·¥å¿ƒè„çš„äººï¼Œä¹Ÿæ˜¯ä¸–ç•Œç¬¬å…­ä¾‹äººå·¥å¿ƒè„æ¤å…¥ã€‚å‰äº”ä¾‹çš„äººå·¥å¿ƒè„éƒ½åªæ˜¯è¿‡æ¸¡ï¼Œç—…äººåŽæ¥åˆç§»æ¤äº†å…¶ä»–äººçš„å¿ƒè„ã€‚\nå¦‚æžœæœºå™¨å¿ƒè„ä»¥åŽæŠ€æœ¯æˆç†Ÿäº†ï¼Œäººç±»çš„å¯¿å‘½å¯æœ›å¤§å¹…å»¶é•¿ã€‚\n2ã€æ‰‹æœºæ”¹è·¯ç”±å™¨\næ—§æ‰‹æœºæœ‰ä»€ä¹ˆç”¨ï¼Ÿ\nä¸€å®¶æ¯”åˆ©æ—¶å…¬å¸å–å‡ºæ‰‹æœºä¸»æ¿ï¼ŒåŠ ä¸Šç½‘çº¿å£ã€USB å£ï¼Œå°†å…¶æ”¹æˆäº†è·¯ç”±å™¨ã€‚\n\nä¸Šå›¾å·¦ä¾§æ˜¯æ‰‹æœºä¸»æ¿ï¼Œå³ä¾§æ˜¯å°†æ‰‹æœºä¸»æ¿å®‰è£…åœ¨æ‰©å±•æ¿ä¸Šï¼Œä»Žè€Œå½¢æˆè·¯ç”±å™¨ä¸»æ¿ã€‚\næ‰‹æœºçš„ CPUã€è°ƒåˆ¶è§£è°ƒå™¨ã€å†…å­˜ç­‰ï¼Œéƒ½æ˜¯å¯å¤ç”¨çš„ï¼Œå› æ­¤æ”¹è£…è´¹ç”¨å¾ˆä½Žã€‚è€Œä¸”ï¼Œæ‰‹æœºçš„ç¡¬ä»¶é…ç½®å¾ˆé«˜ï¼Œæ€§èƒ½æ¯”é«˜ç«¯è·¯ç”±å™¨å¼ºå¾—å¤šã€‚\n3ã€é™éŸ³å›¾æ ‡\nè‹¹æžœä¸Šå‘¨å‘å¸ƒçš„ MacBook Air M4ï¼Œæ‚„ç„¶æ”¹æŽ‰äº†ä¸€ä¸ª26å¹´ä¹‹ä¹…çš„è®¾è®¡ã€‚\nå®ƒæŠŠç¬”è®°æœ¬çš„é™éŸ³å›¾æ ‡ï¼ˆF10 æŒ‰é’®ä¸Šçš„å›¾æ ‡ï¼‰ï¼Œåœ¨å–‡å­ä¸ŠåŠ äº†ä¸€é“åˆ é™¤çº¿ã€‚\nä¸‹å›¾æ˜¯ä»¥å‰çš„å›¾æ ‡ã€‚\n\nä¸‹å›¾æ˜¯çŽ°åœ¨çš„å›¾æ ‡ã€‚\n\nè¿™ä¹ˆç®€å•çš„ä¸€ä¸ªå›¾æ ‡ï¼Œè‹¹æžœç”¨äº†26å¹´æ‰æ”¹æŽ‰ã€‚\n4ã€æ±½è½¦çš„ç‰©ç†æŒ‰é’®\nå¾·å›½å¤§ä¼—æ±½è½¦å®£å¸ƒï¼Œæœªæ¥å®ƒçš„æ‰€æœ‰è½¦åž‹ï¼Œéƒ½ä¼šåŒæ—¶é…å¤‡è§¦æ‘¸å±å’Œç‰©ç†æŒ‰é’®ã€‚\n\nä¸Šå›¾æ˜¯å¤§ä¼— ID.3 è½¦åž‹çš„æŽ§åˆ¶å°ï¼Œä¸Šæ–¹æ˜¯è§¦æ‘¸å±ï¼Œä¸‹æ–¹éƒ½æ˜¯æŒ‰é’®ã€‚\nè¯¥å…¬å¸è¡¨ç¤ºï¼Œæ±½è½¦ä¸æ˜¯æ‰‹æœºï¼Œä¸èƒ½éƒ½é è§¦æ‘¸å±ï¼Œé‡è¦çš„åŠŸèƒ½å¿…é¡»æœ‰å›ºå®šçš„ä½ç½®å’ŒçœŸå®žçš„è§¦æ„Ÿã€‚\n5ã€å…¶ä»–\nï¼ˆ1ï¼‰ä¸€å®¶è‹±å›½ç”Ÿç‰©å…¬å¸ï¼Œç ”å‘äº†è½¬åŸºå› é¦™è•‰ã€‚è¿™ç§é¦™è•‰å¯ä»¥é•¿æœŸä¿æŒæ–°é²œå’Œé»„è‰²ï¼Œä¸ä¼šå˜è¤å˜é»‘ã€‚\n\nå³ä½¿å‰¥å¼€åŽ12å°æ—¶ï¼Œé¦™è•‰çš®ä¹Ÿä¸å˜è‰²ï¼Œè¿™æ ·æœ‰åˆ©äºŽé¦™è•‰é”€å”®ã€‚\nï¼ˆ2ï¼‰Android 15 å°†æœ‰ä¸€ä¸ªåŽŸç”Ÿçš„ç»ˆç«¯ç¨‹åºï¼Œæä¾›ä¸€ä¸ªåŸºäºŽ Debian çš„ Linux å‘è¡Œç‰ˆä¾›ç”¨æˆ·ä½¿ç”¨ã€‚\n\nè¿™ä¸ªåŠŸèƒ½çš„åº•å±‚æ˜¯è™šæ‹Ÿæœºæœºåˆ¶ï¼Œå®ƒå°†å¤§å¤§æ–¹ä¾¿ç¨‹åºå‘˜ï¼Œå°†å®‰å“æ‰‹æœºå½“ä½œ Linux æ¡Œé¢ç”µè„‘ä½¿ç”¨ã€‚\n\næ–‡ç« \n1ã€AI å¤§æ¨¡åž‹2024å¹´çš„è¿›å±•ï¼ˆè‹±æ–‡ï¼‰\n\nè‘—åç¨‹åºå‘˜ Simon Willison 3æœˆ7æ—¥çš„æ¼”è®²ç¨¿ï¼Œé€šä¿—åœ°ä»‹ç»äº† AI åœ¨è¿‡åŽ»ä¸€å¹´çš„å·¨å¤§é£žè·ƒï¼Œå¾ˆå¥½çš„ç»¼è¿°ã€‚\n2ã€å¦‚ä½•ç”¨ Claude Code åç¼–è¯‘ä»£ç ï¼ˆè‹±æ–‡ï¼‰\n\nä½œè€…æ¼”ç¤ºäº†ä¸€ä¸ªæƒŠäººçš„ä¾‹å­ï¼Œä½¿ç”¨ Anthropic å‘å¸ƒçš„ Claude Codeï¼Œå°† Webpack ç¼–è¯‘å‡ºæ¥çš„æ–‡ä»¶åç¼–è¯‘ï¼Œè¿˜åŽŸæˆæºä»£ç ã€‚\n3ã€CSS è·¨æ–‡æ¡£è§†å›¾è½¬æ¢ï¼ˆè‹±æ–‡ï¼‰\næœ¬æ–‡ä»‹ç»ä¸€ä¸ªç¤ºä¾‹ï¼Œé€šè¿‡ CSS æ–°çš„è·¨æ–‡æ¡£è§†å›¾è½¬æ¢åŠŸèƒ½ï¼Œä½¿å¾—å¤šé¡µé¢åº”ç”¨çš„è·³è½¬ï¼Œä¹Ÿåƒå•é¡µé¢åº”ç”¨ï¼ˆSPAï¼‰ä¸€æ ·æµç•…é¡ºæ»‘ã€‚\n4ã€Cursor ä¸Šä¼  .env æ–‡ä»¶ï¼ˆè‹±æ–‡ï¼‰\n\nCursor æ˜¯çŽ°åœ¨éžå¸¸æµè¡Œçš„ä¸€ä¸ª AI ä»£ç ç¼–è¾‘å™¨ï¼Œå®ƒçš„ç”¨æˆ·è®ºå›çˆ†å‡ºä¸€ä¸ªå¸–å­ï¼Œæœ‰äººå‘çŽ°å®ƒä¼šä¸Šä¼ ç”¨æˆ·çš„ .env æ–‡ä»¶ï¼Œç”±äºŽé‡Œé¢éƒ½æ˜¯çŽ¯å¢ƒå‚æ•°ï¼Œä¼šå¸¦æ¥å®‰å…¨éšæ‚£ã€‚\n5ã€JSON ä¸Ž JavaScript çš„å¯¹è±¡æˆå‘˜é¡ºåºï¼ˆä¸­æ–‡ï¼‰\n\nJSON ä¸Ž JavaScript çš„å¯¹è±¡ï¼Œé‡Œé¢çš„æˆå‘˜é¡ºåºæœ‰æ²¡æœ‰è§„å®šï¼Ÿæœ¬æ–‡æŽ¢è®¨è¿™ä¸ªé—®é¢˜ã€‚\n6ã€Go è¯­è¨€é”™è¯¯å¤„ç†æœºåˆ¶çš„ä¼˜ç‚¹ï¼ˆè‹±æ–‡ï¼‰\n\nGo è¯­è¨€çš„é”™è¯¯å¤„ç†å¾ˆç‰¹åˆ«ï¼Œæ²¡æœ‰ try...catch æœºåˆ¶ï¼Œé”™è¯¯æ˜¯ä¸€ä¸ªå€¼ï¼Œä½œè€…è§£é‡Šè¿™æ ·è®¾è®¡çš„å¥½å¤„ã€‚\nå·¥å…·\n1ã€TypeScript 7\nå¾®è½¯ä½¿ç”¨ Go è¯­è¨€é‡å†™äº† TypeScript ç¼–è¯‘å™¨ tscï¼Œæ®è¯´é€Ÿåº¦å¯ä»¥æé«˜10å€ï¼Œå‚çœ‹ä»‹ç»æ–‡ç« ã€‚\n\nç›®å‰ï¼ŒTypeScript çš„ç‰ˆæœ¬æ˜¯5.8ï¼Œç­‰åˆ°è¿™ä¸ªå·¥å…·ç¨³å®šäº†ï¼Œå°†å‘å¸ƒä¸º TypeScript 7ã€‚\n2ã€QR Code Generator\n\nä¸€ä¸ªç½‘é¡µåº”ç”¨ï¼Œå¯ä»¥å®šåˆ¶äºŒç»´ç çš„é¢œè‰²ã€æ–‘ç‚¹ã€å¾½æ ‡ã€‚\n3ã€WatchYourLAN\n\nä¸€ä¸ªå¼€æºçš„ç½‘é¡µåº”ç”¨ï¼Œç”¨æ¥æ‰«æå±€åŸŸç½‘çš„ IP åˆ†é…ï¼Œå¯ä»¥å‘é€ä¸»æœºä¸Šçº¿å’ŒæŽ‰çº¿çš„é€šçŸ¥ã€‚\n4ã€XPipe\n\nä¸€ä¸ªè·¨å¹³å°çš„æ¡Œé¢åº”ç”¨ï¼Œé€šè¿‡å›¾å½¢ç•Œé¢ï¼Œå°†æ‰€æœ‰çš„æœåŠ¡å™¨è¿žæŽ¥åœ¨ä¸€ä¸ªåœ°æ–¹ç®¡ç†ã€‚\n5ã€TransBridge\n\nä¸€ä¸ªå¼€æºçš„ç¿»è¯‘ API ä»£ç†æœåŠ¡ï¼Œå¯ä»¥æŽ¥å…¥å„ç§å¤§æ¨¡åž‹ï¼Œå¯¹å¤–æä¾›ç¿»è¯‘æœåŠ¡ï¼Œè¯•ç”¨ Demoã€‚ï¼ˆ@fruitbars æŠ•ç¨¿ï¼‰\n6ã€DouYin Downloader\n\nå¼€æºçš„ Python è„šæœ¬ï¼Œç”¨æ¥ä¸‹è½½æŠ–éŸ³çŸ­è§†é¢‘ã€‚ï¼ˆ@jiji262 æŠ•ç¨¿ï¼‰\n7ã€Java Thread Dump\n\nå…è´¹åˆ†æž java thread çš„ç½‘ç«™ï¼Œä¸Šä¼  jstack å¯¼å‡ºçš„çº¿ç¨‹å¿«ç…§æ–‡ä»¶ï¼Œåˆ†æžçº¿ç¨‹æ± å†…çº¿ç¨‹çŠ¶æ€ã€‚ï¼ˆ@HbOrea æŠ•ç¨¿ï¼‰\n8ã€Mono\n\nåˆ¶ä½œå†…å®¹åˆ†äº«å¡ç‰‡çš„å…è´¹ç½‘ç«™ã€‚ï¼ˆ@RiverTwilight æŠ•ç¨¿ï¼‰\n9ã€Telegram Files\n\nå¼€æºçš„ Telegram æ–‡ä»¶ä¸‹è½½å™¨ï¼Œæ”¯æŒå¤šé¢‘é“ã€å¤šè´¦æˆ·åŒæ—¶ä¸‹è½½ã€‚ï¼ˆ@jarvis2f æŠ•ç¨¿ï¼‰\n10ã€Obsidian äº‘ç›˜åŒæ­¥æ’ä»¶\nä¸€ä¸ªå¼€æºçš„ Obsidian æ’ä»¶ï¼Œå°†ç¬”è®°è‡ªåŠ¨åŒæ­¥åˆ°å¤šç§äº‘ç›˜æœåŠ¡ã€‚ï¼ˆ@ai-bytedance æŠ•ç¨¿ï¼‰\nAI ç›¸å…³\n1ã€Mistral OCR\nä¸Šå‘¨ï¼ŒMistral AI å‘å¸ƒäº†å·ç§°å²ä¸Šæœ€å¼ºçš„ OCR è¯†åˆ«å·¥å…·ï¼Œå…·æœ‰å…¬å¼å’Œè¡¨æ ¼çš„è¯†åˆ«èƒ½åŠ›ï¼Œå‚è§ä»‹ç»æ–‡ç« ã€‚\n\nç½‘å‹ monsoonw åšäº†ä¸€ä¸ªå…è´¹çš„è¯•ç”¨ç½‘ç«™ã€‚\n\nè‘—åç¨‹åºå‘˜ Simon Willison å¼€æºäº†ä¸€ä¸ª Python è„šæœ¬ï¼Œæ¼”ç¤ºäº†æ€Žæ ·è°ƒç”¨ Mistral çš„ API è¿›è¡Œæ–‡å­—è¯†åˆ«ï¼Œå‚è€ƒä»–çš„æ–‡ç« ã€‚\n2ã€Free QWQ\n\nå…è´¹ã€æ— é™åˆ¶çš„ç®—åŠ›å¹³å°ï¼Œä¸ºå¼€å‘è€…æä¾› QwQ 32B å¤§è¯­è¨€æ¨¡åž‹ APIã€‚ï¼ˆ@nexmoe æŠ•ç¨¿ï¼‰\n3ã€Code-Review-LLM-Gitlab\n\nä½¿ç”¨å¤§æ¨¡åž‹å¯¹ GitLab é¡¹ç›®è¿›è¡Œ Code review çš„å·¥å…·ã€‚ï¼ˆ@mimo-x æŠ•ç¨¿ï¼‰\n4ã€äººè¯ç¿»è¯‘å™¨\nä¸€ä¸ª Chrome æ’ä»¶ï¼Œé€šè¿‡ AI å°†éš¾æ‡‚çš„ä¸­æ–‡ç¿»è¯‘æˆå¥½æ‡‚çš„ä¸­æ–‡ã€‚ï¼ˆ@DemoJ æŠ•ç¨¿ï¼‰\nèµ„æº\n1ã€è¾°å®‡è½é›ä½“\n\nä¸€ä¸ªå¼€æºçš„ä¸­æ–‡æ‰‹å†™å­—ä½“ã€‚\n2ã€JetBrains Maple Mono\n\nä¸€æ¬¾åˆæˆå­—ä½“ï¼Œè§£å†³ JetBrains Mono æ²¡æœ‰ä¸­æ–‡å­—å½¢çš„ç—›ç‚¹ï¼Œå…¨éƒ¨ç­‰å®½æ— è¡¬çº¿ï¼Œä¸­è‹±æ–‡ 2:1 å®½å¯¹é½ã€‚ï¼ˆ@SpaceTimee æŠ•ç¨¿ï¼‰\n3ã€BeddyStories\n\nä¸€ä¸ªå„¿ç«¥ç¡å‰æ•…äº‹ç½‘ç«™ï¼Œæ”¶é›†äº†å…¨çƒç»å…¸çš„å„¿ç«¥ç¡å‰æ•…äº‹ã€‚ï¼ˆ@yimiqidage æŠ•ç¨¿ï¼‰\n4ã€IP ä¾¦æŽ¢\n\nå…è´¹çš„åœ¨çº¿ IP å½’å±žåœ°æŸ¥è¯¢ã€‚ï¼ˆ@Oliverwqcwrw æŠ•ç¨¿ï¼‰\nå¦æœ‰ä¸€ä¸ª Chrome æ’ä»¶ IP Location Finderï¼Œé€‰ä¸­ IP åœ°å€ï¼Œæ˜¾ç¤ºå½’å±žåœ°ã€‚ï¼ˆ@Yanel85 æŠ•ç¨¿ï¼‰\n\nå›¾ç‰‡\n1ã€çº¢ç»¿è‰²ç›²\nçº¢ç»¿è‰²ç›²çš„æ‚£è€…ï¼Œçœ‹ä¸åˆ°çº¢è‰²å’Œç»¿è‰²ã€‚åœ¨ä»–ä»¬çœ¼é‡Œï¼Œè¿™ä¸¤ç§é¢œè‰²éƒ½ä¼šå˜æˆé»„è‰²ã€‚\nä¸‹é¢æ˜¯ä¸€åŠçº¢ã€ä¸€åŠç»¿çš„æ ‘å¶ã€‚\n\nçº¢ç»¿è‰²ç›²æ‚£è€…çœ‹åˆ°çš„å´æ˜¯ä¸€å¼ é»„è‰²æ ‘å¶ã€‚\n\nå¤§æ¦‚æ¯20ä¸ªäººé‡Œé¢ï¼Œå°±æœ‰ä¸€ä¸ªäººæœ‰è‰²ç›²æˆ–è‰²å¼±é—®é¢˜ã€‚æ‰€ä»¥ï¼Œè®¾è®¡ç•Œé¢çš„æ—¶å€™ï¼Œä½¿ç”¨çº¢è‰²æˆ–ç»¿è‰²å¿…é¡»éžå¸¸è°¨æ…Žï¼Œå› ä¸ºçº¢ç»¿è‰²ç›²æ‚£è€…åˆ†ä¸æ¸…ã€‚\nä¸‹é¢çš„æ—¥åŽ†ä½¿ç”¨ç»¿è‰²å’Œç²‰çº¢è‰²ï¼Œè¡¨ç¤ºç‰¹æ®Šçš„æ—¥æœŸã€‚\n\nä½†æ˜¯ï¼Œçº¢ç»¿è‰²ç›²æ‚£è€…çœ‹åˆ°çš„æ˜¯ä¸‹é¢è¿™æ ·ï¼Œæ ¹æœ¬åˆ†ä¸æ¸…ã€‚\n\nå› æ­¤ï¼Œç”¨æˆ·ç•Œé¢è½»æ˜“ä¸è¦ä½¿ç”¨çº¢è‰²å’Œç»¿è‰²ã€‚\næ–‡æ‘˜\n1ã€å¦‚æžœ AI å’Œæœºå™¨äººæŽ¥ç®¡ä¸€åˆ‡\næˆ‘æœ€è¿‘å¸¸å¸¸æƒ³ä¸€ä¸ªé—®é¢˜ï¼šå¦‚æžœ AI å¼ºå¤§åˆ°æ‰€æœ‰æ–¹é¢éƒ½è¶…è¿‡äººç±»ï¼Œå®ƒå’Œæœºå™¨äººæŽ¥ç®¡ä¸€åˆ‡ï¼Œäººç±»è¦å¹²ä»€ä¹ˆå‘¢ï¼Ÿ\nå‡¯æ–‡Â·å‡¯åˆ©è®¤ä¸ºï¼Œéšç€å·¥ä½œéƒ½äº¤ç»™æœºå™¨äººï¼Œäººç±»å¯ä»¥ä»Žäº‹è¶Šæ¥è¶Šå¤šæœ‰è¶£çš„å·¥ä½œï¼Œå°±åƒå·¥ä¸šé©å‘½åŽä¸€æ ·ã€‚\nè¿™ç§è¯´æ³•åœ¨çŸ­æœŸå†…æœ‰ä¸€å®šé“ç†ï¼Œä½†æ˜¯æœ‰ä¸€ä¸ªå‰æï¼Œå°±æ˜¯äººç±»èƒ½åšè®¡ç®—æœºåšä¸åˆ°çš„äº‹æƒ…ã€‚\næˆ‘è®¤ä¸ºï¼Œæ²¡æœ‰ç†ç”±è®¤ä¸ºè¿™ä¸ªå‰æä¼šæ°¸è¿œæˆç«‹ã€‚\né™¤éžæ”¿åºœå¼ºåˆ¶è§„å®šï¼Œè®¡ç®—æœºä¸å¾—ä»Žäº‹æŸäº›å·¥ä½œï¼Œåªæœ‰äººç±»å¯ä»¥åšã€‚ä½†æ˜¯é‚£æ ·çš„è¯ï¼Œé‚£äº›å·¥ä½œå¾ˆå¯èƒ½å°±ä¼šåœæ»žå‘å±•äº†ã€‚åœæ»žå‘å±•çš„è¡Œä¸šæ²¡æœ‰å‰æ™¯ï¼Œæ”¶å…¥ä¹Ÿä¸ä¼šå¢žé•¿ï¼Œä»Žä¸šè€…éš¾ä»¥æ„Ÿåˆ°æ»¡æ„ã€‚\nè®©æˆ‘ä»¬å‡è®¾ä¸€ç§æžç«¯çš„æƒ…å†µï¼Œå¦‚æžœæœºå™¨å®Œå…¨è¶…è¶Šäººç±»ï¼Œæ¯ä»¶äº‹éƒ½æ¯”äººç±»åšå¾—å¥½ï¼Œå¤§éƒ¨åˆ†äººæ— æ³•ä¸ºç¤¾ä¼šåšå‡ºè´¡çŒ®æ—¶ï¼Œä¸€åˆ‡ä¼šæ€Žæ ·ï¼Ÿ\nå¦‚æžœä¸€ä¸ªäººæ— æ³•ä¸ºç¤¾ä¼šåšå‡ºè´¡çŒ®ï¼Œä¹Ÿå°±å¤±åŽ»äº†ä»–çš„ç»æµŽä»·å€¼ï¼Œå°±ç®—ä»–èƒ½é æ”¿åºœçš„è¡¥åŠ©ç»§ç»­æ´»ç€ï¼Œé‚£ä¹ˆå¯¹äºŽä»–æ¥è¯´ï¼Œä¸ªäººä»·å€¼æ˜¯ä»€ä¹ˆå‘¢ï¼Œå°±æ˜¯æ´»ä¸€å¤©ç®—ä¸€å¤©ï¼Ÿ\nç›®å‰æ¥çœ‹ï¼Œè¿™ä¸ªé—®é¢˜è¿˜æ¯”è¾ƒé¥è¿œï¼Œå°±ç®—é‚£ä¸€å¤©åˆ°æ¥ï¼Œä¹Ÿæ˜¯å¾ˆä¹…ä»¥åŽçš„äº‹æƒ…äº†ã€‚çœ¼ä¸‹æ¯”è¾ƒçŽ°å®žçš„é—®é¢˜æ˜¯ï¼ŒAI æ­£åœ¨å¤§é‡å‡å°‘é«˜è–ªå·¥ä½œã€‚éšç€æœºå™¨çš„èƒ½åŠ›è¶Šæ¥è¶Šå¼ºï¼Œå¾ˆå¤šç™½é¢†å·¥ä½œçš„ä»·å€¼è¿…é€Ÿå˜å°ï¼Œå¤§å¤šæ•°äººè¶Šæ¥è¶Šéš¾æ‰¾åˆ°æŠ¥é…¬ä¸°åŽšã€ä»¤äººæ»¡æ„çš„å·¥ä½œã€‚\nè¿™å°±æ˜¯çŽ°åœ¨å‘ç”Ÿçš„é—®é¢˜ï¼Œé«˜è–ªçš„å·¥ä½œå²—ä½ä¸æ–­å‡å°‘ï¼Œéš¾ä»¥èŽ·å¾—ã€‚\nè¨€è®º\n1ã€\nä»¥å‰çš„çƒç¥¨ã€éŸ³ä¹ä¼šç¥¨ã€æ™¯ç‚¹ç¥¨ã€ç”µå½±ç¥¨éƒ½æ˜¯çº¸è´¨çš„ï¼ŒçŽ°åœ¨å…¨æ”¹æˆæ•°å­—çš„ã€‚\næˆ‘ä»¬çš„è¿‡åŽ»éƒ½ä¿å­˜åœ¨æ‰‹æœºé‡Œï¼Œå†ä¹Ÿæ²¡æœ‰çºªå¿µç‰©äº†ã€‚\n-- å½­åšç¤¾\n2ã€\nè¶Šæ¥è¶Šå¤šçš„åº”ç”¨ç¨‹åºè½¬ç§»åˆ°äº’è”ç½‘ä¸Šï¼Œæ“ä½œç³»ç»Ÿçš„è½¯ä»¶å·®å¼‚å˜å¾—è¶Šæ¥è¶Šä¸é‡è¦ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ M1 èŠ¯ç‰‡å¯¹ Mac çš„æœªæ¥å¦‚æ­¤é‡è¦ã€‚\nè‹¹æžœåº”å½“åˆ©ç”¨è¿™ä¸€æ³¢ AIï¼Œå‘æŒ¥å…¶ç¡¬ä»¶ä¼˜åŠ¿ï¼Œé¼“åŠ±å¼€å‘è€…åœ¨æœ¬åœ°è¿è¡Œ AI æ¨¡åž‹ã€‚\n-- ã€Šè‹¹æžœ AI çš„æ½œåŠ›ã€‹ï¼Œæœ¬æ–‡æŒ‡å‡ºè‹¹æžœèŠ¯ç‰‡å¯ä»¥æœ¬åœ°è¿è¡Œ AI æ¨¡åž‹ï¼Œä¸éœ€è¦ Nvidia æ˜¾å¡ï¼Œè‹¹æžœåº”è¯¥åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œæ‰©å¤§é”€å”®\n3ã€\nè‡ªä»Žæœ‰äº† AIï¼Œæˆ‘å‘çŽ°è‡ªå·±ä¸å†æ‹…å¿ƒé¡¹ç›®å¯¹æˆ‘æ¥è¯´å¤ªå¤§ã€å¤ªå¤æ‚ï¼Œæˆ–è€…é¡¹ç›®ä½¿ç”¨äº†æˆ‘ä¸äº†è§£çš„æŠ€æœ¯æˆ–ç¼–ç¨‹è¯­è¨€ï¼Œä¸€åˆ‡éƒ½å˜å¾—å®¹æ˜“å¾—å¤šã€‚\næˆ‘æ­£åœ¨é‡æ–°å®¡è§†ä¸€äº›æˆ‘æ›¾è®¤ä¸ºå¤ªå¤æ‚æˆ–è¶…å‡ºæˆ‘èƒ½åŠ›èŒƒå›´çš„ä¸šä½™é¡¹ç›®ï¼Œåªè¦æœ‰æ—¶é—´ï¼Œæˆ‘å°±ä¼šåŽ»å°è¯•ã€‚è¿™æ˜¯ä¸€ä¸ªä»¤äººå…´å¥‹çš„æ—¶ä»£ã€‚\n-- ã€Šæœ‰äº† AIï¼Œä½ éœ€è¦æƒ³å¾—æ›´å¤§ã€‹\n4ã€\næˆ‘è®¤ä¸ºï¼Œæ•°å­¦æœ¬è´¨ä¸Šå·²ç»æ²¡æœ‰ä»€ä¹ˆå¥½é—®é¢˜äº†ã€‚è®©å¤§é‡æ•°å­¦å®¶æ„Ÿå…´è¶£çš„é—®é¢˜æ•°é‡æ¯å¹´éƒ½åœ¨å‡å°‘ï¼Œè€Œä¸”å‡ ä¹Žæ‰€å‰©æ— å‡ ã€‚\nçŽ°ä»£æ•°å­¦ç ”ç©¶è¶Šæ¥è¶Šå±€é™äºŽå°‘æ•°äººå¯¹æŸä¸ªç‰¹å®šä¸»é¢˜çš„ç ”ç©¶ï¼Œå³ä½¿æ˜¯ç ”ç©¶ç”Ÿä¹Ÿå¸¸å¸¸è¢«çŽ°ä»£æ•°å­¦é—®é¢˜çš„æžç«¯ä¸“ä¸šæ€§å’Œæ·±å¥¥æ€§æ‰€å›°æ‰°ã€‚\næœªæ¥çš„ç ”ç©¶ç”Ÿä¸åº”å†éœ€è¦è¯æ˜Žä¸€äº›å…¨æ–°çš„ä¸œè¥¿ï¼Œç›¸ååœ°ï¼Œä»–ä»¬çš„ä¸»è¦ç›®æ ‡å¯èƒ½æ˜¯ç®€åŒ–è¿‡åŽ»çš„ç ”ç©¶ç»“æžœã€‚\n-- ã€Šæ•°å­¦å·²ç»æ²¡æœ‰é—®é¢˜äº†ã€‹\nå¾€å¹´å›žé¡¾\nå´–é—¨æµ·æˆ˜çš„æ„Ÿæƒ³ï¼ˆ#294ï¼‰\nå¤§æ•°æ®å·²æ­»ï¼ˆ#244ï¼‰\næ‚²è§‚è€…æ­£ç¡®ï¼Œä¹è§‚è€…æˆåŠŸï¼ˆ#194ï¼‰\næé«˜æ”¶å…¥çš„æ ¹æœ¬é€”å¾„ï¼ˆ#144ï¼‰\nï¼ˆå®Œï¼‰\næ–‡æ¡£ä¿¡æ¯\nç‰ˆæƒå£°æ˜Žï¼šè‡ªç”±è½¬è½½-éžå•†ç”¨-éžè¡ç”Ÿ-ä¿æŒç½²åï¼ˆåˆ›æ„å…±äº«3.0è®¸å¯è¯ï¼‰\nå‘è¡¨æ—¥æœŸï¼š 2025å¹´3æœˆ14æ—¥",
    "link": "http://www.ruanyifeng.com/blog/2025/03/weekly-issue-341.html",
    "pubDate": "2025-03-14T00:08:44.000Z",
    "source": "é˜®ä¸€å³°çš„ç½‘ç»œæ—¥å¿—",
    "category": "æŠ€æœ¯åšå®¢"
  },
  {
    "id": "ruanyf",
    "title": "ç§‘æŠ€çˆ±å¥½è€…å‘¨åˆŠï¼ˆç¬¬ 340 æœŸï¼‰ï¼šæŠ€æœ¯ç‚’ä½œä¸‰åå¹´",
    "description": "è¿™é‡Œè®°å½•æ¯å‘¨å€¼å¾—åˆ†äº«çš„ç§‘æŠ€å†…å®¹ï¼Œå‘¨äº”å‘å¸ƒã€‚\næœ¬æ‚å¿—å¼€æºï¼Œæ¬¢è¿ŽæŠ•ç¨¿ã€‚å¦æœ‰ã€Šè°åœ¨æ‹›äººã€‹æœåŠ¡ï¼Œå‘å¸ƒç¨‹åºå‘˜æ‹›è˜ä¿¡æ¯ã€‚åˆä½œè¯·é‚®ä»¶è”ç³»ï¼ˆyifeng.ruan@gmail.comï¼‰ã€‚\nå°é¢å›¾\n\næˆéƒ½å»ºç­‘å¸ˆåˆ˜å®¶ç¨ï¼Œæœ¬å‘¨èŽ·å¾—å·ç§°\"å»ºç­‘ç•Œè¯ºè´å°”å¥–\"çš„æ™®åˆ©å…¹å…‹å¥–ï¼Œä¸Šå›¾æ˜¯ä»–çš„ä½œå“è‹å·žå¾¡çª‘é‡‘ç –åšç‰©é¦†ã€‚ï¼ˆviaï¼‰\næŠ€æœ¯ç‚’ä½œä¸‰åå¹´\nå¤§å®¶æœ‰æ²¡æœ‰å‘çŽ°ï¼Œæ¯éš”ä¸€æ®µæ—¶é—´ï¼Œåª’ä½“å°±ä¼šå¤§è‚†ç‚’ä½œä¸€ç§æ–°æŠ€æœ¯ï¼Œå®£æ‰¬å®ƒå°†å¯¹äººç±»äº§ç”Ÿå·¨å¤§å½±å“ï¼Œå…¨ç¤¾ä¼šéƒ½åœ¨å…³æ³¨ï¼Œäººäººéƒ½åœ¨è°ˆè®ºã€‚\n\nè¿™ç§ç‚’ä½œå°±æ˜¯å¤§å®¶å¸¸è¯´çš„\"é£Žå£\"å§ã€‚çªç„¶ä¹‹é—´ï¼Œé£Žå°±èµ·æ¥äº†ï¼Œå¦‚æžœæ­£å¥½ç«™åœ¨é£Žå£ï¼ŒçŒªä¹Ÿèƒ½é£žèµ·æ¥ã€‚\nä½ èƒ½ä¸¾å‡ºå¤šå°‘ä¸ªè¿™ç§ç‚’ä½œçš„ä¾‹å­ï¼Ÿ\nä¸€ä¸ªå›½å¤–ç¨‹åºå‘˜æ ¹æ®å›žå¿†ï¼Œåˆ—å‡ºäº†è¿‡åŽ»ä¸‰åå¹´ä¸»è¦çš„å‡ æ¬¡æŠ€æœ¯ç‚’ä½œã€‚\n1998-2001 å¹´ï¼šäº’è”ç½‘ WWW\n1999-2006 å¹´ï¼šJava\n2004-2007 å¹´ï¼šWeb 2.0\n2007-2010ï¼šäº‘è®¡ç®—\n2010-2015ï¼šç¤¾äº¤åª’ä½“\n2012-2015ï¼šç‰©è”ç½‘\n2013-2015ï¼šå¤§æ•°æ®\n2017-2021ï¼šåŒºå—é“¾\n2021 å¹´è‡³ä»Šï¼šäººå·¥æ™ºèƒ½\nå¤§å®¶è§‰å¾—ï¼Œè¿™ä¸ªæ—¶é—´åˆ—è¡¨æ˜¯å¦å‡†ç¡®ï¼Ÿ\n\næˆ‘çš„äº²èº«æ„Ÿå—æ˜¯å·®ä¸å¤šã€‚è¿™æ˜¯ä¸»è¦çš„å‡ æ¬¡æŠ€æœ¯ç‚’ä½œï¼Œè€Œä¸”è¿™äº›æŠ€æœ¯éƒ½æˆåŠŸäº†ï¼Œæ‰€ä»¥ç‚’ä½œçš„æ—¶é—´æ‰ä¼šæŒç»­è¿™ä¹ˆä¹…ï¼Œä¸¤å¹´åˆ°äº”å¹´ï¼Œç„¶åŽè¢«ä¸‹ä¸€ä¸ªçƒ­ç‚¹å–ä»£ã€‚\nå½“ä¸­ï¼Œè¿˜æœ‰è®¸å¤šæ¬¡å°çš„æŠ€æœ¯ç‚’ä½œï¼Œä½†éƒ½æ²¡æœ‰é‚£ä¹ˆæˆåŠŸï¼ŒæŒç»­æ—¶é—´å°±æ²¡æœ‰è¿™ä¹ˆä¹…ï¼Œå¾ˆå¿«é€€æ½®äº†ï¼Œæ¯”å¦‚å…ƒå®‡å®™ã€Web 3ã€AR/VR çœ¼é•œã€3D æ‰“å°ã€è‡ªåŠ¨é©¾é©¶ç­‰ç­‰ã€‚\nä¸€ç§æ–°æŠ€æœ¯èƒ½å¤Ÿå¸¦æ¥å¤§è§„æ¨¡ã€é•¿æ—¶é—´çš„ç‚’ä½œï¼Œæœ‰ä¸€ä¸ªå‰ææ¡ä»¶ï¼Œé‚£å°±æ˜¯å®ƒæœ‰çœŸä¸œè¥¿ï¼Œç¡®å®žèƒ½å¯¹ç¤¾ä¼šç»æµŽå¸¦æ¥éžå¸¸æœ‰æ„Ÿçš„å˜åŒ–ã€‚\nä¸Šé¢åˆ—è¡¨çš„æ¯ä¸€ç§æ–°æŠ€æœ¯ï¼Œç¡®å®žéƒ½æ˜¯å¤§çš„çªç ´ï¼Œæ”¹å˜äº†æŠ€æœ¯æ–¹å‘ï¼Œæ²¡æœ‰ä¸€ä¸ªæ˜¯è™šçš„ã€‚å¦‚æžœå†åŠ ä¸Šæ™ºèƒ½æ‰‹æœºã€çŸ­è§†é¢‘ã€åŠ å¯†è´§å¸ï¼Œå¯èƒ½å°±æŠŠæœ€è¿‘ä¸‰åå¹´å¤§çš„æŠ€æœ¯\"é£Žå£\"éƒ½åŒ…æ‹¬äº†ã€‚\næˆ‘ä»¥å‰æœ‰ä¸€ä¸ªè¯¯åŒºï¼Œçœ‹ä¸èµ·æŠ€æœ¯ç‚’ä½œï¼Œè®¤ä¸ºé‚£åªæ˜¯ä¸€çªèœ‚çš„éŸ³æµªï¼Œè·Ÿå¨±ä¹ç‰ˆçš„æ˜Žæ˜Ÿç‚’ä½œæ²¡ä»€ä¹ˆä¸åŒã€‚\näººåˆ°ä¸­å¹´ï¼Œæˆ‘æ‰æ„è¯†åˆ°ï¼Œè¿™ç§è§‚å¿µå¤§é”™ç‰¹é”™ï¼ŒæŠ€æœ¯ä»Žä¸šè€…åƒä¸‡ä¸èƒ½æœ‰è¿™ç§æƒ³æ³•ã€‚æ¯ä¸€æ¬¡æŠ€æœ¯ç‚’ä½œï¼Œä¸ä»…æ˜¯éŸ³æµªï¼Œæ›´æ˜¯æœºä¼šï¼Œä¼šå¸¦æ¥ç©ºå‰çš„å…³æ³¨ã€ç–¯ç‹‚æ¶Œå…¥çš„èµ„é‡‘ã€ä»¥åŠåˆ‡åˆ‡å®žå®žçš„éœ€æ±‚ã€‚ç‚’ä½œè§„æ¨¡è¶Šå¤§ã€ç¨‹åº¦è¶ŠåŽ‰å®³ï¼Œå¸¦æ¥çš„æœºä¼šå’Œèµ„é‡‘ä¹Ÿå°±è¶Šå¤§ã€‚\næ¯ä¸€æ¬¡å¤§è§„æ¨¡çš„æŠ€æœ¯ç‚’ä½œï¼Œéƒ½ä¼šè¯žç”Ÿä¸€äº›å¿«é€Ÿå¢žé•¿çš„æŒ‡æ ‡å…¬å¸ï¼Œåˆ›é€ å·¨å¤§çš„è´¢å¯Œæ•ˆåº”ã€‚å¦‚æžœä½ æ­£å¥½èº«åœ¨å…¶ä¸­ï¼Œäº‹ä¸šå’Œè´¢å¯Œéƒ½ä¼šéšä¹‹èµ·é£žã€‚\nè®©æˆ‘ä»¬çŽ°å®žä¸€ç‚¹ï¼Œä¸€ä¸ªå·¥ç¨‹å¸ˆæœ€æœ‰æŠ€æœ¯ç”Ÿäº§åŠ›ã€åˆ›é€ åŠ›ã€äº‹ä¸šèµ·é£žçš„æ—¶é—´çª—å£ï¼Œå°±åªæœ‰é‚£ä¹ˆå‡ å¹´ã€‚å¦‚æžœä¸ªäººäº‹ä¸šè¦å¿«é€Ÿèµ·æ¥ã€ä¸ºæœªæ¥é“ºå¥½é“è·¯ï¼Œå…‰æœ‰æŠ€æœ¯è¿˜ä¸å¤Ÿï¼Œè¿˜å¿…é¡»èµ¶ä¸Šè‡³å°‘ä¸€ä¸ªå¤§çš„æŠ€æœ¯é£Žå£ï¼Œç”¨å¤–éƒ¨çš„èµ„é‡‘å’Œéœ€æ±‚æ”¾å¤§ä¸ªäººåŠªåŠ›ã€‚\nå¦åˆ™ï¼Œå•é è‡ªå·±çš„æˆæžœç§¯ç´¯ï¼Œå°±å¤ªæ…¢äº†ï¼Œå¾ˆéš¾å¿«é€Ÿåˆ°è¾¾æ›´é«˜çš„å±‚æ¬¡ï¼Œå¾ˆå¯èƒ½è¾›è¾›è‹¦è‹¦å¹²äº†äºŒåå¹´ï¼Œè¿˜æ˜¯åœ¨åšä¸€äº›åŸºç¡€çš„äº‹æƒ…ã€‚å¦‚æžœå‡ºçŽ°æŠ€æœ¯å‡çº§ï¼Œä½¿å¾—ä½ çš„æŠ€èƒ½è¿‡æ—¶äº†ï¼ŒåŽé¢çš„è·¯å°±éš¾äº†ã€‚æŠ€æœ¯é£Žå£å…¶å®žæ˜¯å®žçŽ°ä¸ªäººé˜¶å±‚é£žè·ƒã€äººç”Ÿç¿»è½¬çš„æœ€å¯è¡Œçš„è·¯å¾„ã€‚\næ‰€ä»¥ï¼Œæ¯ä¸€è½®å¤§çš„æŠ€æœ¯é£Žå£å¹¶ä¸å®Œå…¨æ˜¯ä¸€å“„è€Œä¸Šçš„ç‚’ä½œï¼Œé‡Œé¢åŒ…å«äº†ä¸€äº›çœŸæ­£çš„æœºä¼šï¼Œå€¼å¾—å…³æ³¨å’Œè·Ÿä¸Šã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå‘¨åˆŠæ¯ä¸€æ¬¡éƒ½å¯¹æ–°æŠ€æœ¯å€åŠ å…³æ³¨ã€ç§¯æžè¯„ä»·çš„åŽŸå› ã€‚\nå½“ç„¶ï¼Œèµ¶ä¸ŠæŠ€æœ¯é£Žå£çš„å‰æï¼Œè¿˜æ˜¯è¦æœ‰çœŸæ‰å®žå­¦ï¼Œèƒ½åšå‡ºå®žæ‰“å®žçš„äº§å“ã€‚å¦åˆ™ï¼ŒçœŸé‡åˆ°é£Žå£ï¼Œä½ ä¹Ÿæ— æ³•è„±é¢–è€Œå‡ºï¼Œæ‹¿åˆ°æŠ€æœ¯ç‚’ä½œçš„çº¢åˆ©ã€‚\n[æ´»åŠ¨] AI FOR CODE åˆ›æ„æŒ‘æˆ˜èµ›\nä¸Šå‘¨æåˆ°çš„å…¨å›½ AI ç¼–ç¨‹å¤§èµ›ï¼Œå¤§å®¶è¿˜æœ‰å°è±¡å—ã€‚\nè¿™æ¬¡å¤§èµ›ä¸ºäº†è®©æ›´å¤šäººå‚ä¸Žï¼Œé™¤äº†å¸¸è§„çš„\"åº”ç”¨èµ›é“\"ï¼Œè¿˜ç‰¹åˆ«è®¾ç½®äº†\"åˆ›æ„èµ›é“\"ã€‚\nåªè¦æœ‰åˆ›æ„ï¼Œå°±èƒ½å‚åŠ ï¼Œä¸éœ€è¦å…·ä½“çš„å®žçŽ°ï¼Œå®žçŽ°äº¤ç»™ AIã€‚\n\nåˆ›æ„èµ›é“ä»Žä»Šå¤©ï¼ˆ3æœˆ7æ—¥ï¼‰å¼€å§‹ï¼Œå°±å¯ä»¥æäº¤ä½œå“äº†ï¼Œåˆ°3æœˆ27æ—¥æˆªæ­¢ã€‚\nå¦‚æžœä½ æœ‰æƒ³è®© AI å®žçŽ°çš„åˆ›æ„ï¼ˆç‚¹å­ï¼‰ï¼Œä¸å¦¨å‘å¸ƒåˆ°ä½œå“æäº¤ä¸“åŒºã€‚å‘å¸ƒæ—¶ï¼Œéœ€è¦æŒ‰ç…§æ¨¡ç‰ˆè¦æ±‚æäº¤ã€‚\næ³¨æ„ï¼Œå‘å¸ƒçš„åˆ›æ„éœ€è¦å…¬å¼€å¯è§ï¼Œè¿™æ ·æ‰èƒ½è®©å¤§å®¶æŠ•ç¥¨ã€‚å¾—ç¥¨é«˜çš„åˆ›æ„ï¼Œå°†æœ‰ä¸°å¯Œçš„å¥–å“ã€‚\næ¯ä¸ªäººæœ€å¤šæäº¤5ä¸ªåˆ›æ„ã€‚å¦‚æœ‰å›¢é˜Ÿä½¿ç”¨ä½ çš„åˆ›æ„å®Œæˆé¡¹ç›®å¼€å‘ï¼Œä½ å°†èŽ·å¾—ç¥žç§˜å¤§ç¤¼ï¼\nä¸è¦é”™è¿‡æœ¬æ¬¡å¤§èµ›ï¼Œåªè¦ä½ æœ‰æƒ³æ³•ï¼Œå°±æœ‰æœºä¼šå¾—å¥–ã€‚æäº¤åˆ›æ„å’ŒæŠ•ç¥¨çš„è¯¦ç»†ä»‹ç»ï¼Œå¯ä»¥ç‚¹å‡»è¿™é‡Œï¼Œæˆ–è€…æ‰«æä¸Šé¢æµ·æŠ¥çš„äºŒç»´ç ã€‚\nä¿®å¤å£ç”»çš„æ–°æ–¹æ³•\næ„å¤§åˆ©å¸•å¤šç“¦æ•™å ‚ï¼Œæ›¾ç»æœ‰ä¸€å¹…å·¨å¤§çš„ä¸­ä¸–çºªå£ç”»ï¼Œéžå¸¸ç²¾ç¾Žã€‚\n\nä½†æ˜¯ï¼Œè¿™å¹…å£ç”»åœ¨1944å¹´çš„ç¬¬äºŒæ¬¡ä¸–ç•Œå¤§æˆ˜è¢«ç‚¸æ¯ã€‚\nä¸‹é¢æ˜¯å£ç”»çš„è™šæ‹Ÿé‡å»ºå›¾ï¼ˆå±€éƒ¨ï¼‰ã€‚\n\nå£ç”»è¢«ç‚¸æ¯æ—¶ï¼Œäººä»¬æŠŠå¢™å£çš„ç¢Žç‰‡æ”¶é›†èµ·æ¥ï¼Œä¸€å…±æœ‰88000å¤šå—ï¼Œå­˜æ”¾åœ¨åšç‰©é¦†ã€‚\nä¸‹é¢æ˜¯ç¢Žç‰‡çš„ç…§ç‰‡ï¼Œè¿™äº›ç¢Žç‰‡å¤§æ¦‚åªå åŽŸå§‹å£ç”»çš„10%ã€‚\n\nç¢Žç‰‡çš„æ•°é‡å¤ªå¤§ï¼Œç¼ºå¤±åˆå¤ªå¤šï¼Œä»Žæ¥æ²¡äººæ•¢äºŽå°è¯•å°†å®ƒä»¬è¿˜åŽŸã€‚\nä½†æ˜¯ï¼Œ1992å¹´çš„æ—¶å€™ï¼Œåšç‰©é¦†æ›¾ç»å°†æ‰€æœ‰ç¢Žç‰‡æ‹æˆäº†æ•°ç ç…§ç‰‡ã€‚\næ…•å°¼é»‘å·¥ä¸šå¤§å­¦çš„æ•°å­¦æ•™æŽˆé©¬è¥¿èŽ«Â·ç¦çº³è¥¿è€¶ï¼ˆMassimo Fornasierï¼‰å¾—çŸ¥äº†è¿™ä»¶äº‹ï¼Œå†³å®šåŸºäºŽè¿™äº›æ•°ç ç…§ç‰‡ï¼Œä½¿ç”¨è®¡ç®—æœºè¿›è¡Œå£ç”»è¿˜åŽŸã€‚\nè¿™å¹…å£ç”»åœ¨æˆ˜å‰ï¼Œæ›¾ç»æœ‰è¿‡ä¸€å¼ é»‘ç™½ç…§ç‰‡ï¼ˆä¸‹å›¾ï¼‰ï¼Œå¯ä»¥ä½œä¸ºä¿®å¤çš„ä¾æ®ã€‚\n\né©¬è¥¿èŽ«æ•™æŽˆçš„ç¬¬ä¸€æ­¥ï¼Œæ˜¯å°†è¿™å¼ ç…§ç‰‡ä¸Šè‰²ï¼Œè¿˜åŽŸæˆå½©è‰²ç…§ç‰‡ã€‚\n\nç„¶åŽï¼Œå°†ç¢Žç‰‡è¿›è¡Œå›¾åƒå»åˆï¼Œä¸€å—å—æ‰¾åˆ°å®ƒä»¬çš„ä½ç½®ï¼ˆä¸‹å›¾ï¼‰ã€‚\n\nä¸‹é¢æ˜¯ç¢Žç‰‡ä¸Šå¢™çš„æ ·å­ã€‚\n\nç¼ºå¤±çš„éƒ¨åˆ†ï¼Œå›¢é˜Ÿç”¨ç°ç™½é¢œè‰²è¡¥å…¨ã€‚\n\nå…¨å½©çš„è™šæ‹Ÿæ•ˆæžœå›¾å¦‚ä¸‹ã€‚\n\nç§‘æŠ€åŠ¨æ€\n1ã€ç¾Žå›½è¤ç«è™«èˆªå¤©å…¬å¸çš„\"è“è‰²å¹½çµ\"ç™»é™†å™¨ï¼ŒæˆåŠŸç™»é™†æœˆçƒï¼Œæˆä¸ºç¬¬ä¸€å®¶ç™»é™†æœˆçƒçš„æ°‘è¥ä¼ä¸šã€‚\n\n2ã€ä¸€å®¶ç¾Žå›½ç”Ÿç‰©æŠ€æœ¯å…¬å¸ï¼Œæ”¹é€ äº†è€é¼ çš„æ¯›å‘åŸºå› ï¼ŒæˆåŠŸåŸ¹å…»å‡ºäº†é•¿æ¯›é¼ ã€‚\n\n\nä»–ä»¬ä¸‹ä¸€æ­¥çš„ç›®æ ‡ï¼Œæ˜¯åŸ¹è‚²é•¿æ¯›è±¡ã€‚\n3ã€æœ¬ç”°å…¬å¸æŽ¨å‡ºä¸€æ¬¾å£è¢‹å¦–æ€ªæ‘©æ‰˜è½¦ï¼Œå¤–å½¢éžå¸¸æƒŠè‰³ï¼ˆä¸‹å›¾ï¼‰ã€‚\n\n4ã€è”æƒ³æŽ¨å‡ºä¸€æ¬¾å¤ªé˜³èƒ½ç¬”è®°æœ¬ï¼Œä¸Šç›–è¦†ç›–äº†å¤ªé˜³èƒ½ç”µæ± ã€‚\n\næ®è¯´é˜³å…‰ä¸‹æ”¾20åˆ†é’Ÿï¼Œå¯ä»¥æ’­æ”¾è§†é¢‘1å°æ—¶ã€‚ä½†æ˜¯æ€Žä¹ˆçœ‹ï¼Œéƒ½ä¸å¦‚å¤–æŽ¥ä¸€ä¸ªå¤ªé˜³èƒ½å‘ç”µæ¿å®žç”¨ã€‚\n5ã€å¾®è½¯å°†åœ¨ä»Šå¹´5æœˆå…³é—­é€šä¿¡æœåŠ¡ Skypeï¼Œç”± Teams æ›¿ä»£ã€‚æ™ºèƒ½æ‰‹æœºå‡ºçŽ°ä¹‹å‰ï¼ŒSkype æ˜¯æœ€æµè¡Œçš„å›½é™…ç”µè¯è½¯ä»¶ã€‚\n\næ–‡ç« \n1ã€æµå¼ HTMLï¼ˆè‹±æ–‡ï¼‰\n\nAI çš„èŠå¤©å¯¹è¯éƒ½æ˜¯æµå¼åŠ è½½çš„ï¼Œæœ¬æ–‡ä»‹ç»ä¸€ä¸ªæŠ€å·§ï¼Œä¸ä½¿ç”¨ JS ä¹Ÿèƒ½åŠ è½½æµå¼å†…å®¹ã€‚\n2ã€ä¸è¦ç”¨ TypeScript æžšä¸¾ï¼ˆè‹±æ–‡ï¼‰\n\nTypeScript å®˜æ–¹å·²ç»ä¸å»ºè®®ä½¿ç”¨ enumï¼ˆæžšä¸¾ï¼‰è¯­æ³•ï¼Œä½œè€…å»ºè®®æ”¹ç”¨å­—ç¬¦ä¸²çš„è”åˆç±»åž‹ä»£æ›¿ã€‚\n3ã€æˆ‘å¦‚ä½•ä½¿ç”¨ roboscribe éŸ³é¢‘è½¬æ–‡æœ¬ï¼ˆè‹±æ–‡ï¼‰\n\nä¸€ç¯‡æ•™ç¨‹ï¼Œä½œè€…ä½¿ç”¨è½¯ä»¶ roboscribe å°†æ’­å®¢è½¬æˆå¯ç”¨çš„æ–‡æœ¬ï¼Œè¿™äº‹è¦æ¯”å¬ä¸ŠåŽ»éº»çƒ¦ã€‚\n4ã€å¦‚ä½•æµ‹è¯•ç”µæ¢¯ï¼ˆä¸­æ–‡ï¼‰\n\næœ¬æ–‡å°†ç”µæ¢¯æŠ½è±¡æˆä¸€ä¸ª\"æœ‰é™çŠ¶æ€æœº\"ï¼Œè®¾è®¡æµ‹è¯•ç”¨ä¾‹ã€‚ï¼ˆ@lezhi12 æŠ•ç¨¿ï¼‰\n5ã€æˆ‘ä¸ºä»€ä¹ˆé€‰æ‹© Firefoxï¼ˆè‹±æ–‡ï¼‰\n\nä½œè€…ä»‹ç» Firefox æµè§ˆå™¨èƒœè¿‡ Chrome çš„å‡ ä¸ªåœ°æ–¹ï¼Œæœ‰äº›åŠŸèƒ½å¤§å®¶å¯èƒ½æœªå¿…çŸ¥é“ã€‚\n6ã€è„šæœ¬ä»£æ›¿åˆ«åï¼ˆè‹±æ–‡ï¼‰\n\nå¸¸ç”¨çš„ç»ˆç«¯å‘½ä»¤ï¼Œå¾€å¾€å¯ä»¥è®¾ç½®åˆ«åï¼ˆaliasï¼‰ä½œä¸ºå¿«æ·æ–¹å¼ï¼Œä½œè€…æå‡ºä¸€ç§æ–°çš„æ–¹å¼ï¼Œç”¨è„šæœ¬ä»£æ›¿åˆ«åï¼Œæ›´å®¹æ˜“ç»´æŠ¤ã€‚\n7ã€Tailscale å¯¹æˆ‘å¾ˆæœ‰ç”¨ï¼ˆè‹±æ–‡ï¼‰\n\nä½œè€…ä»‹ç»è‡ªå·±çš„ Tailscale ç”¨æ³•ï¼Œå°†ä¸åŒçš„è®¾å¤‡ç»„æˆä¸€ä¸ªè™šæ‹Ÿå±€åŸŸç½‘ã€‚\nå·¥å…·\n1ã€Yaak\n\nä¸€ä¸ªæµ‹è¯• API çš„å¼€æºæ¡Œé¢è½¯ä»¶ï¼ŒåŠŸèƒ½æ¯”è¾ƒå…¨ã€‚\n2ã€cleanmac\næ¸…ç† macOS ç³»ç»Ÿçš„ä¸€ä¸ªå‘½ä»¤è¡Œè„šæœ¬ã€‚\n3ã€Lynx\n\nå­—èŠ‚å¼€æºçš„ä¸€æ¬¾è·¨å¹³å°åŽŸç”Ÿåº”ç”¨å¼€å‘å·¥å…·ï¼Œä½¿ç”¨ Web è¯­æ³•ï¼Œç”Ÿæˆå„ä¸ªå¹³å°çš„åŽŸç”Ÿåº”ç”¨ï¼Œç±»ä¼¼äºŽ React Nativeã€‚\n4ã€appstat\n\nç›‘æŽ§ Windows åº”ç”¨çš„èµ„æºå ç”¨ï¼ˆå†…å­˜ã€CPUã€ç½‘ç»œï¼‰çš„ä¸€æ¬¾å·¥å…·ã€‚\n5ã€Maestro\n\nä¸€ä¸ª Web å’Œ æ‰‹æœºçš„ UI æµ‹è¯•å·¥å…·ï¼Œåªè¦å†™å¥½é…ç½®æ–‡ä»¶ï¼Œå°±èƒ½è‡ªåŠ¨è¿è¡Œæµ‹è¯•ã€‚\n6ã€Git Worktree Manager\n\nVS Code æ’ä»¶ï¼Œæ–¹ä¾¿åœ¨ä¸åŒçš„ Git ä»“åº“ã€ä¸åŒçš„åˆ†æ”¯ä¹‹é—´åˆ‡æ¢ã€‚ï¼ˆ@jackiotyu æŠ•ç¨¿ï¼‰\n7ã€Hugo Translator\nä¸€ä¸ª Python è„šæœ¬ï¼Œå°† markdown æ ¼å¼çš„ä¸­æ–‡ Hugo åšå®¢å¸–å­ï¼Œç¿»è¯‘æˆè‹±æ–‡ã€‚ï¼ˆ@Rico00121 æŠ•ç¨¿ï¼‰\n8ã€O-Spy\n\nä¸€ä¸ª Web åº”ç”¨çš„è®°å½•å¹¶å›žæ”¾ç”¨æˆ·æ“ä½œçš„å·¥å…·ï¼Œç”¨æ¥è¿œç¨‹è°ƒè¯•ã€‚ï¼ˆ@wqcstrong æŠ•ç¨¿ï¼‰\n9ã€MTranServer\n\nå¼€æºçš„ç¦»çº¿ç¿»è¯‘æœåŠ¡å™¨ï¼Œå·ç§°èµ„æºæ¶ˆè€—ä½Žï¼ŒCPU + 1G å†…å­˜å³å¯è¿è¡Œï¼Œæ”¯æŒè°ƒç”¨æ²‰æµ¸å¼ç¿»è¯‘ã€‚ï¼ˆ@xxnuo æŠ•ç¨¿ï¼‰\n10ã€Screen Sharing Application\n\nä¸€ä¸ªå¼€æºçš„ Next.js åº”ç”¨ï¼Œé€šè¿‡ç‚¹å¯¹ç‚¹é€šä¿¡ï¼Œå®žæ—¶åˆ†äº«ä½ çš„å±å¹•ã€‚å®ƒä¼šç”Ÿæˆä¸€ä¸ªæˆ¿é—´ç ï¼Œå…¶ä»–äººè®¿é—®è¿™ä¸ªæˆ¿é—´ï¼Œå°±èƒ½çœ‹åˆ°ä½ çš„å±å¹•ã€‚\nAI ç›¸å…³\n1ã€olmOCR\n\nä¸€ä¸ªä½¿ç”¨ AI æ¨¡åž‹è¿›è¡Œæ–‡å­—è¯†åˆ«ï¼ˆOCRï¼‰çš„ Python å·¥å…·ã€‚\n2ã€Probly\n\nä¸€ä¸ªåŸºäºŽ AI çš„ç”µå­è¡¨æ ¼è½¯ä»¶ï¼Œå¯ä»¥åœ¨æµè§ˆå™¨ä¸­å¯¹è¡¨æ ¼è¿è¡Œ Python ä»£ç ã€‚\n3ã€Hacker News æ¯æ—¥æ’­æŠ¥\n\næ¯å¤©è‡ªåŠ¨æŠ“å– Hacker News çƒ­é—¨æ–‡ç« ï¼Œé€šè¿‡ AI ç”Ÿæˆä¸­æ–‡æ’­å®¢ã€‚ï¼ˆ@Y024 æŠ•ç¨¿ï¼‰\n4ã€è¯­æž\n\nåŸºäºŽå¤§æ¨¡åž‹ï¼Œè¿›è¡ŒçŸ¥è¯†åº“ç®¡ç†ä¸Žç”ŸæˆçŸ¥è¯†å›¾è°±çš„å·¥å…·ã€‚ï¼ˆ@xerrors æŠ•ç¨¿ï¼‰\n5ã€DiffRhythm\n\nè¥¿åŒ—å·¥ä¸šå¤§å­¦ ASLP å®žéªŒå®¤å¼€å‘çš„ä¸€ä¸ª AI éŸ³ä¹ç”Ÿæˆæ¨¡åž‹ã€‚ï¼ˆ@JoeDeanx æŠ•ç¨¿ï¼‰\nèµ„æº\n1ã€Meta çš„ AI Demo\n\nMeta å…¬å¸çš„ AI å®žéªŒå®¤ï¼Œå±•ç¤ºæœ€æ–°çš„æˆæžœã€‚\n2ã€ProWords\n\nä¸€ä¸ªåŸºäºŽ AI çš„å•è¯è®°å¿†å¹³å°ï¼Œæ ¹æ®èŒä¸šèº«ä»½ç”Ÿæˆä¾‹å¥ï¼Œä»£ç å¼€æºã€‚ï¼ˆ@winterfx æŠ•ç¨¿ï¼‰\n3ã€åœ£å½¼å¾—å¤§æ•™å ‚ 3D å¯¼è§ˆ\n\næ¢µè’‚å†ˆçš„åœ£å½¼ç‰¹å¤§æ•™å ‚ï¼ˆSt. Peter's Basilicaï¼‰æ˜¯ä¸–ç•Œæœ€å¤§æ•™å ‚ï¼Œè¿™ä¸ªç½‘ç«™æä¾›å®ƒçš„ 3D æ¨¡åž‹è¿˜åŽŸã€‚\n4ã€Shapecatcher\n\nè¿™ä¸ªç½‘ç«™æ ¹æ®ä½ ç”»å‡ºçš„å½¢çŠ¶ï¼Œè¿”å›žåŒ¹é…çš„ Unicode å­—ç¬¦ï¼ŒåŒ…æ‹¬ Emoji å­—ç¬¦å’Œä¸œäºšæ–‡å­—ã€‚\nå›¾ç‰‡\n1ã€å¥¥ä¹é½çš„æ¡å½¢ç \nå¥¥ä¹é½ï¼ˆAldiï¼‰æ˜¯ä¸€å®¶å¾·å›½è¿žé”è¶…å¸‚ï¼Œä¸ºäº†æ–¹ä¾¿ç”¨æˆ·æ‰«ææ¡å½¢ç ï¼ŒæŠŠæ¡å½¢ç å°åˆ·å¾—ç‰¹åˆ«é•¿ã€‚\n\nå°åŒ…è£…å•†å“æ— æ³•æ”¾ç½®é‚£ä¹ˆé•¿çš„æ¡å½¢ç ï¼Œå¥¥ä¹é½å°±ä¼šè®¾æ³•æ”¾ç½®å¤šä¸ªæ¡å½¢ç ã€‚\n\nä¸Šå›¾çš„å¥¶é…ªé€šå¿ƒç²‰ï¼Œåœ¨ä¾§é¢å’Œåº•éƒ¨éƒ½æœ‰æ¡å½¢ç ã€‚\n2ã€ä¹é«˜æ—¥å¿ƒä»ª\nå›½å¤–ç½‘å‹ä½¿ç”¨ä¹é«˜ç§¯æœ¨ï¼Œæ­å»ºäº†ä¸€ä¸ªå¯ä»¥è½¬åŠ¨çš„æ—¥å¿ƒä»ªã€‚\n\nä¸Šå›¾ä¸­ï¼Œä¸­é—´é»„è‰²çš„æ˜¯å¤ªé˜³ï¼Œåœ°çƒå›´ç»•å¤ªé˜³å…¬è½¬ï¼Œå¹¶ä¸”æœ‰22.5Â°çš„å€¾æ–œè§’ã€‚\n\nåœ°çƒçš„æ—è¾¹è¿˜æœ‰æœˆäº®ã€‚æœˆäº®å…¶å®žæœ‰5.15Â°å€¾è§’ï¼Œä½†æ˜¯è‚‰çœ¼ä¸å®¹æ˜“å¯Ÿè§‰ã€‚\n\nå®ƒæ˜¯å¯ä»¥å®žé™…è¿è½¬çš„ï¼Œå†…éƒ¨ç»“æž„å¾ˆå¤æ‚ï¼Œæœ‰å¤§é‡é½¿è½®ã€‚\n\n\næ–‡æ‘˜\n1ã€é«˜ç®¡ä¸Žæ™®é€šå‘˜å·¥çš„è„±èŠ‚\nä½œè€…ï¼šä¼Šæ£®Â·åŸƒæ–‡æ–¯ï¼ˆEthan Evansï¼‰\næˆ‘æ˜¯å·²ç»é€€ä¼‘çš„äºšé©¬é€Šå‰¯æ€»è£ï¼Œåœ¨äºšé©¬é€Šå¾…äº†è¶…è¿‡15å¹´ï¼Œé¢†å¯¼è¿‡800å¤šäººçš„å›½é™…å›¢é˜Ÿã€‚\næˆ‘ä»»èŒæœŸé—´ï¼Œäºšé©¬é€Šè‚¡ç¥¨æ¶¨å¹…é«˜è¾¾9082%ï¼Œå› æ­¤æˆ‘å¯¹æ™®é€šäººçš„è®¸å¤šç”Ÿæ´»å›°å¢ƒå¹¶ä¸äº†è§£ã€‚æ¯”æˆ‘æ›´é«˜çº§çš„å‰¯æ€»è£å’Œé¦–å¸­æ‰§è¡Œå®˜ï¼Œå°±æ›´æ˜¯å¦‚æ­¤äº†ã€‚è°ˆè®ºè‡ªå·±çš„è´¢å¯Œæ˜¯å¤§å¤šæ•°é«˜ç®¡éƒ½é¿è€Œä¸è°ˆçš„ç¦å¿Œè¯é¢˜ã€‚\nä»Šå¤©æˆ‘æƒ³è°ˆè°ˆä¸€ä¸ªå°é—®é¢˜ï¼Œå…ˆä»‹ç»ä¸€ä¸‹æˆ‘è‡ªå·±çš„æƒ…å†µï¼Œå°±ä¸¾å››ç‚¹ï¼š1) æˆ‘æ²¡æœ‰ä»»ä½•æŠµæŠ¼è´·æ¬¾ï¼Œ2) æ¯ä¸¤å‘¨æœ‰ä¸€ä¸ªå¥³ä½£ä¸ºæˆ‘æ‰“æ‰«ä¸€æ¬¡ä½å®…ï¼Œ3) æˆ‘ä»˜é’±è¯·åˆ«äººå¸®æˆ‘çš„èŠ±å›­å‰²è‰ï¼Œ 4) æˆ‘50å²å°±é€€ä¼‘äº†ã€‚\næ™®é€šå®¶åº­ï¼Œå³ä½¿æ˜¯å·¥ç¨‹å¸ˆå’ŒçŸ¥è¯†åˆ†å­ï¼Œä¹Ÿæ²¡æœ‰è¿™äº›ç¦åˆ©ã€‚\nåœ¨æˆ‘ä¸Šé¢çš„é«˜ç®¡ï¼Œäº«æœ‰çš„ç¦åˆ©å°±æ›´å¤šäº†ï¼Œæˆ‘çœ‹åˆ°çš„å°±æœ‰ï¼š1) æœ‰ä¸“é—¨çš„åº¦å‡å±‹ï¼Œé›‡äº†å¤šä¸ªå·¥ä½œäººå‘˜é•¿æœŸçœ‹å®ˆï¼›2) ç§äººé£žæœºï¼›3) ç§äººåŠ©ç†ï¼Œä¸ç”¨è‡ªå·±ä»˜è´¦å•ã€ä¹°æ‚è´§æˆ–æŽ¥å­©å­ï¼ŒåŠ©ç†å¤„ç†ä¸€åˆ‡ï¼›4ï¼‰ç§äººå¸æœºï¼›5ï¼‰å­©å­ä¸Šè´µå¾—æƒŠäººçš„ç§ç«‹å­¦æ ¡ï¼›6ï¼‰ä»–ä»¬æƒ³ä½å“ªå„¿å°±ä½å“ªå„¿ã€‚\nç»æµŽæˆæœ¬ä»Žæ¥ä¸æ˜¯è¿™ä¸€ç±»äººçš„éšœç¢ã€‚\nçŽ°åœ¨è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ï¼Œè¯´æ˜Žé«˜ç®¡ä¸Žå‘˜å·¥æ˜¯å¦‚ä½•è„±èŠ‚çš„ï¼šç»“æŸè¿œç¨‹å·¥ä½œï¼Œé‡è¿”åŠžå…¬å®¤ã€‚\né«˜ç®¡çš„è´¢å¯Œä½¿ä»–ä»¬æœ‰ä¸åŒçš„é€‰æ‹©ã€‚å¤§å¤šæ•°é«˜ç®¡æŠŠå·¥ä½œå’ŒèŒä¸šæˆåŠŸæ”¾åœ¨ç”Ÿæ´»çš„é¦–ä½ã€‚å¦‚æžœä»–ä»¬ä¸è¿™æ ·åšï¼Œä»–ä»¬å¾ˆå°‘èƒ½æˆä¸ºé«˜ç®¡ã€‚ä»–ä»¬ä¸­çš„å¤§å¤šæ•°äººï¼ˆåŒ…æ‹¬æˆ‘è‡ªå·±ï¼‰ï¼Œåˆ©ç”¨è´¢å¯Œä¸ºè‡ªå·±è´­ä¹°æ—¶é—´ã€‚ä»–ä»¬å¤§éƒ¨åˆ†æ—¶é—´éƒ½èŠ±åœ¨å·¥ä½œä¸Šï¼Œå°éƒ¨åˆ†æ—¶é—´èŠ±åœ¨å®¶äººèº«ä¸Šã€‚å¦‚æžœå·¥ä½œæ˜¯ä½ ç”Ÿæ´»çš„é‡å¿ƒï¼Œé‚£ä¹ˆé‡è¿”åŠžå…¬å®¤å°±è‡ªç„¶æ˜¯ä¸€ä¸ªä¼˜å…ˆäº‹é¡¹ã€‚\nä½ æƒ³è±¡ä¸€ä¸‹é«˜ç®¡çš„å·¥ä½œåœºæ™¯ï¼šæ— éœ€é€šå‹¤ï¼Œå¸æœºä¼šé€ä½ åˆ°å®¶ï¼Œä½ ä¸€å¿ƒå·¥ä½œï¼Œæ— éœ€èµ¶å›žå®¶æŽ¥å­©å­ï¼ŒåŠ©ç†ä¼šå¸®ä½ åšè¿™äº›ï¼Œä½ ä¹Ÿæ— éœ€è´­ç‰©ã€æ‰“æ‰«æˆ–åšé¥­ï¼Œä½£äººä¼šåšè¿™äº›ï¼Œæ— éœ€è¾…å¯¼ä½œä¸šï¼Œå¥½å­¦æ ¡ä¼šæä¾›è¾…å¯¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå›žåˆ°åŠžå…¬å®¤æ„Ÿè§‰éžå¸¸\"å€¼å¾—\"ã€‚\nè¿™ä¸æ˜¯ä¸€ç¯‡åå¯¹é«˜ç®¡ä¸ªäººè´¢å¯Œçš„é•¿ç¯‡å¤§è®ºã€‚æ¯•ç«Ÿï¼Œæˆ‘ä»˜å‡ºäº†25å¹´çš„ç”Ÿå‘½ï¼Œå¾—åˆ°äº†ä¸€äº›è´¢å¯Œã€‚ç›¸åï¼Œè¿™æ˜¯ä¸€ç§è§£é‡Šï¼Œä»¥ä¾¿ä½ äº†è§£é«˜ç®¡ä¸Žæ™®é€šå‘˜å·¥çš„è„±èŠ‚ã€‚\nå¦‚æžœä½ éœ€è¦å½±å“é«˜ç®¡ï¼Œè€Œä»–ä»¬çš„ç»åŽ†å¯èƒ½ä¸Žä½ çš„çŽ°å®žç”Ÿæ´»è„±èŠ‚ï¼Œè¯·é€šè¿‡æ•…äº‹ã€è§†é¢‘å’Œæ•°æ®å¸®åŠ©ä»–ä»¬çœ‹åˆ°çŽ°å®žã€‚è¯·è®°ä½ï¼Œä»–ä»¬ç¡®å®žç”Ÿæ´»åœ¨å¦ä¸€ä¸ªä¸–ç•Œã€‚è¿™å¹¶ä¸ä¸€å®šä¼šä½¿ä»–ä»¬å˜å¾—é‚ªæ¶ï¼Œåªæ˜¯è„±èŠ‚äº†ã€‚æˆ‘ä¸æƒ³å‘ç”Ÿ\"è„±èŠ‚\"ï¼Œä½†å¿…é¡»æ‰¿è®¤è¿™ç§æƒ…å†µç¡®å®žä¼šéšç€æ—¶é—´çš„æŽ¨ç§»è€Œå‘ç”Ÿã€‚\nè¨€è®º\n1ã€\nå…¼èŒåˆ›ä¸šä¸æ˜¯å¯ä»¥é•¿æœŸåšæŒçš„äº‹æƒ…ã€‚å¦‚æžœä½ ä¸Šç­æ—¶æ•´å¤©é¢å¯¹ç”µè„‘ï¼Œå›žå®¶åŽåˆååœ¨å¦ä¸€å°ç”µè„‘å‰å¼€å‘è‡ªå·±çš„è½¯ä»¶ï¼Œé‚£å°†è®©ä½ ç­‹ç–²åŠ›å°½ã€‚\nä½ å¯ä»¥è¿™æ ·åšå‡ ä¸ªæœˆï¼Œä½†é—®é¢˜æ˜¯ï¼Œä¼ä¸šé€šå¸¸éœ€è¦æ›´é•¿çš„æ—¶é—´æ‰èƒ½èµ·æ­¥ï¼Œå¾ˆå¤šäººå°±ä¼šæ”¾å¼ƒã€‚\n-- ã€Šå…³äºŽç‹¬ç«‹å¼€å‘ã€‹\n2ã€\nåœ¨å¼€å§‹ä¸€ä¸ªé¡¹ç›®æ—¶ï¼Œä¸€å®šç¨‹åº¦çš„å¤©çœŸæ˜¯å¿…ä¸å¯å°‘çš„ã€‚å¦‚æžœæˆ‘çŸ¥é“è¿™æ¡è·¯æœ‰å¤šéš¾ï¼Œæˆ‘å¯èƒ½æ°¸è¿œä¸ä¼šå¼€å§‹ã€‚ä½†ç”±äºŽæˆ‘å®Œå…¨ä¸äº†è§£æœªæ¥çš„æŒ‘æˆ˜ï¼Œæ‰€ä»¥æˆ‘åªæ˜¯ä¸€å¤´æ‰Žè¿›åŽ»ï¼Œä¸€è·¯æ‘¸ç´¢ã€‚ \n-- é‡‘èŒ¨Â·é½å·´æ´›è¿ªæ–¯ï¼ˆGints Zilbalodisï¼‰ï¼Œæ‹‰è„±ç»´äºšå¯¼æ¼”ï¼Œä»–çš„ä½œå“ã€ŠçŒ«çŒ«çš„å¥‡å¹»æ¼‚æµã€‹ï¼ˆFlowï¼‰èŽ·å¾—ä»Šå¹´çš„å¥¥æ–¯å¡æœ€ä½³åŠ¨ç”»ç‰‡å¥–\n3ã€\nä½ ç¼–å†™çš„æ¯ä¸€è¡Œä»£ç éƒ½å¯èƒ½æ˜¯ä¸€ä¸ªæ½œåœ¨çš„ bugã€‚é™¤éžä½ ç»å¯¹éœ€è¦è¿™è¡Œä»£ç ï¼Œç¼ºäº†å®ƒç¨‹åºå°±ä¼šå—å½±å“ï¼Œå¦åˆ™å°±ä¸è¦å†™ã€‚ä¸è¦ç¼–å†™ä½ ç”¨ä¸åˆ°çš„æŠ½è±¡å±‚ã€‚å¦‚æžœä¼˜åŒ–ä¼šå¢žåŠ ä»»ä½•å¤æ‚æ€§ï¼Œå°±åšå†³ä¸è¦ä¼˜åŒ–ã€‚\n-- ã€Šæ¯ä¸€ä»£ç éƒ½å¯èƒ½æ˜¯ bugã€‹\n4ã€\næˆ‘å¯¹ AI çš„çœ‹æ³•æ˜¯ï¼ŒAI æœ¬èº«ä¸ä¼šåˆ›é€ ï¼Œéœ€è¦äººç±»ä¸Žå®ƒå…±åŒåˆ›é€ ï¼Œåˆ›é€ çš„ç»“æžœå¥½åä¸Žä½¿ç”¨å®ƒçš„äººçš„è´¨é‡é«˜åº¦ç›¸å…³ã€‚\nä¸Ž AI äº¤è°ˆä¸åƒåœ¨ä¸Žä¸€ä¸ªäººäº¤è°ˆï¼Œè€Œåƒåœ¨ä¸Žäººç±»çš„é›†ä½“æ€ç»´äº¤è°ˆã€‚AI ä¸åº”è¯¥è®©ä½ å‡å°‘æ€è€ƒï¼Œè€Œåº”è¯¥å¸®åŠ©ä½ å¢žåŠ æ€è€ƒï¼ŒAI æ˜¯ä½ çš„æ æ†ï¼Œå¯ä»¥è®©ä½ æ‹“å±•è‡ªå·±ã€‚\n-- Alex Komoroskeï¼Œç¾Žå›½ç¨‹åºå‘˜\n5ã€\n10ä¸ªäººå¼€ä¼šï¼Œå¯ä»¥æ²¡æœ‰ä¸»æŒäººã€‚100ä¸ªäººå¼€ä¼šï¼Œå¿…é¡»æœ‰ä¸»æŒäººã€‚1000ä¸ªäººå¼€ä¼šï¼Œéœ€è¦ä¸€ä¸ªç»„å§”ä¼šã€‚\næ‰©å¤§10å€ï¼Œéœ€è¦å°†çŸ¥è¯†/èµ„æºæŽ¨å‘æžé™ï¼Œä½†æ˜¯æ‰©å¤§100å€ï¼Œéœ€è¦è·³å‡ºçŽ°æœ‰çš„ç»´åº¦ï¼Œé‡æ–°å®‰æŽ’ä¸€åˆ‡ã€‚\n-- ã€Šä½ çš„ä¸‹ä¸¤ä¸ªé›¶ã€‹\nå¾€å¹´å›žé¡¾\nä¸€å‘¨æ˜¯ä¸€å¹´çš„2%ï¼ˆ#293ï¼‰\nä¸Žå­”å­ AI èŠå¤©ï¼ˆ#243ï¼‰\nå‰ç«¯ä¸ŽåŽç«¯ï¼Œè°æ›´éš¾ï¼Ÿï¼ˆ#193ï¼‰\nä¸–ç•Œå°½å¤´ä¸Žå†·é…·ä»™å¢ƒï¼ˆ#143ï¼‰\nï¼ˆå®Œï¼‰\næ–‡æ¡£ä¿¡æ¯\nç‰ˆæƒå£°æ˜Žï¼šè‡ªç”±è½¬è½½-éžå•†ç”¨-éžè¡ç”Ÿ-ä¿æŒç½²åï¼ˆåˆ›æ„å…±äº«3.0è®¸å¯è¯ï¼‰\nå‘è¡¨æ—¥æœŸï¼š 2025å¹´3æœˆ 7æ—¥",
    "link": "http://www.ruanyifeng.com/blog/2025/03/weekly-issue-340.html",
    "pubDate": "2025-03-07T00:11:36.000Z",
    "source": "é˜®ä¸€å³°çš„ç½‘ç»œæ—¥å¿—",
    "category": "æŠ€æœ¯åšå®¢"
  },
  {
    "id": "rweekly",
    "title": "R Weekly 2025-W12 Multilingual quarto docs, ellmer, cholera in 1854",
    "description": "Hello and welcome to this new issue!\n\r\n\t\t\t\t\nHow to have (my) content shared by R Weekly?\nThis weekâ€™s release was curated by Ryo Nakagawara, with help from the R Weekly team members and contributors.\nHighlight\nCreating multilingual documentation with Quarto\nThe ellmer package for using LLMs with R is a game changer for scientists\n{SnowData} 1.0.0: Historical Data from John Snowâ€™s 1854 Cholera Outbreak Map\nInsights\nData Science in the Cloud: A Recap of the Snowflake and Posit Webinar\nEnabling the pharmaceutical programming community to develop ADaM datasets in R: Four Perspectives From the Maintainers\nInitial impressions from testing Posit Connect\nR in Organizations\nR-Ladies is rebranding to R-Ladies+\nR in Academia\nVisualizing Uncertainty (lecture slides)\nResources\nMAGA keyword screening tool: Tool built using Quarto and shinylive that allows you to analyze documents for specific MAGA-targeted keywords in response to this executive order. It is intended to be used to help identify words that might get screened by the federal government, e.g. in a grant proposal for federal funding.\nData Viz Showcase - Paul Schmidt\nResources from NICAR data journalism conferences\nCode Nerd: R Chatgpt helper\nNew Packages\nðŸ“¦ Go Live for More New Pkgs ðŸ“¦\n -->\nðŸ“¦ Keep up to date wtih CRANberries ðŸ“¦\nCRAN\n{deltatest} 0.1.0: Statistical Hypothesis Testing Using the Delta Method ( cran.r-project.org )\n{SnowData} 1.0.0: Historical Data from John Snowâ€™s 1854 Cholera Outbreak Map\n{RcppDPR} 0.1.9: â€˜Rcppâ€™ Implementation of Dirichlet Process Regression\n{golfr} 0.1.0: Group Assignment Tool\n{ggvfields} 1.0.0: Vector Field Visualizations with â€˜ggplot2â€™\n{sourcoise} 0.5.0: Source a Script and Cache\n{RcensusPkg} 0.1.4: Easily Access US Census Bureau Survey and Geographic Data\n{ambiorix} 2.2.0: Web Framework Inspired by â€˜Express.jsâ€™\n{cpp11tesseract} 5.3.5: Open Source OCR Engine\n{SeuratExplorer} 0.1.0: An â€˜Shinyâ€™ App for Exploring scRNA-seq Data Processed in\nâ€˜Seuratâ€™\n{HARplus} 1.0.1: Enhanced R Package for â€˜GEMPACKâ€™ .har and .sl4 Files\n{cpam} 0.1.3: Changepoint Additive Models for Time Series Omics Data\n{CAOP.RAA.2024} 0.0.5: Official Administrative Map of the Azores (CAOP 2024)\n{ravepipeline} 0.0.1: Reproducible Pipeline Infrastructure for Neuroscience\n{VizTest} 0.3: Optimal Confidence Intervals for Visual Testing\n{JMbdirect} 0.1.0: Joint Model for Longitudinal and Multiple Time to Events Data\n{IVDML} 1.0.0: Double Machine Learning with Instrumental Variables and\nHeterogeneity\n{weatherOz} 2.0.0: An API Client for Australian Weather and Climate Data Resources\n{tabtibble} 0.0.1: Simplify Reporting Many Tables\n{clayringsmiletus} 1.0.2: Clay Stacking Rings Found in Miletus (Data)\n{brandr} 0.1.0: Brand Identity Management Using brand.yml Standard\n{geneNR} 1.0.1: Automated Gene Identification for Post-GWAS Analysis\nGitHub or Bitbucket\n{quartabs} 0.1.0.9001: Dynamically generate tabset panels in Quarto HTML documents\n{gsapy} 0.0.0.9000: â€˜Shinyâ€™ interface for GSAP JavaScript animations\nUpdated Packages\nðŸ” Search on R-universe ðŸ”\n{httpgd} 2.0.3: A â€˜HTTPâ€™ Server Graphics Device - diffify\n{DemographicTable} 0.1.10: Creating Demographic Table - diffify\n{Rforestry} 0.11.1.0: Random Forests, Linear Trees, and Gradient Boosting for\nInference and Interpretability - diffify\n{tzdb} 0.5.0: Time Zone Database Information - diffify\n{greenfeedr} 1.2.0: Process and Report â€˜GreenFeedâ€™ Data - diffify\n{ggalign} 1.0.0: A â€˜ggplot2â€™ Extension for Consistent Axis Alignment - diffify\n{accessr} 1.1.2: Command Line Tools to Produce Accessible Documents using â€˜R\nMarkdownâ€™ - diffify\n{rjsoncons} 1.3.2: Query, Pivot, Patch, and Validate â€˜JSONâ€™ and â€˜NDJSONâ€™ - diffify\n{blogdown} 1.21: Create Blogs and Websites with R Markdown - diffify\n{ScottKnott} 1.3-3: The ScottKnott Clustering Algorithm - diffify\n{RCzechia} 1.12.6: Spatial Objects of the Czech Republic - diffify\n{xml2} 1.3.8: Parse XML - diffify\n{ichimoku} 1.5.6: Visualization and Tools for Ichimoku Kinko Hyo Strategies - diffify\n{grateful} 0.2.11: Facilitate Citation of R Packages - diffify\n{mlr3} 0.23.0: Machine Learning in R - Next Generation - diffify\n{gemini.R} 0.9.2: Interface for â€˜Google Geminiâ€™ API - diffify\n{wordvector} 0.3.0: Word and Document Vector Models - diffify\n{hexfont} 1.0.0: â€˜GNU Unifontâ€™ Hex Fonts - diffify\n{depCensoring} 0.1.7: Statistical Methods for Survival Data with Dependent Censoring - diffify\n{ggeffects} 2.2.1: Create Tidy Data Frames of Marginal Effects for â€˜ggplotâ€™ from\nModel Outputs - diffify\n{versioning} 0.2.0: Settings and File I/O using a Configuration YAML File - diffify\n{ggblanket} 12.2.0: Simplify â€˜ggplot2â€™ Visualisation - diffify\n{xmeta} 1.3.3: A Toolbox for Multivariate Meta-Analysis - diffify\n{ggstats} 0.9.0: Extension to â€˜ggplot2â€™ for Plotting Stats - diffify\n{collapse} 2.1.0: Advanced and Fast Data Transformation - diffify\n{politeness} 0.9.4: Detecting Politeness Features in Text - diffify\n{rstan} 2.32.7: R Interface to Stan - diffify\n{uisapi} 0.1.0.9000: Access the UNESCO Institute for Statistics API - diffify\nVideos and Podcasts\nListen to the R-Weekly Highlights Podcast\nShiny Apps\nAppsilon at ShinyConf 2025: Pushing the Boundaries of Shiny Development\nPosit at ShinyConf 2025\nTutorials\nHow to Select Columns from data.table in R\nSparklines in Reactable Tables\nThe ellmer package for using LLMs with R is a game changer for scientists\nMachine Learning Insights on BIST 100â€™s Future\nCreating data-driven art\n3MW (User-Specific Authentication for Quarto Projects on Azure Static Web Apps)\nDigital Difficulties\nEvidence Synthesis for Decision Making in Healthcare\nConformal prediction intervals with the probably package\nCreating multilingual documentation with Quarto\n\n-->\n\nR Project Updates\nUpdates from R Core:\nCall for Participation\n  \n \nPost by @rOpenSci@hachyderm.io\n View on Mastodon\n  \n\n\nUpcoming Events in 3 Months\nEvents in 3 Months:\nA list of R conferences and meetings\nThis weekâ€™s local R-User and applied stats events\nWeekly R Workshops for Ukraine\nShiny in Production 2025: Abstracts Deadline Extension\nEffective Data Visualization in R in Scientific Contexts workshop\nConnect\nJoin the Data Science Learning Community\nrtistry\nMathematical art based on Hilbert curves.  Made with R\n\n#mathart #math #creativecoding #codeart #rtistry\n[image or embed]\nâ€” George Savva (@georgemsavva.bsky.social) March 1, 2025 at 11:03 PM\n\n\nQuotes of the Week\nThe problem with #rstats is portability. Shit like `df$x` has to be converted to `dfâ‚¬x` in Europe and `dfÂ£x` in the UK but nobody talks about this.\nâ€” John Coene (@johncoene.bsky.social) March 14, 2025 at 9:42 PM\n\n\n\nI was recently asked to create an Atlas of population diversity for major Spanish municipalities at the census tract level. Who else thinks bivariate maps + scatter plots are a powerhouse combo? Open to suggestions.\n\n#rstats #map #barcelona #diversity\n[image or embed]\nâ€” Juan Galeano (@juangaleano.bsky.social) March 15, 2025 at 11:55 PM\n\n\n\nFeels like air raid alerts in Kyiv are nightly. I checked: since the yearâ€™s start, only 13 nights were free of alerts, and each lasts about 131 minutes on average. Letâ€™s see how the ceasefire goes, but meanwhile, please donate to air defense, links in the next reply. #UaView #RStats\n[image or embed]\nâ€” Dariia Mykhailyshyna (@dariia.bsky.social) March 13, 2025 at 12:47 AM",
    "link": "https://rweekly.org//2025-W12.html",
    "pubDate": "Mon, 17 Mar 2025 00:00:00 +0000",
    "source": "R Weekly",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "rweekly",
    "title": "R Weekly 2025-W11 LaTeX Typesetting in R, Create a unique documentation for your R Package",
    "description": "Hello and welcome to this new issue!\n\r\n\t\t\t\t\nHow to have (my) content shared by R Weekly?\nThis weekâ€™s release was curated by Batool Almaarzouq, with help from the R Weekly team members and contributors.\nHighlight\nLaTeX Typesetting in R: The â€˜xdvirâ€™ Package\nCustomize your expedition: Create a unique documentation for your R Package\nInsights\nCRAN-like repository for most recent releases of Techtoniqueâ€™s R packages\nAdding arm64 to r2u\nBest Before Dates by Bass\n\nResources\n2025-01  LaTeX Typesetting in R\nggplot2: Going further in the tidyverse\n\nWhat They Forgot to Teach You About R\n9 new books added to Big Book of R\nWbsite for tidyplots use cases\n\nNew Packages\nðŸ“¦ Go Live for More New Pkgs ðŸ“¦\n -->\nðŸ“¦ Keep up to date wtih CRANberries ðŸ“¦\nCRAN\n{forgts} 0.0.1: Reads a spreadsheet and its formatting information to produce gt tables with the same cell and text formatting as the input file\n{Certara.DarwinReporter} 2.0.1: Data Visualization Utilities for â€˜pyDarwinâ€™ Machine Learning\nPharmacometric Model Development\n{xlr} 1.0.3: Create Table Summaries and Export Neat Tables to â€˜Excelâ€™\n{visae} 0.2.1: Visualization of Adverse Events\n{shinyTimer} 0.1.0: Customizable Timer for â€˜shinyâ€™ Applications\n{uisapi} 0.1.0: Access the UNESCO Institute for Statistics API\n{RplotterPkg} 0.1.3: R Plotting Functions Using â€˜ggplot2â€™\n{revise} 0.1.0: Dynamic Revision Letters for â€˜Rmarkdownâ€™ Manuscripts\n{connected} 1.1: Visualize and Improve Connectedness of Factors in Tables\n{mixtree} 0.0.1: A Statistical Framework for Comparing Sets of Trees\n{MHQoL} 0.12.0: Mental Health Quality of Life Toolkit\n{rconf} 0.1.2: Minimal and Lightweight Configuration Tool\n{mbX} 0.1.3: A Comprehensive Microbiome Data Processing Pipeline\n{IndexNumberTools} 1.1: Working with Index Numbers\n{sakura} 0.1.0: Extension to R Serialization\n{rmsMD} 0.1.2: Output Results from â€˜rmsâ€™ Models for Medical Journals\n{maths.genealogy} 0.1.2: Mathematics PhD Genealogy Data and Plotting\n{Certara.ModelResults} 3.0.1: Generate Diagnostics for Pharmacometric Models Using â€˜shinyâ€™\nUpdated Packages\nðŸ” Search on R-universe ðŸ”\nRcppSimdJson 0.1.13 on CRAN: Compiler Nag, New Upsteam\nRcppDate 0.0.5: Address Minor Compiler Nag\n{mrbin} 1.9.0: Metabolomics Data Analysis Functions - diffify\n{tidyllm} 0.3.2: Tidy Integration of Large Language Models - diffify\n{tidyplots} 0.2.2: Tidy Plots for Scientific Papers - diffify\n\n{gimap} 1.0.3: Calculate Genetic Interactions for Paired CRISPR Targets - diffify\n{pals} 1.10: Color Palettes, Colormaps, and Tools to Evaluate Them - diffify\n{readxl} 1.4.5: Read Excel Files - diffify\n{archeofrag} 1.1.0: Spatial Analysis in Archaeology from Refitting Fragments - diffify\n{PubChemR} 2.1.4: Interface to the â€˜PubChemâ€™ Database for Chemical Data Retrieval - diffify\n{rgeoda} 0.1.0: R Library for Spatial Data Analysis - diffify\n{rhub} 2.0.1: Tools for R Package Developers - diffify\n{usmapdata} 0.4.0: Mapping Data for â€˜usmapâ€™ Package - diffify\n{hutilscpp} 0.10.8: Miscellaneous Functions in C++ - diffify\n{habtools} 1.1.1: Tools and Metrics for 3D Surfaces and Objects - diffify\n{rnpn} 1.3.0: Interface to the National â€˜Phenologyâ€™ Network â€˜APIâ€™ - diffify\n{divest} 1.2.0: Get Images Out of DICOM Format Quickly - diffify\n{dataquieR} 2.5.1: Data Quality in Epidemiological Research - diffify\n{tutorial.helpers} 0.4.2: Helper Functions for Creating Tutorials - diffify\n{strata} 1.4.3: Simple Framework for Simple Automation - diffify\n{leaflet.extras2} 1.3.1: Extra Functionality for â€˜leafletâ€™ Package - diffify\n{huxtable} 5.6.0: Easily Create and Style Tables for LaTeX, HTML and Other Formats - diffify\n{scoutbaR} 0.1.0: A Spotlight â€˜Reactâ€™ Widget for â€˜shinyâ€™ Apps - diffify\n{isopleuros} 1.4.0: Ternary Plots - diffify\n{formatBibtex} 0.1.1: Format BibTeX Entries and Files - diffify\n{xpectr} 0.4.4: Generates Expectations for â€˜testthatâ€™ Unit Testing - diffify\n{offsetreg} 1.1.1: An Extension of â€˜Tidymodelsâ€™ Supporting Offset Terms - diffify\nVideos and Podcasts\nListen to the R-Weekly Highlights Podcast\nUse Claude Code in RStudio to ship R code like some kind of 10x tidyverse developer\nR for Data Science: Web scraping\nR Internationally\nUnir y combinar grÃ¡ficos {ggplot2} en R\nTutorials\nA Bayesian proportional hazards model with a penalized spline\nCustomize your expedition: Create a unique documentation for your R Package\n\nThe Complete Guide to Handling NA Values in R Tables: Methods, Best Practices, and Solutions\nHarness Local LLMs and GitHub Copilot for Enhanced R Package Development\n3MW (GitHub Authentication for Azure Static Web Apps)\nHow to include control variables in a cross-lagged panel model\n\n-->\n\nR Project Updates\nUpdates from R Core:\nUpcoming Events in 3 Months\nEvents in 3 Months:\nA list of R conferences and meetings\nThis weekâ€™s local R-User and applied stats events\nRegister for R/Pharma at posit::conf(2025)\nWeekly R Workshops for Ukraine\nGrants & Funding\n2025 ISC Grant Program\nConnect\nJoin the Data Science Learning Community\nrtistry\nCrochet-inspired generative art ðŸ§¶ðŸŽ¨\n\n#Rtistry #RStats #ggplot2 #GenerativeArt\n[image or embed]\nâ€” Nicola Rennie (@nrennie.bsky.social) March 7, 2025 at 4:23 PM\n\n\nQuotes of the Week\n  \n \nPost by @rladies_paris@mastodon.social\n View on Mastodon\n  \n\n\n\nReceiving CRAN feedback\n\n#RStats\n[image or embed]\nâ€” coolbutuseless (@coolbutuseless.fosstodon.org.ap.brid.gy) March 8, 2025 at 3:16 PM",
    "link": "https://rweekly.org//2025-W11.html",
    "pubDate": "Mon, 10 Mar 2025 00:00:00 +0000",
    "source": "R Weekly",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "rweekly",
    "title": "R Weekly 2025-W10 ellmer, Closeread Prize winnners, Rapid RAG Prototyping",
    "description": "Hello and welcome to this new issue!\n\r\n\t\t\t\t\nHow to have (my) content shared by R Weekly?\nThis weekâ€™s release was curated by Sam Parmar, with help from the R Weekly team members and contributors.\nHighlight\nAnnouncing ellmer: A package for interacting with Large Language Models in R\nWinners of the Closeread Prize â€“ Data-Driven Scrollytelling with Quarto\nRapid RAG Prototyping: Building a Retrieval Augmented Generation Prototype with ellmer and DuckDB\nInsights\nAnnouncing ellmer: A package for interacting with Large Language Models in R\n\nLLM + Quarto: Turn One-Off Reports Into Automated Solutions\nShare your data apps and docs more seamlessly on Connect Cloud\nJanuary 2025 Top 40 New CRAN Packages\nQ1 2025 tidymodels digest\n\nUnderstand geom_bar and its statistical transformations\nAnalyzing targeted locus amplification (TLA) data\nWinners of the Closeread Prize â€“ Data-Driven Scrollytelling with Quarto\n\nR in the Browser: Announcing Our WebAssembly Distribution\nR in the Real World\nPharmaverse Council Member updates\nR Submissions Working Group: Pilot 5 Launch and more!\nR in Organizations\nWorking with Clinical Trial Data? Thereâ€™s a Pharmaverse Package for That\nResources\nCRANhaven - A repository for recently archived CRAN packages\nNew Packages\nðŸ“¦ Go Live for More New Pkgs ðŸ“¦\n -->\nðŸ“¦ Keep up to date wtih CRANberries ðŸ“¦\nCRAN\n{httpgd} 2.0.3: A â€˜HTTPâ€™ Server Graphics Device\n{awdb} 0.1.1: Query the USDA NWCC Air and Water Database REST API\n{cnd} 0.1.0: Create and Register Conditions\n{EpiSimR} 1.1: A â€˜Shinyâ€™ App to Simulate the Dynamics of Epidemic and Endemic Diseases Spread\n{xdvir} 0.1-2: Render â€˜LaTeXâ€™ in Plots\nâ€˜shinyâ€™\n{crane} 0.1.0: Supplements the â€˜gtsummaryâ€™ Package for Pharmaceutical Reporting\nUpdated Packages\nðŸ” Search on R-universe ðŸ”\n{cards} 0.5.1: Analysis Results Data - diffify\n{pander} 0.6.6: An R â€˜Pandocâ€™ Writer - diffify\n{jobqueue} 1.5.1: Run Interruptible Code Asynchronously - diffify\n{xml2} 1.3.7: Parse XML - diffify\n{teal.modules.general} 0.4.0: General Modules for â€˜tealâ€™ Applications - diffify\n{teal.modules.clinical} 0.10.0: â€˜tealâ€™ Modules for Standard Clinical Outputs - diffify\n{rayrender} 0.38.10: Build and Raytrace 3D Scenes - diffify\n{r2rtf} 1.1.3: Easily Create Production-Ready Rich Text Format (RTF) Tables and\nFigures - diffify\n{odbc} 1.6.0: Connect to ODBC Compatible Databases (using the DBI Interface) - diffify\n{diseasystore} 0.3.1: Feature Stores for the â€˜diseasyâ€™ Framework - diffify\n{CNID} 2.0.2: Get Basic Information from Chinese ID Number - diffify\n{eq5d} 0.15.7: Methods for Analysing â€˜EQ-5Dâ€™ Data and Calculating â€˜EQ-5Dâ€™ Index\nScores - diffify\n{splines2} 0.5.4: Regression Spline Functions and Classes - diffify\n{pmlbr} 0.3.0: Interface to the Penn Machine Learning Benchmarks Data\nRepository - diffify\n{healthdb} 0.4.0: Working with Healthcare Databases - diffify\n{censobr} 0.4.1: Download Data from Brazilâ€™s Population Census - diffify\n{xslt} 1.5.1: Extensible Style-Sheet Language Transformations - diffify\n{readxl} 1.4.4: Read Excel Files - diffify\n{duckplyr} 1.0.1: A â€˜DuckDBâ€™-Backed Version of â€˜dplyrâ€™ - diffify\n{Rfast} 2.1.5: A Collection of Efficient and Extremely Fast R Functions - diffify\n{litedown} 0.6: A Lightweight Version of R Markdown - diffify\n{gtreg} 0.4.1: Regulatory Tables for Clinical Research - diffify\n{aplot} 0.2.5: Decorate a â€˜ggplotâ€™ with Associated Information - diffify\n{sasr} 0.1.4: â€˜SASâ€™ Interface - diffify\n{tinytex} 0.56: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents - diffify\n{QuickJSR} 1.6.0: Interface for the â€˜QuickJSâ€™ Lightweight â€˜JavaScriptâ€™ Engine - diffify\n{PatientProfiles} 1.3.0: Identify Characteristics of Patients in the OMOP Common Data Model - diffify\n{reproducibleRchunks} 1.0.3: Automated Reproducibility Checks for R Markdown Documents - diffify\n{simer} 1.0.0: Data Simulation for Life Science and Breeding - diffify\n{summarytools} 1.1.1: Tools to Quickly and Neatly Summarize Data - diffify\n{flexlsx} 0.3.4: Exporting â€˜flextableâ€™ to â€˜xlsxâ€™ Files - diffify\n{zippeR} 0.1.1: Working with United States ZIP Code and ZIP Code Tabulation Area\nData - diffify\n{and} 0.1.6: Construct Natural-Language Lists with Internationalization - diffify\n{dittoViz} 1.0.3: User Friendly Data Visualization - diffify\n{brickset} 2025.0.0: Interface with the Brickset API for Getting Data About LEGO Sets - diffify\n{khroma} 1.16.0: Colour Schemes for Scientific Data Visualization - diffify\n{arkhe} 1.10.0: Tools for Cleaning Rectangular Data - diffify\n{akc} 0.9.9.1: Automatic Knowledge Classification - diffify\n{watcher} 0.1.2: Watch the File System for Changes - diffify\n{RPostgres} 1.4.8: C++ Interface to PostgreSQL - diffify\n{networktools} 1.6.0: Tools for Identifying Important Nodes in Networks - diffify\n{R.utils} 2.13.0: Various Programming Utilities - diffify\n{reticulate} 1.41.0: Interface to â€˜Pythonâ€™ - diffify\n{ggnewscale} 0.5.1: Multiple Fill and Colour Scales in â€˜ggplot2â€™ - diffify\n{teal} 0.16.0: Exploratory Web Apps for Analyzing Clinical Trials Data - diffify\n{simDAG} 0.2.2: Simulate Data from a DAG and Associated Node Information - diffify\n{planr} 0.5.1: Tools for Supply Chain Management, Demand and Supply Planning - diffify\n{plotscaper} 0.2.8: Explore Your Data with Interactive Figures - diffify\nVideos and Podcasts\nListen to the R-Weekly Highlights Podcast\nR-Ladies Rome (English) - Interactive R, Python, and Shiny in the Browser with Quarto and Shinylive\nMaster Data Extraction - Turn Texts into Tidy Data with R & {ellmer}\nCompany-branded reports, apps, and dashboards made easier with brand.yml & Posit\nTutorials\nChecking your R packages and practicals on a schedule using GitHub Actions\n3MW (Authentication for Quarto Projects on Azure)\nDependency-light hex stickers with {gex}\nWeb app with DeepSeek R1 and Hugging Face API for chatting\nHow to Create Tables in R (With Examples) â€“ A Comprehensive Guide Using Base R, dplyr, and data.table\nRapid RAG Prototyping: Building a Retrieval Augmented Generation Prototype with ellmer and DuckDB\n\n-->\n\nR Project Updates\nUpdates from R Core:\nCall for Participation\nUpcoming Events in 3 Months\nEvents in 3 Months:\nA list of R conferences and meetings\nThis weekâ€™s local R-User and applied stats events\nWeekly R Workshops for Ukraine\nFrame-by-Frame Modeling and Validation of NFL geospatial data using gganimate in R workshop\nIntroduction to Empirical Macroeconomics with R workshop\nRix: reproducible data science environments with Nix\nGrants & Funding\n2025 ISC Grant Program\nConnect\nJoin the Data Science Learning Community\nrtistry\n  \n \nPost by @nrennie@fosstodon.org\n View on Mastodon\n  \n\n\nQuotes of the Week\n#TodayinHistory #dataviz #Onthisday #OTD ðŸ“Š\nðŸŽ‚Happy #Rstats birthday!\nR 1.0.0 was first released on February 29, 2000.\nDoes that make it 24 or just 6 leap-years old? pic.twitter.com/KpZordLXAt\nâ€” Michael Friendly @datavisfriendly.bsky.social (@datavisFriendly) March 1, 2025",
    "link": "https://rweekly.org//2025-W10.html",
    "pubDate": "Mon, 03 Mar 2025 00:00:00 +0000",
    "source": "R Weekly",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "rweekly",
    "title": "R Weekly 2025-W09 nhyris, tisthemachinelearner, Forks",
    "description": "Hello and welcome to this new issue!\n\r\n\t\t\t\t\nHow to have (my) content shared by R Weekly?\nThis weekâ€™s release was curated by Colin Fay, with help from the R Weekly team members and contributors.\nHighlight\nnhyris - The minimal framework for transform R shiny application into standalone\ntisthemachinelearner: A Lightweight interface to scikit-learn with 2 classes, Classifier and Regressor (in Python and R)\nThe Dynamic Relationship of Forks with their Upstream Repository\nInsights\nWhy we forked nixpkgs\nRcpp now used by 3000 CRAN packages!\nThe Dynamic Relationship of Forks with their Upstream Repository\nR in Academia\nWin a Battle in the Game of Risk\nResources\nnhyris - The minimal framework for transform R shiny application into standalone\nNew Packages\nðŸ“¦ Go Live for More New Pkgs ðŸ“¦\n -->\nðŸ“¦ Keep up to date wtih CRANberries ðŸ“¦\nCRAN\n{GitAI} 0.1.0: Extracts Knowledge from â€˜Gitâ€™ Repositories\n{codelist} 0.1.0: Working with Code Lists\n{netknitr} 0.2.1: Knit Network Map for any Dataset\n{aftables} 1.0.2: Create Spreadsheet Publications Following Best Practice\n{musicXML} 1.0.1: Data Sonification using â€˜musicXMLâ€™\nUpdated Packages\nðŸ” Search on R-universe ðŸ”\nRcppDE 0.1.8 on CRAN: Maintenance\n{summarytools} 1.1.0: Tools to Quickly and Neatly Summarize Data - diffify\n{duckdb} 1.2.0: DBI Package for the DuckDB Database Management System - diffify\n{cpp11armadillo} 0.4.4: An â€˜Armadilloâ€™ Interface - diffify\n{parseLatex} 0.3.0: Parse â€˜LaTeXâ€™ Code - diffify\n{flint} 0.0.2: Fast Library for Number Theory - diffify\nVideos and Podcasts\nListen to the R-Weekly Highlights Podcast\nCollaborating Across Pharma: Open Source Highlights from the PHUSE US Connect 2024 Keynote\nTutorials\ntisthemachinelearner: A Lightweight interface to scikit-learn with 2 classes, Classifier and Regressor (in Python and R)\nBurn Notice\nHappy Valentineâ€™s Day\nHow to Replace Values in Data Frame Based on Lookup Table in R\n3MW (Host Quarto Projects on Azure)\n5 Levels of Data Wrangling Every R User Must Master\nCreating a Finder Smart Folder of your RStudio Project files to enable super fast project launching\nCreating R, Python, Stata, and Julia tutorial worksheets (with and without solutions) using Quarto\nCreating effectively multi-engine Quarto documents using Quartoâ€™s embed shortcode\nA First Look at TimeGPT using nixtlar\nHow to use a histogram as a legend in {ggplot2}\n\n-->\n\nR Project Updates\nUpdates from R Core:\nCall for Participation\nShiny in Production 2025: Call for Abstracts\nGovernment Advances in Statistical Programming (GASP) Conference 2025: Call for Abstracts\nUpcoming Events in 3 Months\nEvents in 3 Months:\nA list of R conferences and meetings\nThis weekâ€™s local R-User and applied stats events\nWeekly R Workshops for Ukraine\nGrants & Funding\nDiscover posit::conf as an Opportunity Scholar\nConnect\nJoin the Data Science Learning Community",
    "link": "https://rweekly.org//2025-W09.html",
    "pubDate": "Mon, 24 Feb 2025 00:00:00 +0000",
    "source": "R Weekly",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "Improved sparsity support in tidymodels",
    "description": "Photo by Oliver Olah on Unsplash\n5x height\n* [x] [`hugodown::use_tidy_thumbnails()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html)\n* [x] Add intro sentence, e.g. the standard tagline for the package\n* [x] [`usethis::use_tidy_thanks()`](https://usethis.r-lib.org/reference/use_tidy_thanks.html)\n-->\nWeâ€™re stoked to announce tidymodels now fully supports sparse data from end to end. We have been working on this for \nover 5 years. This is an extension of the work we have done \npreviously with blueprints, which would carry the data sparsely some of the way.\nYou will need \nrecipes 1.2.0, \nparsnip 1.3.0, \nworkflows 1.2.0 or later for this to work.\nWhat are sparse data?\n  \n    \n      \n\n      \n\n    \n  \n\nThe term sparse data refers to a data set containing many zeroes. Sparse data appears in all kinds of fields and can be produced in a number of preprocessing methods. The reason why we care about sparse data is because of how computers store numbers. A 32-bit integer value takes 4 bytes to store. An array of 32-bit integers takes 40 bytes, and so on. This happens because each value is written down.\nA sparse representation instead stores the locations and values of the non-zero entries. Suppose we have the following vector with 20 entries:\nc(0, 0, 1, 0, 3, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n\n\nIt could be represented sparsely using the 3 values positions = c(1, 3, 7), values = c(3, 5, 8), and length = 20. Now, we have seven values to represent a vector of 20 elements. Since some modeling tasks contain even sparser data, this type of representation starts to show real benefits in terms of execution time and memory consumption.\nThe tidymodels set of packages has undergone several internal changes to allow it to represent data sparsely internally when it would be beneficial. These changes allow you to fit models that contain sparse data faster and more memory efficiently than before. Moreover, it allows you to fit models previously not possible due to them not fitting in memory.\nSparse matrix support\n  \n    \n      \n\n      \n\n    \n  \n\nThe first benefit of these changes is that recipe(), prep(), bake(), fit(), and \npredict() now accept sparse matrices created using the Matrix package.\nThe permeability_qsar data set from the modeldata package contains quite a lot of zeroes in the predictors, so we will use it as a demonstration. Starting by coercing it into a sparse matrix.\nlibrary(tidymodels)\nlibrary(Matrix)\npermeability_sparse <- as(as.matrix(permeability_qsar), \"sparseMatrix\")\nWe can now use this sparse matrix in our code the same way as a dense matrix or data frame:\nrec_spec <- recipe(permeability ~ ., data = permeability_sparse) |>\n  step_zv(all_predictors())\n\nmod_spec <- boost_tree(\"regression\", \"xgboost\")\n\nwf_spec <- workflow(rec_spec, mod_spec)\nModel training has the usual syntax:\nwf_fit <- fit(wf_spec, permeability_sparse)\nas does prediction:\npredict(wf_fit, permeability_sparse)\n#> # A tibble: 165 Ã— 1\n#>     .pred\n#>     <dbl>\n#>  1 10.5  \n#>  2  1.50 \n#>  3 13.1  \n#>  4  1.10 \n#>  5  1.25 \n#>  6  0.738\n#>  7 29.3  \n#>  8  2.44 \n#>  9 36.3  \n#> 10  4.31 \n#> # â„¹ 155 more rows\n\nNote that only some models/engines work well with sparse data. These are all listed here https://www.tidymodels.org/find/sparse/. If the model doesnâ€™t support sparse data, it will be coerced into the default non-sparse representation and used as usual.\nWith a few exceptions, it should work like any other data set. However, this approach has two main limitations. The first is that we are limited to regression tasks since the outcome has to be numeric to be part of the sparse matrix.\nThe second limitation is that it only works with non-formula methods for parsnip and workflows. This means that you can use a recipe with add_recipe() or select variables directly with add_variables() when using a workflow. And you need to use fit_xy() instead of fit() when using a parsnip object by itself.\nIf this is of interest we also have a https://www.tidymodels.org/ post about \nusing sparse matrices in tidymodels.\nSparse data from recipes steps\n  \n    \n      \n\n      \n\n    \n  \n\nWhere this sparsity support really starts to shine is when the recipe we use will generate sparse data. They come in two flavors, sparsity creation steps and sparsity preserving steps. Both listed here: https://www.tidymodels.org/find/sparse/.\nSome steps like step_dummy(), step_indicate_na(), and \ntextrecipes::step_tf() will almost always produce a lot of zeroes. We take advantage of that by generating it sparsely when it is beneficial. If these steps end up producing sparse vectors, we want to make sure the sparsity is preserved. A couple of handfuls of steps, such as step_impute_mean() and step_scale(), have been updated to be able to work efficiently with sparse vectors. Both types of steps are detailed in the above-linked list of compatible methods.\nWhat this means in practice is that if you use a model/engine that supports sparse data and have a recipe that produces enough sparse data, then the steps will switch to produce sparse data by using a new sparse data format to store the data (when appropriate) as the recipe is being processed. Then if the model can accept sparse objects, we convert the data from our new sparse format to a standard sparse matrix object. Increasing performance when possible while preserving performance otherwise.\nBelow is a simple recipe using the ames data set. step_dummy() is applied to all the categorical predictors, leading to a significant amount of zeroes.\nrec_spec <- recipe(Sale_Price ~ ., data = ames) |>\n  step_zv(all_predictors()) |>\n  step_normalize(all_numeric_predictors()) |>\n  step_dummy(all_nominal_predictors())\n\nmod_spec <- boost_tree(\"regression\", \"xgboost\")\n\nwf_spec <- workflow(rec_spec, mod_spec)\nWhen we go to fit it now, it takes around 125ms and allocates 37.2MB. Compared to before these changes it would take around 335ms and allocate 67.5MB.\nwf_fit <- fit(wf_spec, ames)\nWe see similar speedups when we predictor with around 20ms and 25.2MB now, compared to around 60ms and 55.6MB before.\npredict(wf_fit, ames)\n#> # A tibble: 2,930 Ã— 1\n#>      .pred\n#>      <dbl>\n#>  1 208649.\n#>  2 115339.\n#>  3 148634.\n#>  4 239770.\n#>  5 190082.\n#>  6 184604.\n#>  7 208572.\n#>  8 177403 \n#>  9 261000.\n#> 10 198604.\n#> # â„¹ 2,920 more rows\n\nThese improvements are tightly related to memory allocation, which depends on the sparsity of the data set produced by the recipe. This is why it is hard to say how much benefit you will see. We have seen orders of magnitudes of improvements, both in terms of time and memory allocation. We have also been able to fit models where previously the data was too big to fit in memory.\nPlease see the post on tidymodels.org, which goes into more detail about when you are likely to benefit from this and how to change your recipes and workflows to take full advantage of this new feature.\nThere is also a https://www.tidymodels.org/ post going into a bit more detail about how to \nuse recipes to produce sparse data.",
    "link": "https://www.tidyverse.org/blog/2025/03/tidymodels-sparsity/",
    "pubDate": "Wed, 19 Mar 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "Q1 2025 tidymodels digest",
    "description": "5x height\n* [ ] `hugodown::use_tidy_thumbnails()`\n* [ ] Add intro sentence, e.g. the standard tagline for the package\n* [ ] `usethis::use_tidy_thanks()`\n-->\nThe tidymodels framework is a collection of R packages for modeling and machine learning using tidyverse principles.\nSince the beginning of 2021, we have been publishing quarterly updates here on the tidyverse blog summarizing whatâ€™s new in the tidymodels ecosystem. The purpose of these regular posts is to share useful new features and any updates you may have missed. You can check out the tidymodels tag to find all tidymodels blog posts here, including our roundup posts as well as those that are more focused.\nWeâ€™ve sent a steady stream of tidymodels packages to CRAN recently. We usually release them in batches since many of our packages are tightly coupled with one another. Internally, this process is referred to as the â€œcascadeâ€ of CRAN submissions.\nThe post will update you on which packages have changed and the major improvements you should know about.\nHereâ€™s a list of the packages and their News sections:\nbaguette\nbrulee\ncensored\ndials\nhardhat\nparsnip\nrecipes\ntidymodels\ntune\nworkflows\nLetâ€™s look at a few specific updates.\nImprovements in errors and warnings\n  \n    \n      \n\n      \n\n    \n  \n\nA group effort was made to improve our error and warning messages across many packages. This started with an internal â€œupkeep weekâ€ (which ended up being 3-4 weeks) and concluded at the \nTidy Dev Day in Seattle after posit::conf(2024).\nThe goal was to use new tools in the cli and rlang packages to make messages more informative than they used to be. For example, using:\ntidy(pca_extract_trained, number = 3, type = \"variances\")\n\n\nused to result in the error message:\nError in `match.arg()`:\n! 'arg' should be one of \"coef\", \"variance\"\n\nThe new system references the function that you called and not the underlying base R function that actually errored. It also suggests a solution:\nError in `tidy()`:\n! `type` must be one of \"coef\" or \"variance\", not \"variances\".\ni Did you mean \"variance\"?\n\nThe rlang package created a set of \nstandalone files that contain high-quality type checkers and related functions. This also improves the information that users get from an error. For example, using an inappropriate formula value in fit(linear_reg(), \"boop\", mtcars), the old message was:\nError in `fit()`:\n! The `formula` argument must be a formula, but it is a <character>.\n\nand now you see:\nError in `fit()`:\n! `formula` must be a formula, not the string \"boop\".\n\nThis was a lot of work and weâ€™re still arenâ€™t finished. Two events helped us get as far as we did.\nFirst, Simon Couch made the \nchores package (its previous name was â€œpalâ€), which enabled us to use AI tools to solve small-scope problems, such as converting old rlang error code to use the new \ncli syntax. I canâ€™t overstate how much of a speed-up this was for us.\nSecond, at developer day, many external folks pitched in to make pull requests from a list of issues:\nOrganizing Tidy Dev Day issues.\nI love these sessions for many reasons, but mostly because we meet users and contributors to our packages in person and work with them on specific tasks.\nThere is a lot more to do here; we have a lot of secondary packages that would benefit from these improvements too.\nQuantile regression in parsnip\n  \n    \n      \n\n      \n\n    \n  \n\nOne big update in parsnip was a new modeling mode of \"quantile regression\". Daniel McDonald and Ryan Tibshirani largely provided some inertia for this work based on their \ndisease modeling framework.\nYou can generate quantile predictions by first creating a model specification, which includes the quantiles that you want to predict:\nlibrary(tidymodels)\ntidymodels_prefer()\n\names <- \n  modeldata::ames |> \n  mutate(Sale_Price = log10(Sale_Price)) |> \n  select(Sale_Price, Latitude)\n\nquant_spec <- \n  linear_reg() |> \n  set_engine(\"quantreg\") |> \n  set_mode(\"quantile regression\", quantile_levels = c(0.1, 0.5, 0.9))\nquant_spec\n\n\n## Linear Regression Model Specification (quantile regression)\n## \n## Computational engine: quantreg\n\n## Quantile levels: 0.1, 0.5, and 0.9.\n\nWeâ€™ll add some spline terms via a recipe and fit the model:\nspline_rec <- \n  recipe(Sale_Price ~ ., data = ames) |> \n  step_spline_natural(Latitude, deg_free = 10)\n\nquant_fit <- \n  workflow(spline_rec, quant_spec) |> \n  fit(data = ames)\n\nquant_fit\n\n\n## â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: linear_reg()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 1 Recipe Step\n## \n## â€¢ step_spline_natural()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## Call:\n## quantreg::rq(formula = ..y ~ ., tau = quantile_levels, data = data)\n## \n## Coefficients:\n##               tau= 0.1    tau= 0.5    tau= 0.9\n## (Intercept) 4.71981123  5.07728741  5.25221335\n## Latitude_01 1.22409173  0.70928577  0.79000849\n## Latitude_02 0.19561816  0.04937750  0.02832633\n## Latitude_03 0.16616065  0.02045910  0.14730573\n## Latitude_04 0.30583648  0.08489487  0.15595080\n## Latitude_05 0.21663212  0.02016258 -0.01110625\n## Latitude_06 0.33541228  0.12005254  0.03006777\n## Latitude_07 0.47732205  0.09146728  0.17394021\n## Latitude_08 0.24028784  0.30450058  0.26144584\n## Latitude_09 0.05840312 -0.14733781 -0.11911843\n## Latitude_10 1.52800673  0.95994216  1.21750501\n## \n## Degrees of freedom: 2930 total; 2919 residual\n\nFor prediction, tidymodels always returns a data frame with as many rows as the input data set (here: ames). The result for quantile predictions is a special vctrs class:\nquant_pred <- predict(quant_fit, ames) \nquant_pred |> slice(1:4)\n\n\n## # A tibble: 4 Ã— 1\n##   .pred_quantile\n##        <qtls(3)>\n## 1         [5.33]\n## 2         [5.33]\n## 3         [5.33]\n## 4         [5.31]\n\n\nclass(quant_pred$.pred_quantile)\n\n\n## [1] \"quantile_pred\" \"vctrs_vctr\"    \"list\"\n\nwhere the output [5.31] shows the middle quantile.\nWe can expand the set of quantile predictions so that there are three rows for each source row in ames. Thereâ€™s also an integer column called .row so that we can merge the data with the source data:\nquant_pred$.pred_quantile[1]\n\n\n## <quantiles[1]>\n## [1] [5.33]\n## # Quantile levels: 0.1 0.5 0.9\n\n\nas_tibble(quant_pred$.pred_quantile[1])\n\n\n## # A tibble: 3 Ã— 3\n##   .pred_quantile .quantile_levels  .row\n##            <dbl>            <dbl> <int>\n## 1           5.08              0.1     1\n## 2           5.33              0.5     1\n## 3           5.52              0.9     1\n\nHere are the predicted quantile values:\nquant_pred$.pred_quantile |> \n  as_tibble() |> \n  full_join(ames |> add_rowindex(), by = \".row\") |> \n  arrange(Latitude) |> \n  ggplot(aes(x = Latitude)) + \n  geom_point(data = ames, aes(y = Sale_Price), alpha = 1 / 5) +\n  geom_line(aes(y = .pred_quantile, col = format(.quantile_levels)), \n            show.legend = FALSE, linewidth = 1.5) \n\n\n10%, 50%, and 90% quantile predictions.\nFor now, the new mode does not have many engines. We need to implement some performance statistics in the yardstick package before integrating these models into the whole tidymodels ecosystem.\nIn other news, weâ€™ve added some additional neural network models based on some improvements in the brulee package. Namely, two-layer networks can be tuned for feed-forward networks on tabular data (using torch).\nOne other improvement has been simmering for a long time: the ability to exploit sparse data structures better. Weâ€™ve improved our fit() interfaces for the few model engines that can use sparsely encoded data. There is much more to come on this in a few months, especially around recipes, so stay tuned.\nFinally, weâ€™ve created a set of \nchecklists that can be used when creating new models or engines. These are very helpful, even for us, since there is a lot of minutiae to remember.\nParallelism in tune\n  \n    \n      \n\n      \n\n    \n  \n\nThis was a small maintenance release mostly related to parallel processing. Up to now, tune facilitated parallelism using the \nforeach package. That package is mature but not actively developed, so we have been slowly moving toward using the \nfuture package(s).\nThe \nfirst step in this journey was to keep using foreach internally (but lean toward future) but to encourage users to move from directly invoking the foreach package and, instead, load and use the future package.\nWeâ€™re now moving folks into the second stage. tune will now raise a warning when:\nA parallel backend has been registered with foreach, and\nNo \nplan() has been specified with future.\nThis will allow users to transition their existing code to only future and allow us to update existing documentation and training materials.\nWe anticipate that the third stage, removing foreach entirely, will occur sometime before posit::conf(2025) in September.\nThings to look forward to\n  \n    \n      \n\n      \n\n    \n  \n\nWe are working hard on a few major initiatives that we plan on showing off at \nposit::conf(2025).\nFirst is integrated support for sparse data. The emphasis is on â€œdataâ€ because users can use a data frame of sparse vectors or the usual sparse matrix format. This is a big deal because it does not force you to convert non-numeric data into a numeric matrix format. Again, weâ€™ll discuss this more in the future, but you should be able to use sparse data frames in parsnip, recipes, tune, etc.\nThe second initiative is the longstanding goal of adding postprocessing to tidymodels. Just as you can add a preprocessor to a model workflow, you will be able to add a set of postprocessing adjustments to the predictions your model generates. See our \nprevious post for a sneak peek.\nFinally, this yearâ€™s \nsummer internship focuses on supervised feature selection methods. Weâ€™ll also have releases (and probably another package) for these tools.\nThese should come to fruition (and CRAN) before or around August 2025.\nAcknowledgements\n  \n    \n      \n\n      \n\n    \n  \n\nWe want to sincerely thank everyone who contributed to these packages since their previous versions:\n@AlbertoImg, \n@asb2111, \n@balraadjsings, \n@bcjaeger, \n@beansrowning, \n@BrennanAntone, \n@cheryldietrich, \n@chillerb, \n@conarr5, \n@corybrunson, \n@dajmcdon, \n@davidrsch, \n@Edgar-Zamora, \n@EmilHvitfeldt, \n@gaborcsardi, \n@gimholte, \n@grantmcdermott, \n@grouptheory, \n@hfrick, \n@ilaria-kode, \n@JamesHWade, \n@jesusherranz, \n@jkylearmstrong, \n@joranE, \n@joscani, \n@Joscelinrocha, \n@josho88, \n@joshuagi, \n@JosiahParry, \n@jrosell, \n@jrwinget, \n@KarlKoe, \n@kscott-1, \n@lilykoff, \n@lionel-, \n@LouisMPenrod, \n@luisDVA, \n@marcelglueck, \n@marcozanotti, \n@martaalcalde, \n@mattwarkentin, \n@mihem, \n@mitchellmanware, \n@naokiohno, \n@nhward, \n@npelikan, \n@obgeneralao, \n@owenjonesuob, \n@pbhogale, \n@Peter4801, \n@pgg1309, \n@reisner, \n@rfsaldanha, \n@rkb965, \n@RobLBaker, \n@RodDalBen, \n@SantiagoD999, \n@shum461, \n@simonpcouch, \n@szimmer, \n@talegari, \n@therealjpetereit, \n@topepo, \n@walkerjameschris, and  \n@ZWael",
    "link": "https://www.tidyverse.org/blog/2025/02/tidymodels-2025-q1/",
    "pubDate": "Thu, 27 Feb 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "Air, an extremely fast R formatter",
    "description": "Weâ€™re thrilled to announce \nAir, an extremely fast R formatter. Formatters are used to automatically style code, but I find that itâ€™s much easier to show what Air can do rather than tell, so weâ€™ll start with a few examples. In the video below, weâ€™re inside \nPositron and weâ€™re looking at some unformatted code. Saving the file (yep, thatâ€™s it!) invokes Air, which automatically and instantaneously formats the code.\nNext, letâ€™s go over to \nRStudio. Here weâ€™ve got a pipe chain that could use a little formatting. Like in Positron, just save the file:\nLastly, weâ€™ll jump back into Positron. Rather than formatting a single file on save, you might want to instead format an entire project (particularly when first adopting Air). To do so, just run air format . in a terminal from the project root, and Air will recursively format any R files it finds along the way (smartly excluding known generated files, like cpp11.R). Here weâ€™ll run Air on dplyr for the first time ever, analyzing and reformatting over 150 files instantly:\nWithin the tidyverse, weâ€™re already using Air in some of our largest packages, like \ndplyr, \ntidyr, and \nrecipes.\nThroughout the rest of this post youâ€™ll learn what a formatter is, why youâ€™d want to use one, and youâ€™ll learn a little about how Air decides to format your R code.\nNote that Air is still in beta, so there may be some breaking changes over the next few releases. We also encourage you to use it in combination with a version control system, like git, so that you can clearly see the changes Air makes. That said, we still feel very confident in the current state of Air, and canâ€™t wait for you to try it!\nInstalling Air\n  \n    \n      \n\n      \n\n    \n  \n\nIf you already know how formatters work and want to jump straight in, follow one of the guides below:\nFor Positron, Air is \navailable on OpenVSX as an Extension. Install it from the Extensions pane within Positron, then read our \nPositron guide.\nFor VS Code, Air is \navailable on the VS Code Marketplace as an Extension. Install it from the Extensions pane within VS Code, then read our \nVS Code guide.\nFor RStudio, Air can be set as an external formatter, but youâ€™ll need to install the command line tool for Air first. Read our \nRStudio guide to get started. Note that this is an experimental feature on the RStudio side, so the exact setup may change a little until it is fully stabilized.\nFor command line users, Air binaries can be installed using our \nstandalone installer scripts.\nFor both Positron and VS Code, the most important thing to enable after installing the extension is format on save for R. You can do that by adding these lines to your settings.json file:\n{\n    \"[r]\": {\n        \"editor.formatOnSave\": true\n    }\n}\n\n\nTo open your settings.json file, run one of the following from the Command Palette:\nRun Preferences: Open User Settings (JSON) to modify global user settings.\nRun Preferences: Open Workspace Settings (JSON) to modify project specific settings. You may want to use this instead of setting the user level setting if you drop in on multiple projects, but not all of them use Air. If you work on a project with collaborators, we recommend that you check in these project specific settings to your repository to ensure that every collaborator is using the same formatting settings.\nIf your preferred editor isnâ€™t listed here, but does support the \nLanguage Server Protocol, then it is likely that we can add support for Air there as well.\nIf you have any questions or run into issues installing or using Air, feel free to open an \nissue!\nWhatâ€™s a formatter?\n  \n    \n      \n\n      \n\n    \n  \n\nA formatter is in charge of the layout of your R code. Formatters do not change the meaning of code; instead they ensure that whitespace, newlines, and other punctuation conform to a set of rules and standards, such as:\nMaking sure your code is indented with the appropriate amount of leading whitespace. By default, Air uses 2 spaces for indentation. You will see this indentation in pipelines:\ndata |>\n  ggplot(aes(x, y)) +\n  geom_point()\n\n\nAs well as in function calls:\nlist(\n  foo = 1,\n  bar = 2\n)\n\n\nPreventing your code from overflowing a given line width. By default, Air uses a line width of 80 characters. It enforces this by splitting long lines of code over multiple lines. For instance, notice how long these expressions are, they would â€œoverflowâ€ past 80 characters:\nband_members |> select(name) |> full_join(band_instruments2, by = join_by(name == artist))\n\nleft_join <- function(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = NULL) {\n  UseMethod(\"left_join\")\n}\n\n\nAir reformats these expressions by switching them from a horizontal layout (called â€œflatâ€) to a vertical one (called â€œexpandedâ€):\nband_members |> \n  select(name) |> \n  full_join(band_instruments2, by = join_by(name == artist))\n\nleft_join <- function(\n  x,\n  y,\n  by = NULL,\n  copy = FALSE,\n  suffix = c(\".x\", \".y\"),\n  ...,\n  keep = NULL\n) {\n  UseMethod(\"left_join\")\n}\n\n\nStandardizing the whitespace around code elements. Have you ever had difficulties deciphering very dense code?\n1+2:3*(4/5)\n\n\nAir reformats this expression to:\n1 + 2:3 * (4 / 5)\n\n\nHow does a formatter improve your workflow?\n  \n    \n      \n\n      \n\n    \n  \n\nBy using a formatter it might seem like youâ€™re giving up control over the layout of your code. And indeed you are! However, putting Air in charge of styling your code has substantial advantages.\nFirst, it automatically forces you to write legible code that is neither too wide nor too narrow, with proper breathing room around syntactic elements. Having a formatter as a companion significantly improves the process of writing code as you no longer have to think about style - the formatter does that for you!\nSecond, it reduces friction when working in a team. By agreeing to use a formatter in a project, collaborators no longer have to discuss styling and layout issues. Code sent to you by a colleague will adhere to the standards that youâ€™re used to. Code review no longer has to be about style nitpicks and can focus on the substance of the changes instead.\nHow does Air decide how to format your code?\n  \n    \n      \n\n      \n\n    \n  \n\nAir tries to strike a balance between enforcing rigid rules and allowing authors some control over the layout. Our main source of styling rules is the \nTidyverse style guide, but we occasionally deviate from these.\nThere is a trend among modern formatters of being opinionated. Air certainly fits this trend and provides very few \nconfiguration options, mostly: the indent style (spaces versus tabs), the indent width, and the line width. However, Air also puts code authors in charge of certain aspects of the layout through the notion of persistent line breaks.\nIn general, Air is in control of deciding where to put vertical space (line breaks) in your code. For instance if you write:\ndictionary <- list(bob = \"apple\",\n  jill = \"juice\")\n\n\nAir will figure out that this expression fits on a single line without exceeding the line width. It will discard the line break and reformat to:\ndictionary <- list(bob = \"apple\", jill = \"juice\")\n\n\nHowever there are very specific places at which you can insert a line break that Air perceives as persistent:\nBefore the very first argument in a function call. This:\n# Persistent line break after `(` and before `bob`\ndictionary <- list(\n  bob = \"apple\", jill = \"juice\")\n\n\ngets formatted as:\ndictionary <- list(\n  bob = \"apple\", \n  jill = \"juice\"\n)\n\n\nBefore the very first right-hand side expression in a pipeline. This:\n# Persistent line break after `|>` and before `select`\ndata |>\n  select(foo) |> filter(!bar)\n\n\ngets formatted as:\ndata |>\n  select(foo) |>\n  filter(!bar)\n\n\nA persistent line break will never be removed by Air. But you can remove it manually. Taking the last example, if you join the first lines like this:\n# Removed persistent line break after `(`\ndictionary <- list(bob = \"apple\", \n  jill = \"juice\"\n)\n\n# Removed persistent line break after `|>`\ndata |> select(foo) |>\n  filter(!bar)\n\n\nAir will recognize that youâ€™ve removed the persistent line break, and reformat as:\ndictionary <- list(bob = \"apple\", jill = \"juice\")\n\ndata |> select(foo) |> filter(!bar)\n\n\nThe goal of this feature is to strike a balance between being opinionated and recognizing that users often know when taking up more vertical space results in more readable output.\nHow can I disable formatting?\n  \n    \n      \n\n      \n\n    \n  \n\nIf you need to disable formatting for a single expression, you can use a # fmt: skip comment. This is particularly useful for manual alignment.\n# This skips formatting for `list()` and its arguments, retaining the manual alignment\n# fmt: skip\nlist(\n  dollar = \"USA\",\n  yen    = \"Japan\",\n  yuan   = \"China\"\n)\n\n# This skips formatting for `tribble()` and its arguments\n# fmt: skip\ntribble(\n  ~x, ~y,\n   1,  2,\n)\n\n\nIf there is a file that Air should skip altogether, you can use a # fmt: skip file comment at the very top of the file.\nTo learn more about these features, see the \ndocumentation.\nHow can I use Air?\n  \n    \n      \n\n      \n\n    \n  \n\nAs weâ€™ve touched on above, Air can be integrated into your IDE to format code on every save. We expect that this will be the most common way to invoke Air, but there are a few other ways to use Air that we think are pretty cool:\nIn IDEs:\nFormat on save\nFormat selection\nAt the command line:\nFormat entire projects with air format .\nSet up a git precommit hook to invoke Air before committing\nIn CI:\nUse a GitHub Action to check that each PR conforms to formatting standards with air format . --check1\nUse a GitHub Action to automatically format each PR by pushing the results of air format as a commit\nWe donâ€™t have guides for all of these use cases yet, but the best place to stay up to date is the \nAir website.\nHow is this different from styler?\n  \n    \n      \n\n      \n\n    \n  \n\nAir would not exist without the preexisting work and dedication poured into \nstyler. Created by \nLorenz Walthert and \nKirill MÃ¼ller, styler proved that the R community does care about how their code is formatted, and has been the primary implementation of the \ntidyverse style guide for many years. Weâ€™ve spoken to Lorenz about Air, and we are all very excited about what Air can do for the future of formatting in R.\nAir is different from styler in a few key ways:\nAir is much faster. So much so that it enables new ways of using a formatter that were somewhat painful before, like formatting on every save, or formatting entire projects on every pull request.\nAir is less configurable. As mentioned above, Air provides very few \nconfiguration options.\nAir respects a line width, with a default of 80 characters.\nAir does not require R to run. Unlike styler, which is an R package, Air is written in Rust and is distributed as a pre-compiled binary for many platforms. This makes Air easy to use across IDEs or on CI with very little setup required.\nHow fast is â€œextremely fastâ€?\n  \n    \n      \n\n      \n\n    \n  \n\nAir is written in Rust using the formatting infrastructure provided by \nBiome2. This is also the same infrastructure that \nRuff, the fast Python formatter, originally forked from. Both of those projects are admired for their performance, and Air is no exception.\nOne goal for Air is for â€œformat on saveâ€ to be imperceptibly fast, encouraging you to keep it on at all times. Benchmarking formatters is a bit hand wavy due to some having built in caching, so bear with me, but one way to proxy this performance is by formatting a large single file, for example the 800+ line \njoin.R in dplyr. Formatting this takes3:\n0.01 seconds with Air\n1 second with styler (no cache)\nSo, ~100x faster for Air! If you make a few changes in the file after the first round of formatting and run the formatter again, then you get something like:\n0.01 seconds with Air\n0.5 seconds with styler (with cache)\nHalf a second for styler might not sound that bad (and indeed, for a formatter written in R itâ€™s pretty good), but itâ€™s slow enough that youâ€™ll â€œfeelâ€ it if you try and invoke styler on every save. But 0.01 seconds? Youâ€™ll never even know its running!\nThe differences get even more drastic if you format entire projects. Formatting the ~150 R files in dplyr takes4:\n0.3 seconds with Air\n100 seconds with styler\nOver 300x faster!\nOut of curiosity, we also ran Air over all ~900 R files in base R and it finished in under 2 seconds.\nWrapping up\n  \n    \n      \n\n      \n\n    \n  \n\nBy contributing this formatter to the R community, our objective is threefold:\nVastly improve your enjoyment of writing well-styled R code by removing the chore of editing whitespace.\nReduce friction in collaborative projects by establishing a consistent style once and for all.\nImprove the overall readability of R code for the community.\nWe hope that Air will prove to be a valuable companion in your daily workflow!\nThe Shiny team already has a \nGitHub Action to help with this. We will likely work on refining this and incorporating it more officially into an Air or r-lib repository. â†©ï¸Ž\nBiome is an open source project maintained by community members, please consider \nsponsoring them! â†©ï¸Ž\nThese benchmarks were run with air format R/join.R and styler::style_file(\"R/join.R\"). â†©ï¸Ž\nWith air format . and \nstyler::style_pkg() â†©ï¸Ž",
    "link": "https://www.tidyverse.org/blog/2025/02/air/",
    "pubDate": "Fri, 21 Feb 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "Three experiments in LLM code assist with RStudio and Positron",
    "description": "The last few months, Iâ€™ve been exploring how AI/LLMs might make my time developing R packages and doing data science more productive. This post will describe three experimental R packagesâ€”\npal, \nensure, and \nganderâ€”that came out of that exploration, and the core tools underlying them. Taken together, Iâ€™ve found that these packages allow me to automate many of the less interesting parts of my work, turning all sorts of 45-second tasks into 5-second ones. Excitement from folks in the community has been very encouraging so far, and Iâ€™m looking forward to getting each of these packages buttoned up and sent off to CRAN in the coming weeks!\nBackground\n  \n    \n      \n\n      \n\n    \n  \n\nTwice a year, the tidyverse team sets a week aside for â€œspring cleaning,â€ bringing all of our R packages up to snuff with the most current tooling and standardizing various bits of our development process. Some of these updates can happen by calling a single function, while others are much more involved. One of those more involved updates is updating erroring code, transitioning away from base R (e.g.Â \nstop()), rlang (e.g.Â \nrlang::abort()), \nglue, and homegrown combinations of them. cliâ€™s new syntax is easier to work with as a developer and more visually pleasing as a user.\nIn some cases, transitioning is almost as simple as Finding + Replacing \nrlang::abort() to \ncli::cli_abort():\n# before:\nrlang::abort(\"`save_pred` can only be used if the initial results saved predictions.\")\n\n# after: \ncli::cli_abort(\"{.arg save_pred} can only be used if the initial results saved predictions.\")\n\n\nIn others, thereâ€™s a mess of ad-hoc pluralization, \npaste0()s, glue interpolations, and other assorted nonsense to sort through:\n# before:\nextra_grid_params <- glue::single_quote(extra_grid_params)\nextra_grid_params <- glue::glue_collapse(extra_grid_params, sep = \", \")\n\nmsg <- glue::glue(\n  \"The provided `grid` has the following parameter columns that have \",\n  \"not been marked for tuning by `tune()`: {extra_grid_params}.\"\n)\n\nrlang::abort(msg)\n\n# after:\ncli::cli_abort(\n  \"The provided {.arg grid} has parameter columns that have not been\n   marked for tuning by {.fn tune}: {.val {extra_grid_params}}.\"\n)\n\n\nTotal pain, especially with thousands upon thousands of error messages thrown across the tidyverse, r-lib, and tidymodels organizations.\nThe week before our most recent spring cleaning, I participated in an internal Posit LLM hackathon, where a small group of employees would familiarize with interfacing with LLMs via APIs and then set aside a day or two to build something to make their work easier. Heading into our spring cleaning and dreading the task of updating thousands of these calls, I decided to look into how effectively LLMs could help me convert this code. Thus was born \nclipal1, a (now-superseded) R package that allows users to select erroring code, press a keyboard shortcut, wait a moment, and watch the updated code be inlined in to the selection.\n\nclipal was a huge boost for us in the most recent spring cleaning. Depending on the code being updated, these erroring calls used to take 30 seconds to a few minutes. With clipal, though, the model could usually get the updated code 80% or 90% of the way there in a couple seconds. Up to this point, irritated by autocomplete and frustrated by the friction of copying and pasting code and typing out the same bits of context into chats again and again, I had been relatively skeptical that LLMs could make me more productive. After using clipal for a week, though, I began to understand how seamlessly LLMs could automate the cumbersome and uninteresting parts of my work.\nclipal itself is now superseded by pal, a more general solution to the problem that clipal solved. Iâ€™ve also written two additional packages like pal that solve two other classes of pal-like problems using similar tools, ensure and gander. In this post, Iâ€™ll write a bit about how Iâ€™ve used a pair of tools in three experiments that have made me much more productive as an R developer.\nPrerequisites: ellmer and the RStudio API\n  \n    \n      \n\n      \n\n    \n  \n\nWhile clipal is now superseded, the package that supersedes it and its other two descendants makes use of the same two tools: \nellmer and the \nRStudio API.\nLast year, Hadley Wickham and Joe Cheng began work on ellmer, a package that aims to make it easy to use large language models in R. For folks that have tried to use LLM APIs through HTTP requests, or interfaced with existing tools that wrap them like langchain, ellmer is pretty incredible. R users can initialize a Chat object using a predictably named function:\nlibrary(ellmer)\n\n# to use a model like GPT-4o or GPT-4o-mini from OpenAI:\nch <- chat_openai()\n\n# ...or a locally hosted ollama model:\nch <- chat_ollama()\n\n# ...or Claude's Sonnet model:\nch <- chat_claude()\n\n\nThen calling the outputâ€™s $chat() method returns a character response:\nch$chat(\"When was R created? Be brief.\")\n#> R was created in 1993 by Ross Ihaka and Robert Gentleman at \n#> the University of Auckland, New Zealand.\n\n\nThereâ€™s a whole lot more to ellmer, but this functionality alone was enough to make clipal happen. I could allow users to choose a Chat from whatever provider they prefer to power the addin and ellmer would take care of all of the details underneath the hood.\nThe other puzzle piece here was how to get that character vector directly into the file so that the user didnâ€™t have to copy and paste code from a chat interface into their document. The RStudio IDE supplies an API to interface with various bits of the RStudio UI through R code via the rstudioapi package. Notably, through R code, the package can read whatâ€™s inside of the userâ€™s active selection and also write character vectors into that range. clipal could thus:\nWhen triggered, read whatâ€™s inside of the selection using rstudioapi.\nPass that selection contents to an LLM along with a system prompt describing how to convert R erroring code to use cli using ellmer. (If youâ€™re curious, the current draft of that prompt is \nhere.)\nWhen the response is returned, replace the contents of the selection with the response using cli.\nThis approach of using ellmer and the rstudioapi has its ups and downs. As for the advantages:\nOur \nPositron IDE has â€œshimsâ€ of the RStudio API, so whatever works in RStudio will also work in Positron. This means that the same shortcuts can be mapped to the same tool in either IDE and it will just work without me, as the developer, having to do anything.2\nSince these packages are written in R, they have access to your R environment. This is quite the differentiator compared to the more language-agnostic tools out thereâ€”these packages can see the data frames you have loaded, the columns and column types in them, etc. When working with other tools for LLM code-assist that donâ€™t have this information, the friction of printing out variable information from my R environment and pasting it into whatever interface is so high that I donâ€™t even ask LLMs for help with tasks theyâ€™re otherwise totally capable of.\nUsing ellmer under the hood means that, once R users have set up model connections with ellmer, they can use the same configuration with any of these packages with minimal additional effort. So, clipal and the packages that followed it support whatever model providers their users want to useâ€”OpenAI, Claude, local ollama models, and so on. If you can use it with ellmer, you can use it with these packages.\nAs for the disadvantages, there are all sorts of UI bummers about this approach. Above all, these packages write directly to your files. This is great in that it removes the need to copy and paste, and when the modelâ€™s response is spot on, itâ€™s awesome. At the same time, if the model starts rambling in an .R file or you want to confirm some difference between your previous code and the new code, the fact that these packages just write right into your files can be a bit annoying. Many other inline LLM code-assist tools out there are based on diffsâ€”they show you proposed changes and some UI element that allows you to accept them, reject them, or ask for revisions. This requires one more step between asking for an LLM to do something and the thing actually being done, but saves the pain of lots of undoing or manually retrieving what code used to look like to verify the modelâ€™s work.\npal\n  \n    \n      \n\n      \n\n    \n  \n\nAfter using clipal during our spring cleaning, I approached another spring cleaning task for the week: updating testing code. testthat 3.0.0 was released in 2020, bringing with it numerous changes that were both huge quality of life improvements for package developers and also highly breaking changes. While some of the task of converting legacy unit testing code to testthat 3e is relatively straightforward, other components can be quite tedious. Could I do the same thing for updating to testthat 3e that I did for transitioning to cli? I sloppily threw together a sister package to clipal that would convert tests for errors to snapshot tests, disentangle nested expectations, and transition from deprecated functions like â expect_known_*(). â (If youâ€™re interested, the current prompt for that functionality is \nhere.) That sister package was also a huge boost for me, but the package reused as-is almost every piece of code from clipal other than the prompt. Thus, I realized that the proper solution would provide all of this scaffolding to attach a prompt to a keyboard shortcut, but allow for an arbitrary set of prompts to help automate these wonky, cumbersome tasks.\nThe next week, \npal was born. The pal package ships with three prompts centered on package development: the cli pal and testthat pal mentioned previously, as well as the roxygen pal, which drafts minimal roxygen documentation based on a function definition. Hereâ€™s what palâ€™s interface looks like now:\n\nUsers can add custom prompts for whatever tasks they please and theyâ€™ll be included in the searchable dropdown shown above.\nIâ€™ve been super appreciative of all of the love the package has received already, and Iâ€™ll be sending the package out to CRAN in the coming weeks.\nensure\n  \n    \n      \n\n      \n\n    \n  \n\nWhile deciding on the initial set of prompts that pal would include, I really wanted to include some sort of â€œwrite unit tests for this functionâ€ pal. To really address this problem, though, requires violating two of palâ€™s core assumptions:\nAll of the context that you need is in the selection and the prompt. In the case of writing unit tests, itâ€™s actually pretty important to have other pieces of context. If a package provides some object type potato, in order to write tests for some function that takes potato as input, itâ€™s likely very important to know how potatoes are created and the kinds of properties they have. palâ€™s sister package for writing unit tests, ensure, can thus â€œseeâ€ the rest of the file that youâ€™re working on, as well as context from neighboring files like other .R source files, the corresponding test file, and package vignettes, to learn about how to interface with the function arguments being tested.\nThe LLMâ€™s response can prefix, replace, or suffix the active selection in the same file. In the case of writing unit tests for R, the place that tests actually ought to go is in a corresponding test file in tests/testthat/. Via the RStudio API, ensure can open up the corresponding test file and write to it rather than the source file where it was triggered from.3\n\nSo far, I havenâ€™t spent as much time with ensure as I have with pal or gander, but Iâ€™ll be revisiting the package and sending it off to CRAN in the coming weeks.\ngander\n  \n    \n      \n\n      \n\n    \n  \n\n\npal really excels at things you do all the time. Providing custom prompts with lots of details about code syntax and your taste means that models will often provide code thatâ€™s almost exactly what youâ€™d write yourself. On its own, though, pal is incomplete as a toolkit for LLM code-assist. What about one-off requests that are specific to the environment that Iâ€™m working in or things I only do every once in a long while? Itâ€™s nice to have a much more general tool that functions much more like a chat interface.\nAt the same time, working with usual chat interfaces is quite high-friction, so much so that youâ€™ll likely spend more time pasting in context from your files and R environmet than you would if you had just written the code yourself. There are all sorts of language-agnostic interfaces (or language-specific but not for R or RStudio) tools out there implementing this. You type some request with your cursor near some code, and then, in the backend, the tool assembles a bunch of context that will help the model respond more effectively. This is super helpful for many software engineering contexts, where most all of the context you need can be found in the contents of files. Data science differs a bit from software engineering here, though, in that the state of your R environment is just as important (or more so) than the contents of your files. For example, the lines of your files may show that you reference some data frame called stackoverflow, but what will really help a model write R code to interface with that data frame is â€œseeingâ€ it: what columns are in it, and what are their types and distributions? gander is a chat interface that allows models to see the data youâ€™re working with.\n\nBehind the scenes, gander combines your selection (or lack thereof), inputted request, file type and contents, and R environment to dynamically assemble prompts to best enable models to tailor their responses to your R session. I use gander several times every day to turn 45-second tasks into 5-second ones and have been super stoked with how well-received itâ€™s been among R folks so far. Compared to pal and ensure, this package feels like a much more substantial lift for data scientists specifically (rather than package developers). In the coming weeks, Iâ€™ll sand down some of its rough edges and send it off to CRAN.\nWhatâ€™s next?\n  \n    \n      \n\n      \n\n    \n  \n\nFor now, all of these packages only live on my GitHub profile. In the coming weeks, I plan to revisit each of them, squash a bunch of bugs, and send them off to CRAN.\nThat said, these packages are very much experimental. The user interface of writing directly to usersâ€™ files very much limits how useful these tools can be, and I think that the kinds of improvements to interface Iâ€™m hoping for may only be possible via some backend other than the RStudio API. Iâ€™m looking forward to seeing what that could look like.\nPronounced â€œc-l-i pal.â€ â†©ï¸Ž\nIn reality, there are bugs and differences here and there, but the development effort to get these packages working in Positron was relatively minimal. â†©ï¸Ž\nThis is one gap between the RStudio API and Positronâ€™s shims for it. The Positron shims currently donâ€™t allow for toggling between files, so ensure isnâ€™t available in Positron. â†©ï¸Ž",
    "link": "https://www.tidyverse.org/blog/2025/01/experiments-llm/",
    "pubDate": "Wed, 29 Jan 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "nanoparquet 0.4.0",
    "description": "5x height\n* [x] [`hugodown::use_tidy_thumbnails()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html)\n* [x] Add intro sentence, e.g. the standard tagline for the package\n* [x] [`usethis::use_tidy_thanks()`](https://usethis.r-lib.org/reference/use_tidy_thanks.html)\n-->\nWeâ€™re thrilled to announce the release of \nnanoparquet 0.4.0. nanoparquet is an R package that reads and writes Parquet files.\nYou can install it from CRAN with:\ninstall.packages(\"nanoparquet\")\n\n\nThis blog post will show the most important new features of nanoparquet 0.4.0: You can see a full list of changes in the \nrelease notes.\nBrand new read_parquet()\n  \n    \n      \n\n      \n\n    \n  \n\nnanoparquet 0.4.0 comes with a completely rewritten Parquet reader. The new version has an architecture that is easier to embed into R, and facilitates fantastic new features, like \nappend_parquet() and the new col_select argument. (More to come!) The new reader is also much faster, see the â€œBenchmarksâ€ chapter.\nRead a subset of columns\n  \n    \n      \n\n      \n\n    \n  \n\nread_parquet() now has a new argument called col_select, that lets you read a subset of the columns from the Parquet file. Unlike for row oriented file formats like CSV, this means that the reader never needs to touch the columns that are not needed for. The time required for reading a subset of columns is independent of how many more columns the Parquet file might have!\nYou can either use column indices or column names to specify the columns to read. Here is an example.\nlibrary(nanoparquet)\nlibrary(pillar)\nThis is the \nnycflights13::flights data set:\nread_parquet(\n  \"flights.parquet\",\n  col_select = c(\"dep_time\", \"arr_time\", \"carrier\")\n)\n#> # A data frame: 336,776 Ã— 3\n#>    dep_time arr_time carrier\n#>       <int>    <int> <chr>  \n#>  1      517      830 UA     \n#>  2      533      850 UA     \n#>  3      542      923 AA     \n#>  4      544     1004 B6     \n#>  5      554      812 DL     \n#>  6      554      740 UA     \n#>  7      555      913 B6     \n#>  8      557      709 EV     \n#>  9      557      838 B6     \n#> 10      558      753 AA     \n#> # â„¹ 336,766 more rows\n\nUse \nread_parquet_schema() if you want to see the structure of the Parquet file first:\nread_parquet_schema(\"flights.parquet\")\n#> # A data frame: 20 Ã— 12\n#>    file_name       name  r_type type  type_length repetition_type converted_type\n#>    <chr>           <chr> <chr>  <chr>       <int> <chr>           <chr>         \n#>  1 flights.parquet scheâ€¦ NA     NA             NA NA              NA            \n#>  2 flights.parquet year  integâ€¦ INT32          NA REQUIRED        INT_32        \n#>  3 flights.parquet month integâ€¦ INT32          NA REQUIRED        INT_32        \n#>  4 flights.parquet day   integâ€¦ INT32          NA REQUIRED        INT_32        \n#>  5 flights.parquet dep_â€¦ integâ€¦ INT32          NA OPTIONAL        INT_32        \n#>  6 flights.parquet scheâ€¦ integâ€¦ INT32          NA REQUIRED        INT_32        \n#>  7 flights.parquet dep_â€¦ double DOUBâ€¦          NA OPTIONAL        NA            \n#>  8 flights.parquet arr_â€¦ integâ€¦ INT32          NA OPTIONAL        INT_32        \n#>  9 flights.parquet scheâ€¦ integâ€¦ INT32          NA REQUIRED        INT_32        \n#> 10 flights.parquet arr_â€¦ double DOUBâ€¦          NA OPTIONAL        NA            \n#> 11 flights.parquet carrâ€¦ charaâ€¦ BYTEâ€¦          NA REQUIRED        UTF8          \n#> 12 flights.parquet fligâ€¦ integâ€¦ INT32          NA REQUIRED        INT_32        \n#> 13 flights.parquet tailâ€¦ charaâ€¦ BYTEâ€¦          NA OPTIONAL        UTF8          \n#> 14 flights.parquet origâ€¦ charaâ€¦ BYTEâ€¦          NA REQUIRED        UTF8          \n#> 15 flights.parquet dest  charaâ€¦ BYTEâ€¦          NA REQUIRED        UTF8          \n#> 16 flights.parquet air_â€¦ double DOUBâ€¦          NA OPTIONAL        NA            \n#> 17 flights.parquet distâ€¦ double DOUBâ€¦          NA REQUIRED        NA            \n#> 18 flights.parquet hour  double DOUBâ€¦          NA REQUIRED        NA            \n#> 19 flights.parquet minuâ€¦ double DOUBâ€¦          NA REQUIRED        NA            \n#> 20 flights.parquet timeâ€¦ POSIXâ€¦ INT64          NA REQUIRED        TIMESTAMP_MICâ€¦\n#> # â„¹ 5 more variables: logical_type <I<list>>, num_children <int>, scale <int>,\n#> #   precision <int>, field_id <int>\n\nThe output of \nread_parquet_schema() also shows you the R type that nanoparquet will use for each column.\nAppending to Parquet files\n  \n    \n      \n\n      \n\n    \n  \n\nThe new \nappend_parquet() function makes it easy to append new data to a Parquet file, without first reading the whole file into memory. The schema of the file and the schema new data must match of course. Lets merge \nnycflights13::flights and \nnycflights23::flights:\nfile.copy(\"flights.parquet\", \"allflights.parquet\", overwrite = TRUE)\n#> [1] TRUE\nappend_parquet(nycflights23::flights, \"allflights.parquet\")\nread_parquet_info() returns the most basic information about a Parquet file:\nread_parquet_info(\"flights.parquet\")\n#> # A data frame: 1 Ã— 7\n#>   file_name       num_cols num_rows num_row_groups file_size parquet_version\n#>   <chr>              <int>    <dbl>          <int>     <dbl>           <int>\n#> 1 flights.parquet       19   336776              1   5687737               1\n#> # â„¹ 1 more variable: created_by <chr>\nread_parquet_info(\"allflights.parquet\")\n#> # A data frame: 1 Ã— 7\n#>   file_name          num_cols num_rows num_row_groups file_size parquet_version\n#>   <chr>                 <int>    <dbl>          <int>     <dbl>           <int>\n#> 1 allflights.parquet       19   772128              1  13490997               1\n#> # â„¹ 1 more variable: created_by <chr>\n\nNote that you should probably still create a backup copy of the original file when using \nappend_parquet(). If the appending process is interrupted by a power failure, then you might end up with an incomplete and invalid Parquet file.\nSchemas and type conversions\n  \n    \n      \n\n      \n\n    \n  \n\nIn nanoparquet 0.4.0 \nwrite_parquet() takes a schema argument that can customize the R to Parquet type mappings. For example by default \nwrite_parquet() writes an R character vector as a STRING Parquet type. If youâ€™d like to write a certain character column as an ENUM type1 instead, youâ€™ll need to specify that in schema:\nwrite_parquet(\n  nycflights13::flights,\n  \"newflights.parquet\",\n  schema = parquet_schema(carrier = \"ENUM\")\n)\nread_parquet_schema(\"newflights.parquet\")\n#> # A data frame: 20 Ã— 12\n#>    file_name       name  r_type type  type_length repetition_type converted_type\n#>    <chr>           <chr> <chr>  <chr>       <int> <chr>           <chr>         \n#>  1 newflights.parâ€¦ scheâ€¦ NA     NA             NA NA              NA            \n#>  2 newflights.parâ€¦ year  integâ€¦ INT32          NA REQUIRED        INT_32        \n#>  3 newflights.parâ€¦ month integâ€¦ INT32          NA REQUIRED        INT_32        \n#>  4 newflights.parâ€¦ day   integâ€¦ INT32          NA REQUIRED        INT_32        \n#>  5 newflights.parâ€¦ dep_â€¦ integâ€¦ INT32          NA OPTIONAL        INT_32        \n#>  6 newflights.parâ€¦ scheâ€¦ integâ€¦ INT32          NA REQUIRED        INT_32        \n#>  7 newflights.parâ€¦ dep_â€¦ double DOUBâ€¦          NA OPTIONAL        NA            \n#>  8 newflights.parâ€¦ arr_â€¦ integâ€¦ INT32          NA OPTIONAL        INT_32        \n#>  9 newflights.parâ€¦ scheâ€¦ integâ€¦ INT32          NA REQUIRED        INT_32        \n#> 10 newflights.parâ€¦ arr_â€¦ double DOUBâ€¦          NA OPTIONAL        NA            \n#> 11 newflights.parâ€¦ carrâ€¦ charaâ€¦ BYTEâ€¦          NA REQUIRED        ENUM          \n#> 12 newflights.parâ€¦ fligâ€¦ integâ€¦ INT32          NA REQUIRED        INT_32        \n#> 13 newflights.parâ€¦ tailâ€¦ charaâ€¦ BYTEâ€¦          NA OPTIONAL        UTF8          \n#> 14 newflights.parâ€¦ origâ€¦ charaâ€¦ BYTEâ€¦          NA REQUIRED        UTF8          \n#> 15 newflights.parâ€¦ dest  charaâ€¦ BYTEâ€¦          NA REQUIRED        UTF8          \n#> 16 newflights.parâ€¦ air_â€¦ double DOUBâ€¦          NA OPTIONAL        NA            \n#> 17 newflights.parâ€¦ distâ€¦ double DOUBâ€¦          NA REQUIRED        NA            \n#> 18 newflights.parâ€¦ hour  double DOUBâ€¦          NA REQUIRED        NA            \n#> 19 newflights.parâ€¦ minuâ€¦ double DOUBâ€¦          NA REQUIRED        NA            \n#> 20 newflights.parâ€¦ timeâ€¦ POSIXâ€¦ INT64          NA REQUIRED        TIMESTAMP_MICâ€¦\n#> # â„¹ 5 more variables: logical_type <I<list>>, num_children <int>, scale <int>,\n#> #   precision <int>, field_id <int>\n\nHere we wrote the carrier column as ENUM, and left the other other columns to use the default type mappings.\nSee the \n?nanoparquet-types manual page for the possible type mappings (lots of new ones!) and also for the default ones.\nEncodings\n  \n    \n      \n\n      \n\n    \n  \n\nIt is now also possible to customize the encoding of each column in \nwrite_parquet(), via the encoding argument. By default \nwrite_parquet() tries to choose a good encoding based on the type and the values of a column. E.g. it checks a small sample for repeated values to decide if it is worth using a dictionary encoding (RLE_DICTIONARY).\nIf \nwrite_parquet() gets it wrong, use the encoding argument to force an encoding. The following forces the PLAIN encoding for all columns. This encoding is very fast to write, but creates a larger file. You can also specify different encodings for different columns, see the \nwrite_parquet() manual page.\nwrite_parquet(\n  nycflights13::flights,\n  \"plainflights.parquet\",\n  encoding = \"PLAIN\"\n)\nfile.size(\"flights.parquet\")\n#> [1] 5687737\nfile.size(\"plainflights.parquet\")\n#> [1] 11954574\n\nSee more about the implemented encodings and how the defaults are selected in the \nparquet-encodings manual page.\nAPI changes\n  \n    \n      \n\n      \n\n    \n  \n\nSome nanoparquet functions have new, better names in nanoparquet 0.4.0. In particular, all functions that read from a Parquet file have a read_parquet prefix now. The old functions still work, with a warning.\nAlso, the \nparquet_schema() function is now for creating a new Parquet schema from scratch, and not for inferring a schema from a data frame (use \ninfer_parquet_schema()) or for reading the schema from a Parquet file (use \nread_parquet_schema()). \nparquet_schema() falls back to the old behaviour when called with a file name, with a warning, so this is not a breaking change (yet), and old code still works.\nSee the complete list of API changes in the \nChangelog.\nBenchmarks\n  \n    \n      \n\n      \n\n    \n  \n\nWe are very excited about the performance of the new Parquet reader, and the Parquet writer was always quite speedy, so we ran a simple benchmark.\nWe compared nanoparquet to the Parquet implementations in Apache Arrow and DuckDB, and also to CSV readers and writers, on a real data set, for samples of 330k, 6.7 million and 67.4 million rows (40MB, 800MB and 8GB in memory). For these data nanoparquet is indeed very competitive with both Arrow and DuckDB.\nYou can see the full results \non the website.\nOther changes\n  \n    \n      \n\n      \n\n    \n  \n\nOther important changes in nanoparquet 0.4.0 include:\nwrite_parquet() can now write multiple row groups. By default it puts at most 10 million rows in a single row group. (This is subject to https://nanoparquet.r-lib.org/references/parquet_options.html ) on how to change the default.\nwrite_parquet() now writes minimum and maximum statistics (by default) for most Parquet types. See the \nparquet_options() manual page on how to turn this off, which will probably make the writer faster.\nwrite_parquet() can now write version 2 data pages. The default is still version 1, but it might change in the future.\nNew compression_level option to select the compression level manually.\nread_parquet() can now read from an R connection.\nAcknowledgements\n  \n    \n      \n\n      \n\n    \n  \n\n@alvarocombo, \n@D3SL, \n@gaborcsardi, and \n@RealTYPICAL.\nA Parquet ENUM type is very similar to a factor in R. â†©ï¸Ž",
    "link": "https://www.tidyverse.org/blog/2025/01/nanoparquet-0-4-0/",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "httr2 1.1.0",
    "description": "5x height\n* [x] [`hugodown::use_tidy_thumbnails()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html)\n* [x] Add intro sentence, e.g. the standard tagline for the package\n* [x] [`usethis::use_tidy_thanks()`](https://usethis.r-lib.org/reference/use_tidy_thanks.html)\n-->\nWeâ€™re chuffed to announce the release of \nhttr2 1.1.0. httr2 (pronounced â€œhitter2â€) is a comprehensive HTTP client that provides a modern, pipeable API for working with web APIs. It builds on top of \n{curl} to provide features like explicit request objects, built-in rate limiting & retry tooling, comprehensive OAuth support, and secure handling of secrets and credentials.\nIn this blog post, weâ€™ll dive into the new streaming interface built around \nreq_perform_connection(), explore the new suite of URL manipulation tools, and highlight a few of the other biggest changes (including better support for AWS and enhancements to the caching system), and update you on the lifecycle changes.\nThis blog post includes the most important enhacenments in versions 1.0.1 through 1.0.7, where weâ€™ve been iterating on various features and fixing numerous bugs. For a complete list of changes, you can check the \nGitHub release notes or the \nNEWS file.\nInstallation\n  \n    \n      \n\n      \n\n    \n  \n\nInstall httr2 from CRAN with:\ninstall.packages(\"httr2\")\nStreaming data\n  \n    \n      \n\n      \n\n    \n  \n\nThe headline feature of this release is a better API for streaming responses, where the body is not available immediately but is streamed back over time. This is particularly important for interacting with LLMs, where itâ€™s needed to make chat responses feel snappy. You can try it out in \nellmer, our new package for chatting with LLMs from a variety of providers.\nThe most important new function is \nreq_perform_connection(), which supersedes the older callback-based \nreq_perform_stream(). Unlike its predecessor, \nreq_perform_connection() returns a regular response object with a connection object for the body:\nlibrary(httr2)\n\nreq <- request(example_url()) |> req_template(\"/stream-bytes/:n\", n = 10240)\nresp <- req_perform_connection(req)\nresp\n#> <httr2_response>\n#> GET http://127.0.0.1:49283/stream-bytes/10240\n#> Status: 200 OK\n#> Content-Type: application/octet-stream\n#> Body: Streaming connection\n\nOnce you have a streaming connection you can repeatedly call a resp_stream_*() function to pull down data in chunks, using \nresp_stream_is_complete() to figure out when to stop.\nwhile (!resp_stream_is_complete(resp)) {\n  bytes <- resp_stream_raw(resp, kb = 2)\n  cat(\"Downloaded \", length(bytes), \" bytes\\n\", sep = \"\")\n}\n#> Downloaded 2048 bytes\n#> Downloaded 2048 bytes\n#> Downloaded 2048 bytes\n#> Downloaded 2048 bytes\n#> Downloaded 2048 bytes\n#> Downloaded 0 bytes\n\nAs well as \nresp_stream_raw(), which returns a raw vector, you can use \nresp_stream_lines() to stream lines and \nresp_stream_sse() to stream \nserver-sent events.\nURL manipulation tools\n  \n    \n      \n\n      \n\n    \n  \n\nWorking with URLs got easier with three new functions: \nurl_modify(), \nurl_modify_query(), and \nurl_modify_relative(). You can see how they work in the examples below:\n# url_modify() modifies components of a URL\nurl_modify(\"https://example.com\", hostname = \"github.com\")\n#> [1] \"https://github.com/\"\nurl_modify(\"https://example.com\", scheme = \"http\")\n#> [1] \"http://example.com/\"\nurl_modify(\"https://example.com\", path = \"abc\", query = list(foo = \"bar\"))\n#> [1] \"https://example.com/abc?foo=bar\"\n\n# url_modify_query() lets you modify individual query parameters\n# modifying an existing parameter:\nurl_modify_query(\"http://example.com?a=1&b=2\", a = 10)\n#> [1] \"http://example.com/?b=2&a=10\"\n# delete a parameter:\nurl_modify_query(\"http://example.com?a=1&b=2\", b = NULL)\n#> [1] \"http://example.com/?a=1\"\n# add a new parameter:\nurl_modify_query(\"http://example.com?a=1&b=2\", c = 3)\n#> [1] \"http://example.com/?a=1&b=2&c=3\"\n\n# url_modify_relative() navigates to a relative URL\nurl_modify_relative(\"https://example.com/a/b/c.html\", \"/d/e/f.html\")\n#> [1] \"https://example.com/d/e/f.html\"\nurl_modify_relative(\"https://example.com/a/b/c.html\", \"C.html\")\n#> [1] \"https://example.com/a/b/C.html\"\nurl_modify_relative(\"https://example.com/a/b/c.html\", \"../B.html\")\n#> [1] \"https://example.com/a/B.html\"\n\nWe also added \nreq_url_relative() to make it easier to navigate to a relative URL for an existing request.\nOther improvements\n  \n    \n      \n\n      \n\n    \n  \n\nThere are a handful of other improvements that are worth highlighting:\nWeâ€™ve made it easier to talk to AWS web services with \nreq_auth_aws_v4() for signing requests and \nresp_stream_aws() for streaming responses. Special thanks goes to the \nlifion-aws-event-stream project for providing a clear reference implementation.\nWeâ€™ve run-down a long list of bugs that made \nreq_cache() unreliable. This includes improving the handling of header-only changes, better cache pruning, and new debugging options. If youâ€™re working with a web API that supports caching, we highly recommend that you try it out. The next release of {\ngh} will use a cache by default, and my use of the dev version suggests that it gives a pretty nice performance improvment.\nis_online() provides an easy way to check internet connectivity.\nreq_perform_promise() allows you to execute requests in the background (thanks to \n@gergness) using an efficient approach that waits on curl socket activity (thanks to \n@shikokuchuo).\nBreaking changes\n  \n    \n      \n\n      \n\n    \n  \n\nAs httr2 continues to mature, weâ€™ve made some lifecycle changes:\nreq_perform_iterative() is now stable and no longer experimental.\nreq_perform_stream() is superseded by \nreq_perform_connection(), as mentioned above.\nwith_mock() and \nlocal_mock() are defunct and will be rmeoved in the next release. Use \nwith_mocked_responses() and \nlocal_mocked_responses() instead.\nAcknowledgements\n  \n    \n      \n\n      \n\n    \n  \n\nA big thanks to all 76 folks who filed issues, created PRs and generally helped to make httr2 better! \n@Aariq, \n@AGeographer, \n@amael-ls, \n@anishjoni, \n@asadow, \n@atheriel, \n@awpsoras, \n@billsanto, \n@bonushenricus, \n@botan, \n@burgerga, \n@CareCT, \n@cderv, \n@cole-brokamp, \n@covid19ec, \n@datapumpernickel, \n@denskh, \n@deschen1, \n@DyfanJones, \n@erydit, \n@exetico, \n@fh-mthomson, \n@frzambra, \n@gergness, \n@GreenGrassBlueOcean, \n@guslipkin, \n@hadley, \n@i2z1, \n@isachng93, \n@IshuaWang, \n@JamesHWade, \n@jameslairdsmith, \n@JBGruber, \n@jcheng5, \n@jeroen, \n@jimbrig, \n@jjesusfilho, \n@jl5000, \n@jmuhlenkamp, \n@jonthegeek, \n@JosiahParry, \n@jwimberl, \n@krjaworski, \n@m-muecke, \n@maarten-vermeyen, \n@MarekGierlinski, \n@maxsutton, \n@mgirlich, \n@MichaelChirico, \n@mkoohafkan, \n@MSHelm, \n@mstei4176, \n@mthomas-ketchbrook, \n@NateNohling, \n@nick-youngblut, \n@pbulsink, \n@PietrH, \n@pkautio, \n@plietar, \n@pmlefeuvre-met, \n@rkrug, \n@romainfrancois, \n@salim-b, \n@shikokuchuo, \n@simplyalexander, \n@sluga, \n@stefanedwards, \n@steveputman, \n@tebancr, \n@thohan88, \n@tony2015116, \n@toobiwankenobi, \n@verhovsky, \n@walinchus, \n@werkstattcodes, and \n@zacdav-db.",
    "link": "https://www.tidyverse.org/blog/2025/01/httr2-1-1-0/",
    "pubDate": "Mon, 20 Jan 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "Updates to Text Rendering in R Graphics",
    "description": "5x height\n* [x] `hugodown::use_tidy_thumbnails()`\n* [ ] Add intro sentence, e.g. the standard tagline for the package\n* [ ] `usethis::use_tidy_thanks()`\n-->\n\ntext rendering is one of those disciplines where, if you think you finally got it right, you can be 100% certain that you didn't\nâ€” Thomas Lin Pedersen (@thomasp85.com) January 10, 2025 at 10:44 AM\n\nNo reason to hide the fact: Text rendering is complicated! When I set out to improve the support for modern text rendering features in R all those years ago, I donâ€™t think I truly appreciated that fact. And probably for the better, since Iâ€™m not sure I would have taken on the task had I known.\nTaking the quote above as a universal truth (it comes from a reputable source after all), Iâ€™m sure Iâ€™ll never be fully done, but recent work on the whole stack at least makes me worry less about the correctness. This post will go through the changes that span the \nsystemfonts, \ntextshaping, and \nmarquee packages and let you now how you, as a user or developer, should take advantage of them.\nWorking with non-installed fonts\n  \n    \n      \n\n      \n\n    \n  \n\nThe genesis of the systemfonts package was a need to be able to tap into the operating systems font library, so that whatever was installed on the system, would be available to graphics devices (assuming those devices used systemfonts). The scope of the package has gradually increased, and one of the needs that has become obvious over time, is a way to work with fonts, that arenâ€™t installed on the system (E.g. if you want to bundle a font with a package, or if you are deploying a Shiny app that uses a specific font for the graphics).\nUntil now, the register_font() and register_variant() functions have been the only option for letting systemfonts know about fonts other than those installed on the system. However, both of these functions were designed to circumvent limitations in the R graphics system when it comes to font selection (e.g. no way to use a â€œthinâ€ font variant as the only weight option in the graphics system is bold yes/no), and as such were clunky to use for introducing new fonts.\nWith the new version of systemfonts we get a dedicated way to tell systemfonts â€œplease consider these font files as equals to the installed onesâ€. The function is called add_fonts() and all you need to do is to pass in a vector of paths to font files and these will then be reachable by systemfonts.\n# Add fonts from specific files\nsystemfonts::add_fonts(c(\"path/to/font1.ttf\", \"path/to/font2.ttf\"))\n\n\nIn addition to this function, systemfonts also comes with scan_local_fonts() that looks in ./fonts and ~/fonts and adds any fonts located there. The function is called when systemfonts is loaded meaning that you can immediately uses fonts saved in these directories. This is great for deploying projects because all you need to do is to include a fonts folder at the root of you project and these fonts will then always be available wherever you deploy your code.\nWhile it is nice to have good access to the font files on your computer, the files has to come from somewhere. Nowadays that somewhere is usually \nGoogle Fonts or some other online font repository. systemfonts is now aware of a few of these repositories (Google Fonts and \nFont Squirrel for now), and can search and download from these (using search_web_fonts(), get_from_google_fonts(), and get_from_font_squirrel()). The downloaded fonts are automatically added using add_fonts() so they are immediately available, and by default they are placed in ~/fonts so that they persist across R sessions and projects.\n# Search and download fonts\nsystemfonts::get_from_font_squirrel(\"Quicksand\")\nsystemfonts::get_from_google_fonts(\"Rubik Moonrocks\")\n\n\nBut what if you donâ€™t want to think too much about all these details and just want to ensure that some specific font is available when a piece of code is running? In that case require_font() got you covered. This function allows you to state a dependency on a font in a script. The function scans the available fonts on the system and, if it doesnâ€™t find anything, proceeds to look for the font in the online repositories, downloading it if it finds it. If that also fails the function will either throw an error, or map the required font to a fallback of your choosing:\nlibrary(systemfonts)\nrequire_font(\"Rubik Moonrocks\")\n\nplot.new()\ntext(0.5, 0.5, \"Fancy Font\", family = \"Rubik Moonrocks\", cex = 6)\n\n\n\nRemember that all of these niceties only goes into effect if you use a graphics device that uses systemfonts. For now, that more or less means that you should use ragg (you should use ragg anyway so that is not a terrible requirement).\nGetting to the Glyphs\n  \n    \n      \n\n      \n\n    \n  \n\nMost fonts these days are based on a vector outline. That means that they can be scaled smoothly to any size and doesnâ€™t take up a lot of storage space. It also means that there are polygons inside the font files and that these can be extracted! This is now possible with systemfonts and the new glyph_outline() and glyph_raster() functions.\n# Get the location of the glyph inside the font\nmoonrocks <- font_info(\"Rubik Moonrocks\")\nG <- glyph_info(\"G\", path = moonrocks$path, index = moonrocks$index)\n\n# Extract the outline of the glyph and plot it\noutline <- glyph_outline(G$index, moonrocks$path, moonrocks$index, size = 400)\ngrid::grid.path(\n  x = outline$x,\n  y = outline$y + 20, # To raise the baseline a bit\n  id = outline$contour,\n  default.units = \"bigpts\",\n  gp = grid::gpar(fill = \"grey\", col = \"black\", lwd = 4)\n)\n\n\n\nExtracting them as polygons means that we can do all sorts of weird stuff with them if we so pleases:\n# Skew the glyph making it italic\ngrid::grid.path(\n  x = outline$x + outline$y * 0.4,\n  y = outline$y + 20, # To raise the baseline a bit\n  id = outline$contour,\n  default.units = \"bigpts\",\n  gp = grid::gpar(fill = \"grey\", col = \"black\", lwd = 4)\n)\n\n\n\n(real italic glyphs are designed to look good skewed, not just skewed versions of the regular glyphs)\nRemember how I said â€œmost fontsâ€ in the beginning of this section. There are still fonts that do not provide an outline, the prime example being most emoji fonts. The glyphs in such fonts are encoded as multiple bitmaps at fixed sizes (Microsofts emoji font going a different way by encoding them as SVGs). Since we canâ€™t get to the data as outlines we can instead extract it as a raster:\nemoji <- font_info(\"emoji\")\ndancer <- glyph_info(\"ðŸ’ƒ\", path = emoji$path, index = emoji$index)\nraster <- glyph_raster(dancer$index, emoji$path, emoji$index, size = 400)\ngrid::grid.draw(glyph_raster_grob(raster[[1]], 0, 50))\n\n\n\nIn the above we used the glyph_raster_grob() helper function to create a raster grob with the correct scaling of the resulting raster.\nRaster extraction is not only for bitmap encoded fonts since it is easy to go from an outline to a raster (but not the other way around). Freetype (which systemfonts uses) includes a very efficient scanline rasterizer (the same as used in ragg) and we can thus get a raster version of any font:\nraster2 <- glyph_raster(G$index, moonrocks$path, moonrocks$index, size = 400)\ngrid::grid.draw(glyph_raster_grob(raster2[[1]], 0, 20))\n\n\n\nThe Way the Text Flows\n  \n    \n      \n\n      \n\n    \n  \n\nThe thing that provoked me to writing the quote in the beginning of this blog post, was my work on the textshaping package. This package is largely invisible to the user but together with systemfonts it is responsible for laying out strings of text correctly. It figures out the location of every glyph and finds alternative fonts if the selected one doesnâ€™t contain the needed glyph. textshaping powers ragg as well as marquee, doing the heavy lifting of translating a string of text into glyphs and locations.\nPart of converting a string into glyphs and coordinates (a process known as text shaping) is to figure out which way the text flows and act accordingly. For many people left-to-right flow is the natural text direction, but this is merely a cultural bias and many scripts with a different flow exists (arabic and hebrew being the two most dominant right-to-left flowing scripts). So, part of shaping requires figuring out what script a specific character belongs to and what direction it flows. This is all fairly simple when a string internally agrees on the direction of flow, but can get much more complicated when scripts are embedded within other scripts that doesnâ€™t have the same flow (not to mention scripts embedded even deeper). Combine all of this with soft wrapping of text inside an embedded script and you got the recipe for a headache. textshaping (through me) already made the claim that it fully supported bi-directional text but it turned out that I severely misjudged the complexity. Because of this, the shaping engine has been rewritten almost from scratch. Based on the starting quote I canâ€™t quite claim that it now works 100% correctly but it does pass all 91.707 test cases for bidirectional text provided by the Unicode consortium so thereâ€™s that.\nAgain, it is unlikely that you will come into contact with textshaping directly so you will mostly experience these improvements in the way text just appears more correct (to the extend that this was ever an issue for you). The place you are most likely to stumble upon these changes is marquee, which uses textshaping under the hood. Styling in marquee has been expanded to include a text_direction setting. It defaults to \"auto\" which mean â€œdeduce it from the text you getâ€, but you can also set it to \"ltr\" or \"rtl\" to set the direction explicitly. Be aware that this setting doesnâ€™t change how single glyphs flow so you cannot use it to e.g. write arabic in left-to-right flow. Instead it governs the paragraph-level direction and thus how bi-directional text should be assembled. It also governs to which side indentation happen and the placement of bullets in bullet lists. Often, leaving it on the default value will work fine. There are also two new values for the align setting. \"auto\" picks either \"left\" or \"right\" depending on the text direction, while \"justified\" picks either \"justified-left\" or \"justified-right\". This makes it much easier to work natively with right-to-left text as everything just looks as it should. To top it off, classic_style() gains an ltr argument that controls whether the styling in general should cater to left-to-right or right-to-left text. It controls things such as the position of the grey bar in quotation blocks and the indentation of nested lists.\nlibrary(marquee)\n# Create a style specific for rtl text\nrtl_style <- classic_style(\n  text_direction = \"rtl\", # Forces bidi text to be assembled from right to left\n  align = \"auto\", # Will convert itself to \"right\"\n  ltr = FALSE # Will move bullet padding and bar along quote blocks to the right\n)\n\n\n\n\n\nA marquee for Everyone\n  \n    \n      \n\n      \n\n    \n  \n\nSpeaking of marquee, the biggest obstacle it has put in front of its users is that it is build on very new features in R. The ability to write text by placing glyphs one at a time was only added in R 4.2 and not every graphics device supports it yet (worse still, the implementation in the default macOS quartz device caused the session to crash). Again, ragg is your friend, but the Cairo devices also has excellent support.\nText rendering, however, should always work. It is quite frustrating for text to not show up when you expect it to. Because of this it has been a clear plan to expand the support for marquee somehow. With the new version of marquee this is finally a reality. How does it work? Well, remember when we talked about extracting glyph outlines and rasters? If marquee encounters a graphics device that doesnâ€™t provide the necessary features it will take matters into its own hands, by extracting all the necessary polygons and bitmaps and plot them. It is certainly not faster than relying on the optimized routines of the graphics device and it can also lead to visual degradation at smaller font sizes. But it works - everywhere.\nTo show it off, here is an svg created with svglite which doesnâ€™t have the required new features:\ntext <- \"_Fancy_ {.red Font}ðŸ“\"\n\nm_grob <- marquee_grob(\n  text,\n  classic_style(\n    body_font = \"Rubik Moonrocks\",\n    base_size = 72\n  )\n)\n\ns <- svglite::svgstring(width = 7, height = 1.5)\ngrid::grid.draw(m_grob)\ninvisible(dev.off())\n\ns()\n\n\n\n\n\n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you inspect the SVG above youâ€™ll see that rather than being made up of text elements it is a collection of path and image elements.\nAgain, it is unlikely that many people will use marquee like this. It is much more likely that they will encounter it through ggplot2 in the form of geom_marquee() and element_marquee(). The takeaway, however, is the same - it is now safe to use marquee even when you donâ€™t know which graphics device will be used to render the text with.\nWhatâ€™s Next?\n  \n    \n      \n\n      \n\n    \n  \n\nCircling back to the starting quote. Iâ€™m 100% certain Iâ€™m not done yet. I believe the next big push will be proper support for vertical text in textshaping (it currently only deals with horizontal text). I also have some plans to get marquee to automatically translate the numbers in ordered lists into their proper representation in the script that is being used, so that e.g. â€˜3.â€™ will be shown as â€˜.Ù£â€™ when used with Arabic text.",
    "link": "https://www.tidyverse.org/blog/2025/01/text-rendering-updates/",
    "pubDate": "Fri, 17 Jan 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "orbital 0.3.0",
    "description": "5x height\n* [x] [`hugodown::use_tidy_thumbnails()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html)\n* [x] Add intro sentence, e.g. the standard tagline for the package\n* [x] [`usethis::use_tidy_thanks()`](https://usethis.r-lib.org/reference/use_tidy_thanks.html)\n-->\nWeâ€™re thrilled to announce the release of \norbital 0.3.0. orbital lets you predict in databases using tidymodels workflows.\nYou can install it from CRAN with:\ninstall.packages(\"orbital\")\nThis blog post will cover the highlights, which are classification support and the new augment method.\nYou can see a full list of changes in the \nrelease notes.\nClassification support\n  \n    \n      \n\n      \n\n    \n  \n\nThe biggest improvement in this version is that \norbital() now works for supported classification models. See \nvignette for list of all supported models.\nLetâ€™s start by fitting a classification model on the penguins data set, using {xgboost} as the engine.\nrec_spec <- recipe(species ~ ., data = penguins) |>\n  step_unknown(all_nominal_predictors()) |>\n  step_dummy(all_nominal_predictors()) |>\n  step_impute_mean(all_numeric_predictors()) |>\n  step_zv(all_predictors())\n\nlr_spec <- boost_tree() |>\n  set_mode(\"classification\") |>\n  set_engine(\"xgboost\")\n\nwf_spec <- workflow(rec_spec, lr_spec)\nwf_fit <- fit(wf_spec, data = penguins)\nWith this fitted workflow object, we can call \norbital() on it to create an orbital object.\norbital_obj <- orbital(wf_fit)\norbital_obj\n#> \n#> â”€â”€ orbital Object â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> â€¢ island = dplyr::if_else(is.na(island), \"unknown\", island)\n#> â€¢ sex = dplyr::if_else(is.na(sex), \"unknown\", sex)\n#> â€¢ island_Dream = as.numeric(island == \"Dream\")\n#> â€¢ island_Torgersen = as.numeric(island == \"Torgersen\")\n#> â€¢ sex_male = as.numeric(sex == \"male\")\n#> â€¢ sex_unknown = as.numeric(sex == \"unknown\")\n#> â€¢ bill_length_mm = dplyr::if_else(is.na(bill_length_mm), 43.92193, bill_l ...\n#> â€¢ bill_depth_mm = dplyr::if_else(is.na(bill_depth_mm), 17.15117, bill_dep ...\n#> â€¢ flipper_length_mm = dplyr::if_else(is.na(flipper_length_mm), 201, flipp ...\n#> â€¢ body_mass_g = dplyr::if_else(is.na(body_mass_g), 4202, body_mass_g)\n#> â€¢ island_Dream = dplyr::if_else(is.na(island_Dream), 0.3604651, island_Dr ...\n#> â€¢ island_Torgersen = dplyr::if_else(is.na(island_Torgersen), 0.1511628, i ...\n#> â€¢ sex_male = dplyr::if_else(is.na(sex_male), 0.4883721, sex_male)\n#> â€¢ sex_unknown = dplyr::if_else(is.na(sex_unknown), 0.03197674, sex_unknow ...\n#> â€¢ Adelie = 0 + dplyr::case_when((bill_depth_mm < 15.1 | is.na(bill_depth_ ...\n#> â€¢ Chinstrap = 0 + dplyr::case_when((island_Dream < 0.5 | is.na(island_Dre ...\n#> â€¢ Gentoo = 0 + dplyr::case_when((bill_depth_mm < 15.95 | is.na(bill_depth ...\n#> â€¢ .pred_class = dplyr::case_when(Adelie > Chinstrap & Adelie > Gentoo ~ \" ...\n#> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> 18 equations in total.\n\nThis object contains all the information that is needed to produce predictions. Which we can produce with \npredict().\npredict(orbital_obj, penguins)\n#> # A tibble: 344 Ã— 1\n#>    .pred_class\n#>    <chr>      \n#>  1 Adelie     \n#>  2 Adelie     \n#>  3 Adelie     \n#>  4 Adelie     \n#>  5 Adelie     \n#>  6 Adelie     \n#>  7 Adelie     \n#>  8 Adelie     \n#>  9 Adelie     \n#> 10 Adelie     \n#> # â„¹ 334 more rows\n\nThe main thing to note here is that the orbital package produces character vectors instead of factors. This is done as a unifying approach since many databases donâ€™t have factor types.\nSpeaking of databases, you can \npredict() on an orbital object using tables from databases. Below we create an ephemeral in-memory RSQLite database.\nlibrary(DBI)\nlibrary(RSQLite)\n\ncon_sqlite <- dbConnect(SQLite(), path = \":memory:\")\npenguins_sqlite <- copy_to(con_sqlite, penguins, name = \"penguins_table\")\nAnd we can predict with it like normal. All the calculations are sent to the database for execution.\npredict(orbital_obj, penguins_sqlite)\n#> # Source:   SQL [?? x 1]\n#> # Database: sqlite 3.47.1 []\n#>    .pred_class\n#>    <chr>      \n#>  1 Adelie     \n#>  2 Adelie     \n#>  3 Adelie     \n#>  4 Adelie     \n#>  5 Adelie     \n#>  6 Adelie     \n#>  7 Adelie     \n#>  8 Adelie     \n#>  9 Adelie     \n#> 10 Adelie     \n#> # â„¹ more rows\n\nThis works the same with \nmany types of databases.\nClassification is different from regression in part because it comes with multiple prediction types. The above example showed the default which is hard classification. You can set the type of prediction you want with the type argument to orbital. For classification models, possible options are \"class\" and \"prob\".\norbital_obj_prob <- orbital(wf_fit, type = c(\"class\", \"prob\"))\norbital_obj_prob\n#> \n#> â”€â”€ orbital Object â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> â€¢ island = dplyr::if_else(is.na(island), \"unknown\", island)\n#> â€¢ sex = dplyr::if_else(is.na(sex), \"unknown\", sex)\n#> â€¢ island_Dream = as.numeric(island == \"Dream\")\n#> â€¢ island_Torgersen = as.numeric(island == \"Torgersen\")\n#> â€¢ sex_male = as.numeric(sex == \"male\")\n#> â€¢ sex_unknown = as.numeric(sex == \"unknown\")\n#> â€¢ bill_length_mm = dplyr::if_else(is.na(bill_length_mm), 43.92193, bill_l ...\n#> â€¢ bill_depth_mm = dplyr::if_else(is.na(bill_depth_mm), 17.15117, bill_dep ...\n#> â€¢ flipper_length_mm = dplyr::if_else(is.na(flipper_length_mm), 201, flipp ...\n#> â€¢ body_mass_g = dplyr::if_else(is.na(body_mass_g), 4202, body_mass_g)\n#> â€¢ island_Dream = dplyr::if_else(is.na(island_Dream), 0.3604651, island_Dr ...\n#> â€¢ island_Torgersen = dplyr::if_else(is.na(island_Torgersen), 0.1511628, i ...\n#> â€¢ sex_male = dplyr::if_else(is.na(sex_male), 0.4883721, sex_male)\n#> â€¢ sex_unknown = dplyr::if_else(is.na(sex_unknown), 0.03197674, sex_unknow ...\n#> â€¢ Adelie = 0 + dplyr::case_when((bill_depth_mm < 15.1 | is.na(bill_depth_ ...\n#> â€¢ Chinstrap = 0 + dplyr::case_when((island_Dream < 0.5 | is.na(island_Dre ...\n#> â€¢ Gentoo = 0 + dplyr::case_when((bill_depth_mm < 15.95 | is.na(bill_depth ...\n#> â€¢ .pred_class = dplyr::case_when(Adelie > Chinstrap & Adelie > Gentoo ~ \" ...\n#> â€¢ norm = exp(Adelie) + exp(Chinstrap) + exp(Gentoo)\n#> â€¢ .pred_Adelie = exp(Adelie) / norm\n#> â€¢ .pred_Chinstrap = exp(Chinstrap) / norm\n#> â€¢ .pred_Gentoo = exp(Gentoo) / norm\n#> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#> 22 equations in total.\n\nNotice how we can select both \"class\" and \"prob\". The predictions now include both hard and soft class predictions.\npredict(orbital_obj_prob, penguins)\n#> # A tibble: 344 Ã— 4\n#>    .pred_class .pred_Adelie .pred_Chinstrap .pred_Gentoo\n#>    <chr>              <dbl>           <dbl>        <dbl>\n#>  1 Adelie             0.989         0.00554      0.00560\n#>  2 Adelie             0.989         0.00554      0.00560\n#>  3 Adelie             0.989         0.00554      0.00560\n#>  4 Adelie             0.709         0.0245       0.267  \n#>  5 Adelie             0.989         0.00554      0.00560\n#>  6 Adelie             0.989         0.00554      0.00560\n#>  7 Adelie             0.989         0.00554      0.00560\n#>  8 Adelie             0.989         0.00554      0.00560\n#>  9 Adelie             0.979         0.00549      0.0158 \n#> 10 Adelie             0.980         0.00559      0.0148 \n#> # â„¹ 334 more rows\n\nThat works equally well in databases.\npredict(orbital_obj_prob, penguins_sqlite)\n#> # Source:   SQL [?? x 4]\n#> # Database: sqlite 3.47.1 []\n#>    .pred_class .pred_Adelie .pred_Chinstrap .pred_Gentoo\n#>    <chr>              <dbl>           <dbl>        <dbl>\n#>  1 Adelie             0.989         0.00554      0.00560\n#>  2 Adelie             0.989         0.00554      0.00560\n#>  3 Adelie             0.989         0.00554      0.00560\n#>  4 Adelie             0.709         0.0245       0.267  \n#>  5 Adelie             0.989         0.00554      0.00560\n#>  6 Adelie             0.989         0.00554      0.00560\n#>  7 Adelie             0.989         0.00554      0.00560\n#>  8 Adelie             0.989         0.00554      0.00560\n#>  9 Adelie             0.979         0.00549      0.0158 \n#> 10 Adelie             0.980         0.00559      0.0148 \n#> # â„¹ more rows\n\nNew augment method\n  \n    \n      \n\n      \n\n    \n  \n\nThe users of tidymodels have found the \naugment() function to be a handy tool. This function performs predictions and returns them alongside the original data set.\nThis release adds \naugment() support for orbital objects.\naugment(orbital_obj, penguins)\n#> # A tibble: 344 Ã— 8\n#>    .pred_class species island    bill_length_mm bill_depth_mm flipper_length_mm\n#>    <chr>       <fct>   <fct>              <dbl>         <dbl>             <int>\n#>  1 Adelie      Adelie  Torgersen           39.1          18.7               181\n#>  2 Adelie      Adelie  Torgersen           39.5          17.4               186\n#>  3 Adelie      Adelie  Torgersen           40.3          18                 195\n#>  4 Adelie      Adelie  Torgersen           NA            NA                  NA\n#>  5 Adelie      Adelie  Torgersen           36.7          19.3               193\n#>  6 Adelie      Adelie  Torgersen           39.3          20.6               190\n#>  7 Adelie      Adelie  Torgersen           38.9          17.8               181\n#>  8 Adelie      Adelie  Torgersen           39.2          19.6               195\n#>  9 Adelie      Adelie  Torgersen           34.1          18.1               193\n#> 10 Adelie      Adelie  Torgersen           42            20.2               190\n#> # â„¹ 334 more rows\n#> # â„¹ 2 more variables: body_mass_g <int>, sex <fct>\n\nThe function works for most databases, but for technical reasons doesnâ€™t work with all. It has been confirmed to not work work in spark databases or arrow tables.\naugment(orbital_obj, penguins_sqlite)\n#> # Source:   SQL [?? x 8]\n#> # Database: sqlite 3.47.1 []\n#>    .pred_class species island    bill_length_mm bill_depth_mm flipper_length_mm\n#>    <chr>       <chr>   <chr>              <dbl>         <dbl>             <int>\n#>  1 Adelie      Adelie  Torgersen           39.1          18.7               181\n#>  2 Adelie      Adelie  Torgersen           39.5          17.4               186\n#>  3 Adelie      Adelie  Torgersen           40.3          18                 195\n#>  4 Adelie      Adelie  Torgersen           NA            NA                  NA\n#>  5 Adelie      Adelie  Torgersen           36.7          19.3               193\n#>  6 Adelie      Adelie  Torgersen           39.3          20.6               190\n#>  7 Adelie      Adelie  Torgersen           38.9          17.8               181\n#>  8 Adelie      Adelie  Torgersen           39.2          19.6               195\n#>  9 Adelie      Adelie  Torgersen           34.1          18.1               193\n#> 10 Adelie      Adelie  Torgersen           42            20.2               190\n#> # â„¹ more rows\n#> # â„¹ 2 more variables: body_mass_g <int>, sex <chr>\n\nAcknowledgements\n  \n    \n      \n\n      \n\n    \n  \n\nA big thank you to all the people who have contributed to orbital since the release of v0.3.0:\n@EmilHvitfeldt, \n@joscani, \n@jrosell, \n@npelikan, and \n@szimmer.",
    "link": "https://www.tidyverse.org/blog/2025/01/orbital-0-3-0/",
    "pubDate": "Mon, 13 Jan 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "Joining the ggplot2 team",
    "description": "5x height\n* [x] [`hugodown::use_tidy_thumbnails()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html)\n* [ ] Add intro sentence, e.g. the standard tagline for the package\n* [ ] [`usethis::use_tidy_thanks()`](https://usethis.r-lib.org/reference/use_tidy_thanks.html)\n-->\nHello there! Iâ€™ve been working on ggplot2 for a while now, and Iâ€™d like to tell you how that came about and what it is like.\nHow I got involved\n  \n    \n      \n\n      \n\n    \n  \n\nMy journey into learning R started in 2017 during an internship at the EMBL-EBI. The main gripe about base R plotting that drove me into ggplot2â€™s arms were the arcane invocations to get anything else than one of the pre-approved chart types. In contrast, ggplot2 absorbs a bunch of small paper cuts, is very compositional in nature while remaining highly customisable. In a bid to â€œlearn from the mistakes of othersâ€ rather than (continue to copiously) make my own, I became active on Stack Overflow answering questions and solving plotting issues. For posterity: this was in the days before you could ask an large language model for personalised advice and actual humans were equally frustrated on both sides of the question.\nI was keeping track of solutions to common problems in a personal cookbook that had its own arcane invocations. To give a bit of flavour: much of the cookbook was about preparing gtables (the data structure that comes out of building a plot) for combining and aligning plots. 1 The cookbook eventually grew into my first ggplot2 extension package: \nggh4x. Perhaps that package would be best subtitled: â€˜Remedies to my common ggplot2 ailmentsâ€™. It contains a bunch of miscellaneous functions ranging from reorganising facets to putting minor ticks on the axes. The nature of the package was also its downside, as ggh4x lacked any sense of scope (and still does, as befits any first package).\nAround the time when I was really getting into ggplot extensions, \nGina Reynolds had started organising a meeting for people who build ggplot2 extensions. It is an interesting place to meet others and hear about their packages and how they face interacting with the ggplot2 extension system. I started attending with some degree of regularity and made a discussion place on GitHub. We now use this for general exchange of ideas, but also package specific issues.\nMeanwhile, the questions on Stack Overflow kept directing my attention at the ggplot2 issue tracker every once in a while. After lurking in there for a bit, I started my first informal contributions to ggplot2 itself by answering the simple stuff just as I did on Stack Overflow. It may not seem like much of a contribution, but in retrospect, answering issues helps triaging them: it separates those issues that need additional changes in ggplot2 from those that do not. My first â€˜proper contributionâ€™ in the shape of a pull request was in 2020. It replaced 3 lines of code with 2 lines of code to benefit type stability (this was prior to \nvctrs)2.\nIn 2022, I commented â€œIâ€™d be willing to take a stab at thisâ€ on an issue proposing a large refactor of the guide system. I like to think it was this precise moment that Thomas, the project lead after having taken over for Hadley, took notice and later invited me to join the team3. This new guide system ended up laying the foundation for \nlegendry, so it wasnâ€™t entirely out of unselfish reasons that I volunteered. At any rate, this is a great opportunity to fill big shoes on a major R project, so Iâ€™m very excited to have joined!\nBecoming an insider\n  \n    \n      \n\n      \n\n    \n  \n\nPart of being on the team is straightforward. You triage issues. You fix bugs. You implement new features. At the point that I joined, I had already done these things as an outsider. The only thing that really changes is that you get the keys to the kingdom: you can now close issues and merge pull requests 4. Youâ€™re then trusted to wield this power wisely. You then hope you do.\nAt the time I joined the most active maintainers were Thomas, Claus and Hiroaki. I was surprised to learn that really most communication happens on GitHub and it is all public discussion. Even more abstract coordination that does not neatly fit into a single issue, like preparing a new release, didnâ€™t occur behind closed doors. I think what made my introduction to the team more awkward than it needed to be was that GitHub issues is not really a good place for announcements where you can say â€˜Hi everyone, this person is on the team now and will be doing stuff in the projectâ€™. I had interacted with the other active maintainers before, so I wasnâ€™t a completely alien actor, but I felt some unclarity lingered longer than it ought have. Perhaps I should more assertively have introduced myself 5.\nHowever, by the time posit::conf(2024) was over, Iâ€™ve met 6 out of the 9 other authors in person. I have more thoughts about conf and my first time in the United States, but it has been amazing to meet all these people in person whose work youâ€™ve been admiring for a while!\nMaintaining ggplot2\n  \n    \n      \n\n      \n\n    \n  \n\nThe ggplot2 package has both the blessing and the curse of being a popular package. One the one hand, it is a blessing that people care about the project, post issues that they find and make intermittent contributions. The curse is that it is such a staple in the R ecosystem, that almost any change will inadvertently affect somebody elseâ€™s code. Not only because ggplot2 is widely used, but also because people have been â€¦creativeâ€¦ with how they are using ggplot2. The art of making changes is to largely affect plots in a good way.\nThe first big project I was rummaging through was the guide system I proposed to rewrite. The guide system had never been advertised as an official extension point, but naturally that didnâ€™t preclude people from using it as an extension point anyway.6 So in addition to rewriting the system, we also had to prevent terribly breaking extensions that relied on the old system. In some cases, this meant sending out PRs to other packages to be compatible with both systems.\nHaving worked through a good number of issues at this point in time, I can see some emergent patterns. Different patterns can be partially explained by different audiences. The regular user wants to be empowered to execute their vision of a plot effectively. Maintainers of extensions would often like things to work consistently or change a very obscure line somewhere that they have identified as blocking a niche use case. Teachers would like their students to get stuck less often, which often involves improving error messages. All in all, there is no shortage of issues to work through.\nThe next big thing weâ€™re working on is some practical necromancy in getting themeable aesthetics resurrected, which was \ninitiated by Dana Paige Seidel all the way back in 2018! Weâ€™d like the theme to be a home for more default choices than just non-data elements. Default layer aesthetics are a start, but we plan on putting in default palettes too.\nA few words of thanks\n  \n    \n      \n\n      \n\n    \n  \n\nIâ€™ve been plucked from a level of relative obscurity â€”a package maintainer that has this weird miscellaneous packageâ€” into the path of a flagship R project, for which Iâ€™m very grateful. First and foremost Iâ€™m thankful to Thomas Lin Pedersen, who has put me into this position and steers the ggplot2 project. Secondly to Hadley Wickham and the rest of the tidyverse team, who make me feel included; both at conf and during regular meetings7. Thirdly, the co-authors I met during conf: Claus Wilke, for whose workshop I TAâ€™d, but also Kara Woo and Winston Chang. Lastly, Iâ€™d like to thank Posit the company for contracting me to do work I also enjoy as a hobby!\nLuckily, we donâ€™t have to think about this at all, thanks to the \npatchwork package! â†©ï¸Ž\nIâ€™m omitting here that I also had to write 50 lines of tests for this small change â†©ï¸Ž\nHow much this actually reflects any truth is for any of us to guess and for Thomas to know. Later, I learned that this was also \nhow Thomas himself was roped into the project! â†©ï¸Ž\nAfter review though. Youâ€™re not given that much power! â†©ï¸Ž\nBut Iâ€™m not celebrated for my social graces :) â†©ï¸Ž\nI donâ€™t have a moral high ground here: I was one of the worst offenders! â†©ï¸Ž\nMostly for The Golden Hex Sticker though! â†©ï¸Ž",
    "link": "https://www.tidyverse.org/blog/2025/01/joining-ggplot2/",
    "pubDate": "Thu, 09 Jan 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  },
  {
    "id": "tidyverse",
    "title": "tidymodels Internship for 2025",
    "description": "We are chuffed once again to offer a summer internship with the tidymodels team.\nWeâ€™ve had eight previous summer interns and these led to the creation of a number of new packages: \nagua, \napplicable, \nbundle, \nbutcher, \nshinymodels, \nspatialsample, and \nstacks. Our own \nSimon Couch is a former intern who won \nan award for his work.\nThis year, the primary focus is on expanding our feature selection capabilities. Some of this will involve new recipe steps and other functions. Towards the end of the internship, there might be time to work on other things, too!\nTo apply, make sure that you have a GitHub handle and follow this link:\n\nhttps://posit.co/job-detail/?gh_jid=6323043003\nThe internship is US-based.\nIf you want to know what the internship is like, a few of our alumni have written about it:\nA summer with RStudio (2018)\nRStudio Summer Internship (2018)\nThis Is Not Like the Others (2019)\nTidymodels Internship (2020)\nI know what I did last summer (2022)\nWe canâ€™t wait to get started and look forward to reading your applications.",
    "link": "https://www.tidyverse.org/blog/2025/01/tidymodels-2025-internship/",
    "pubDate": "Wed, 08 Jan 2025 00:00:00 +0000",
    "source": "Tidyverse Blog",
    "category": "Rè¯­è¨€"
  }
]